[{"authors":["admin"],"categories":null,"content":"I am a research fellow at Glasgow Caledonian University and a healthcare scientist at Public Health Scotland. My research interests relate to the epidemiology and prevention of blood borne viruses as well as the evaluation of policies related to this field. I provide analytical and statistical support for a broad range of blood borne viruses including hepatitis B, hepatitis C and HIV. I am a supporter for the widespread adoption of open-source statistical software within the public sector in Scotland, particularly for the use of R.\nI also work as a freelancer on the Upwork platform and I am interested in taking on data science projects, ranging from the simple to the more complex. If you have a project that you feel I could help with, please get in touch.\nAll views and opinions expressed here are my own. \n","date":1695081600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1695081600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://alan-y.netlify.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a research fellow at Glasgow Caledonian University and a healthcare scientist at Public Health Scotland. My research interests relate to the epidemiology and prevention of blood borne viruses as well as the evaluation of policies related to this field. I provide analytical and statistical support for a broad range of blood borne viruses including hepatitis B, hepatitis C and HIV. I am a supporter for the widespread adoption of open-source statistical software within the public sector in Scotland, particularly for the use of R.","tags":null,"title":"Alan Yeung","type":"authors"},{"authors":null,"categories":null,"content":" Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://alan-y.netlify.com/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://alan-y.netlify.com/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":" Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://alan-y.netlify.com/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":null,"categories":["R"],"content":"\rFor a piece of work I had to calculate the number of matches that a team plays away from home in a row, which we will call days_on_the_road. I was not sure how to do this with dplyr but it’s basically a ‘grouped sequence’. For this post, I’ve created some dummy data to illustrate this idea. The num_matches_away variable is what we want to mimic using some data manipulation.\nlibrary(tidyverse)\rsports_df \u0026lt;- tibble::tribble(\r~team, ~date, ~home_or_away, ~num_matches_away,\r\u0026quot;Team A\u0026quot;, \u0026quot;07/10/2022\u0026quot;, \u0026quot;H\u0026quot;, 0L,\r\u0026quot;Team A\u0026quot;, \u0026quot;14/10/2022\u0026quot;, \u0026quot;A\u0026quot;, 1L,\r\u0026quot;Team A\u0026quot;, \u0026quot;21/10/2022\u0026quot;, \u0026quot;A\u0026quot;, 2L,\r\u0026quot;Team A\u0026quot;, \u0026quot;28/10/2022\u0026quot;, \u0026quot;H\u0026quot;, 0L,\r\u0026quot;Team A\u0026quot;, \u0026quot;04/11/2022\u0026quot;, \u0026quot;A\u0026quot;, 1L,\r\u0026quot;Team A\u0026quot;, \u0026quot;11/11/2022\u0026quot;, \u0026quot;A\u0026quot;, 2L,\r\u0026quot;Team A\u0026quot;, \u0026quot;18/11/2022\u0026quot;, \u0026quot;A\u0026quot;, 3L,\r\u0026quot;Team A\u0026quot;, \u0026quot;25/11/2022\u0026quot;, \u0026quot;H\u0026quot;, 0L,\r\u0026quot;Team A\u0026quot;, \u0026quot;02/12/2022\u0026quot;, \u0026quot;H\u0026quot;, 0L,\r\u0026quot;Team A\u0026quot;, \u0026quot;09/12/2022\u0026quot;, \u0026quot;H\u0026quot;, 0L,\r\u0026quot;Team B\u0026quot;, \u0026quot;07/10/2022\u0026quot;, \u0026quot;H\u0026quot;, 0L,\r\u0026quot;Team B\u0026quot;, \u0026quot;14/10/2022\u0026quot;, \u0026quot;A\u0026quot;, 1L,\r\u0026quot;Team B\u0026quot;, \u0026quot;21/10/2022\u0026quot;, \u0026quot;A\u0026quot;, 2L,\r\u0026quot;Team B\u0026quot;, \u0026quot;28/10/2022\u0026quot;, \u0026quot;A\u0026quot;, 3L,\r\u0026quot;Team B\u0026quot;, \u0026quot;04/11/2022\u0026quot;, \u0026quot;H\u0026quot;, 0L,\r\u0026quot;Team B\u0026quot;, \u0026quot;11/11/2022\u0026quot;, \u0026quot;A\u0026quot;, 1L,\r\u0026quot;Team B\u0026quot;, \u0026quot;18/11/2022\u0026quot;, \u0026quot;A\u0026quot;, 2L,\r\u0026quot;Team B\u0026quot;, \u0026quot;25/11/2022\u0026quot;, \u0026quot;H\u0026quot;, 0L,\r\u0026quot;Team B\u0026quot;, \u0026quot;02/12/2022\u0026quot;, \u0026quot;H\u0026quot;, 0L,\r\u0026quot;Team B\u0026quot;, \u0026quot;09/12/2022\u0026quot;, \u0026quot;A\u0026quot;, 1L\r) %\u0026gt;% mutate(date = as.Date(date, \u0026quot;%d/%m/%Y\u0026quot;)) %\u0026gt;% arrange(team, date)\rsports_df\r## # A tibble: 20 × 4\r## team date home_or_away num_matches_away\r## \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt;\r## 1 Team A 2022-10-07 H 0\r## 2 Team A 2022-10-14 A 1\r## 3 Team A 2022-10-21 A 2\r## 4 Team A 2022-10-28 H 0\r## 5 Team A 2022-11-04 A 1\r## 6 Team A 2022-11-11 A 2\r## 7 Team A 2022-11-18 A 3\r## 8 Team A 2022-11-25 H 0\r## 9 Team A 2022-12-02 H 0\r## 10 Team A 2022-12-09 H 0\r## 11 Team B 2022-10-07 H 0\r## 12 Team B 2022-10-14 A 1\r## 13 Team B 2022-10-21 A 2\r## 14 Team B 2022-10-28 A 3\r## 15 Team B 2022-11-04 H 0\r## 16 Team B 2022-11-11 A 1\r## 17 Team B 2022-11-18 A 2\r## 18 Team B 2022-11-25 H 0\r## 19 Team B 2022-12-02 H 0\r## 20 Team B 2022-12-09 A 1\rI firstly came up with a complicated solution for this using a combination of slider::slide() and rle() (run length encoding).\nsports_df2 \u0026lt;- sports_df %\u0026gt;% group_by(team) %\u0026gt;% mutate(days_on_road = unlist(slider::slide(rle(home_or_away)$length, ~1:.x)),\rdays_on_road = if_else(home_or_away == \u0026quot;H\u0026quot;, 0L, days_on_road)) %\u0026gt;% ungroup()\ridentical(sports_df2$days_on_road, sports_df$num_matches_away)\r## [1] TRUE\rThese are some pretty cool functions and it was nice to know rle() existed but I was never really happy with this solution as it seemed overly complex and it’s difficult to understand what the code is doing by simply reading it. So I asked a colleague to try to solve this problem and they came up with a better solution which I’m grateful for! It involves using a combination of group_by() and seq_len() which is a whole lot simpler to understand in my opinion.\nsports_df3 \u0026lt;- sports_df2 %\u0026gt;%\rmutate(away = cumsum(home_or_away == \u0026quot;H\u0026quot;)) %\u0026gt;%\rgroup_by(team, home_or_away, away) %\u0026gt;%\rmutate(days_on_road = seq_len(n())) %\u0026gt;%\rungroup() %\u0026gt;%\rmutate(days_on_road = if_else(home_or_away == \u0026quot;H\u0026quot;, 0L, days_on_road))\ridentical(sports_df3$days_on_road, sports_df$num_matches_away)\r## [1] TRUE\rI hope this is useful for some of you out there coding with R!\n","date":1699142400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699142400,"objectID":"92d96f07df7169fa32b9fb3d9e2ed55b","permalink":"https://alan-y.netlify.com/post/2023-11-05-grouped-sequences-in-dplyr/","publishdate":"2023-11-05T00:00:00Z","relpermalink":"/post/2023-11-05-grouped-sequences-in-dplyr/","section":"post","summary":"For a piece of work I had to calculate the number of matches that a team plays away from home in a row, which we will call days_on_the_road. I was not sure how to do this with dplyr but it’s basically a ‘grouped sequence’. For this post, I’ve created some dummy data to illustrate this idea. The num_matches_away variable is what we want to mimic using some data manipulation.","tags":["data manipulation","tidyverse"],"title":"Grouped Sequences in dplyr","type":"post"},{"authors":null,"categories":["R"],"content":"\rCombining case_when() and across()\rIf you want to use case_when() and across() different variables, then here is an example that can do this with the help of the get() and cur_column() functions.\nlibrary(tidyverse)\riris_df \u0026lt;- as_tibble(iris) %\u0026gt;% mutate(flag_Petal.Length = as.integer(Petal.Length \u0026gt; 1.5),\rflag_Petal.Width = as.integer(Petal.Width \u0026gt; 0.2))\riris_df %\u0026gt;% mutate(across(c(Petal.Length, Petal.Width),\r~case_when(\rget(glue::glue(\u0026quot;flag_{cur_column()}\u0026quot;)) == 1 ~ NA_real_,\rTRUE ~ .x\r))) %\u0026gt;% select(contains(\u0026quot;Petal\u0026quot;))\r## # A tibble: 150 × 4\r## Petal.Length Petal.Width flag_Petal.Length flag_Petal.Width\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt;\r## 1 1.4 0.2 0 0\r## 2 1.4 0.2 0 0\r## 3 1.3 0.2 0 0\r## 4 1.5 0.2 0 0\r## 5 1.4 0.2 0 0\r## 6 NA NA 1 1\r## 7 1.4 NA 0 1\r## 8 1.5 0.2 0 0\r## 9 1.4 0.2 0 0\r## 10 1.5 0.1 0 0\r## # ℹ 140 more rows\rIs there any way to use this with a function from the rlang packages instead of get()? It’s a little beyond my current understanding of tidy evaluation but let me know in the comments if you know please.\n\rCombining case_when() with if_any() and if_all()\rThe if_any() and if_all() functions can be used to save typing lots of variables (as these allow the use of tidyselect helpers) within case_when().\ndf1 \u0026lt;- tibble(var1 = c(1, 0, 1, NA),\rvar2 = c(1, 0, 0, NA))\rdf1 %\u0026gt;% mutate(category = case_when(\rif_any(c(var1, var2), ~.x \u0026gt; 0) ~ 1, if_all(c(var1, var2), is.na) ~ NA_real_,\rTRUE ~ 0\r))\r## # A tibble: 4 × 3\r## var1 var2 category\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 1 1 1\r## 2 0 0 0\r## 3 1 0 1\r## 4 NA NA NA\r\r","date":1696809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696809600,"objectID":"f02cf68b20a84164ae3c06c5687c71d0","permalink":"https://alan-y.netlify.com/post/couple-of-casewhen-tricks/","publishdate":"2023-10-09T00:00:00Z","relpermalink":"/post/couple-of-casewhen-tricks/","section":"post","summary":"Combining case_when() and across()\rIf you want to use case_when() and across() different variables, then here is an example that can do this with the help of the get() and cur_column() functions.\nlibrary(tidyverse)\riris_df \u0026lt;- as_tibble(iris) %\u0026gt;% mutate(flag_Petal.Length = as.integer(Petal.Length \u0026gt; 1.5),\rflag_Petal.Width = as.integer(Petal.Width \u0026gt; 0.2))\riris_df %\u0026gt;% mutate(across(c(Petal.Length, Petal.Width),\r~case_when(\rget(glue::glue(\u0026quot;flag_{cur_column()}\u0026quot;)) == 1 ~ NA_real_,\rTRUE ~ .x\r))) %\u0026gt;% select(contains(\u0026quot;Petal\u0026quot;))\r## # A tibble: 150 × 4\r## Petal.","tags":["tidyverse","data manipulation"],"title":"A couple of case_when() tricks","type":"post"},{"authors":null,"categories":["R"],"content":"\rThis blog post is just a note that when you try to do a grouped summary of a date variable but some groups have all missing values, it will return Inf. This means that the summary will not show up as an NA and this can cause issues in analysis if you are not careful.\nlibrary(tidyverse)\rdf \u0026lt;- tibble::tribble(\r~id, ~dt,\r1L, \u0026quot;01/01/2001\u0026quot;,\r1L, NA,\r2L, NA,\r2L, NA\r) %\u0026gt;% mutate(dt = dmy(dt))\rz1 \u0026lt;- df %\u0026gt;% group_by(id) %\u0026gt;% summarise(dt_min = min(dt, na.rm = TRUE),\r.groups = \u0026quot;drop\u0026quot;)\rz1\r# A tibble: 2 × 2\r# id dt_min # \u0026lt;int\u0026gt; \u0026lt;date\u0026gt; # 1 1 2001-01-01\r# 2 2 Inf\rsum(is.na(z1$dt_min))\r# [1] 0\rThere are a couple of ways around this. Firstly you can use an if() statement.\nz2 \u0026lt;- df %\u0026gt;% group_by(id) %\u0026gt;% summarise(dt_min = if (all(is.na(dt))) NA_Date_ else min(dt, na.rm = TRUE),\r.groups = \u0026quot;drop\u0026quot;)\rz2\r# A tibble: 2 × 2\r# id dt_min # \u0026lt;int\u0026gt; \u0026lt;date\u0026gt; # 1 1 2001-01-01\r# 2 2 NA sum(is.na(z2$dt_min))\r# [1] 1\rOr you can summary functions from the hablar package.\nz3 \u0026lt;- df %\u0026gt;% group_by(id) %\u0026gt;% summarise(dt_min = hablar::min_(dt),\r.groups = \u0026quot;drop\u0026quot;)\rz3\r# A tibble: 2 × 2\r# id dt_min # \u0026lt;int\u0026gt; \u0026lt;date\u0026gt; # 1 1 2001-01-01\r# 2 2 NA sum(is.na(z3$dt_min))\r# [1] 1\rIs there a reason why R decides to return Inf when summarising dates? Are there any other solutions to summarising date variables that contain missing values? Leave me a comment if you know thanks.\n","date":1696204800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696204800,"objectID":"2e26062f48e4922cd44d1311f1813435","permalink":"https://alan-y.netlify.com/post/summarising-dates-with-missing-values/","publishdate":"2023-10-02T00:00:00Z","relpermalink":"/post/summarising-dates-with-missing-values/","section":"post","summary":"This blog post is just a note that when you try to do a grouped summary of a date variable but some groups have all missing values, it will return Inf. This means that the summary will not show up as an NA and this can cause issues in analysis if you are not careful.\nlibrary(tidyverse)\rdf \u0026lt;- tibble::tribble(\r~id, ~dt,\r1L, \u0026quot;01/01/2001\u0026quot;,\r1L, NA,\r2L, NA,\r2L, NA\r) %\u0026gt;% mutate(dt = dmy(dt))\rz1 \u0026lt;- df %\u0026gt;% group_by(id) %\u0026gt;% summarise(dt_min = min(dt, na.","tags":["tidyverse","dates"],"title":"Summarising Dates with Missing Values","type":"post"},{"authors":["Scott McDonald","Matthew Hickman","John Dillon","Alan Yeung","Andrew McAuley","Andrew Fraser","Peter Hayes","Sharon Hutchinson"],"categories":null,"content":"","date":1695081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695081600,"objectID":"1269b3e790f1973b266eb436d1b2e2b1","permalink":"https://alan-y.netlify.com/publication/journal-article-transient_daa/","publishdate":"2023-09-19T00:00:00Z","relpermalink":"/publication/journal-article-transient_daa/","section":"publication","summary":"We investigated associations between outcomes and DAA treatment by comparing post-treatment to baseline periods using a within-subjects design","tags":["DAA","Drugs","PWID"],"title":"A transient positive association between direct-acting antiviral therapy for hepatitis C infection and drug-related hospitalization among people who inject drugs: Self-controlled case-series analysis of national data","type":"publication"},{"authors":["Kirsten Trayner","Alan Yeung","Harry Sumnall","Martin Anderson","Megan Glancy","Amanda Atkinson","Mike Smith","Andrew McAuley"],"categories":null,"content":"","date":1691452800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691452800,"objectID":"0561d2941178d87ffe22e69e86b84bec","permalink":"https://alan-y.netlify.com/publication/journal-article_naloxone_media/","publishdate":"2023-08-08T00:00:00Z","relpermalink":"/publication/journal-article_naloxone_media/","section":"publication","summary":"The aim of this study was to assess the effect of the 'How to save a life' campaign on the supply of take-home naloxone","tags":["Drugs","Naloxone","time-series"],"title":"National increase in the community supply of take-home naloxone associated with a mass media campaign in Scotland: a segmented time series analysis","type":"publication"},{"authors":["Victoria Hamill","Stanley Wong","Jennifer Benselin","Mel Krajden","Peter Hayes","David Mutimer","Amanda Yu","John Dillon","William Gelson","Hector Velásquez García","Alan Yeung","Philip Johnson","Stephen Barclay","Maria Alvarez","Hidenori Toyoda","Kosh Agarwal","Andrew Fraser","Sofia Bartlett","Mark Aldersley","Andrew Bathgate","Mawuena Binka","Paul Richardson","Joanne Morling","Stephen Ryder","Douglas MacDonald","Sharon Hutchinson","Eleanor Barnes","Indra Neil Guha","William Irving","Naveed Janjua","Hamish Innes"],"categories":null,"content":"","date":1690934400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690934400,"objectID":"67323f54ba16ee4bdd8ad7b5d6812519","permalink":"https://alan-y.netlify.com/publication/journal-article-mortality_treated_hcv/","publishdate":"2023-08-02T00:00:00Z","relpermalink":"/publication/journal-article-mortality_treated_hcv/","section":"publication","summary":"This study compared mortality rates for patients treated for hepatitis C in the era of direct acting antivirals with the general population","tags":["DAA","HCV","Mortality","Liver Disease"],"title":"Mortality rates among patients successfully treated for hepatitis C in the era of interferon-free antivirals: population based cohort study","type":"publication"},{"authors":["Andrew McAuley","Rosalyn Fraser","Megan Glancy","Alan Yeung","Hayley Jones","Peter Vickerman","Hannah Fraser","Lara Allen","Scott McDonald","Jack Stone","David Liddell","Lee Barnsdale","Sakey Priyadarshi","Andreas Markoulidakis","Matthew Hickman","Sharon Hutchinson"],"categories":null,"content":"","date":1686009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686009600,"objectID":"a33cf15af727082ca6497de3075955e8","permalink":"https://alan-y.netlify.com/publication/journal-article-oat_mortality/","publishdate":"2023-06-06T00:00:00Z","relpermalink":"/publication/journal-article-oat_mortality/","section":"publication","summary":"We assessed the extent to which opioid-agonist therapy is protective against drug-related mortality in Scotland","tags":["OAT","Drugs","Mortality"],"title":"Mortality among individuals prescribed opioid-agonist therapy in Scotland, UK, 2011-20: a national retrospective cohort study","type":"publication"},{"authors":["Hamish Innes","Victoria Hamill","Scott McDonald","Peter Hayes","Philip Johnson","John Dillon","Jen Bishop","Alan Yeung","April Went","Stephen Barclay","Andrew Fraser","Andrew Bathgate","David Goldberg","Sharon Hutchinson"],"categories":null,"content":"","date":1664064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664064000,"objectID":"543f48633e58b1ffd4881b6fd639f9af","permalink":"https://alan-y.netlify.com/publication/journal-article-comparing_hcc_prob/","publishdate":"2022-09-25T00:00:00Z","relpermalink":"/publication/journal-article-comparing_hcc_prob/","section":"publication","summary":"We compared the predicted hepatocellular carcinoma probability for individuals with cirrhosis and cured hepatitis C with the general population","tags":["HCC","Cirrhosis","HCV"],"title":"Comparing Predicted Probability of Hepatocellular Carcinoma in Patients With Cirrhosis With the General Population: An Opportunity to Improve Risk Communication?","type":"publication"},{"authors":null,"categories":["R","Personal"],"content":"\rI’ve been a Nadal fan for a long time – right back to the days of the pirate-pants so yeah, really a long time. In all this time, Rafa has never been ahead in the grand slam race vs his biggest rivals… but that finally changed after the 2022 Australian Open! The win there was unexpected and came out of nowhere. The final against Medvedev has to go down as one of the best comebacks ever.\nIt’s already been as.Date(\"2022-02-13\") - as.Date(\"2022-01-30\") (14 days) since he won that record 21st grand slam so I thought it has to be about time to do something to mark the achievement. Something that’s been on my list of things to learn is gganimate which is a very cool R package so I thought I’d take the opportunity here. My goal is to create an animated barplot, showing Rafa on top at the very end.\nGetting the data\rI started by using this data on grand slam wins from this blog post by Emily Kuehler and filtering for just the data on the big 3 male players: Nadal, Djokovic and Federer. Since the grand slam data there does not go all the way up to the 2022 Australian Open, I had to manually add that in by looking up the required information on Wikipedia and binding that to the end.\nlibrary(tidyverse)\rlibrary(readxl)\rgs_df \u0026lt;- read_csv(\u0026quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv\u0026quot;, show_col_types = FALSE)\rgs_update \u0026lt;- tibble::tribble(\r~year, ~grand_slam, ~name, ~rolling_win_count, ~tournament_date,\r2019, \u0026quot;French Open\u0026quot;, \u0026quot;Rafael Nadal\u0026quot;, 18, \u0026quot;26/05/2019\u0026quot;,\r2019, \u0026quot;Wimbledon\u0026quot;, \u0026quot;Novak Djokovic\u0026quot;, 16, \u0026quot;01/07/2019\u0026quot;,\r2019, \u0026quot;US Open\u0026quot;, \u0026quot;Rafael Nadal\u0026quot;, 19, \u0026quot;26/08/2019\u0026quot;,\r2020, \u0026quot;Australian Open\u0026quot;, \u0026quot;Novak Djokovic\u0026quot;, 17, \u0026quot;20/01/2020\u0026quot;,\r2020, \u0026quot;French Open\u0026quot;, \u0026quot;Rafael Nadal\u0026quot;, 20, \u0026quot;27/09/2020\u0026quot;,\r2021, \u0026quot;Australian Open\u0026quot;, \u0026quot;Novak Djokovic\u0026quot;, 18, \u0026quot;08/02/2021\u0026quot;,\r2021, \u0026quot;French Open\u0026quot;, \u0026quot;Novak Djokovic\u0026quot;, 19, \u0026quot;30/05/2021\u0026quot;,\r2021, \u0026quot;Wimbledon\u0026quot;, \u0026quot;Novak Djokovic\u0026quot;, 20, \u0026quot;28/07/2021\u0026quot;,\r2022, \u0026quot;Australian Open\u0026quot;, \u0026quot;Rafael Nadal\u0026quot;, 21, \u0026quot;17/01/2022\u0026quot;\r) %\u0026gt;% mutate(tournament_date = as.Date(tournament_date, \u0026quot;%d/%m/%Y\u0026quot;))\rgs_df2 \u0026lt;- gs_df %\u0026gt;%\rfilter(name %in% c(\u0026quot;Rafael Nadal\u0026quot;, \u0026quot;Novak Djokovic\u0026quot;, \u0026quot;Roger Federer\u0026quot;)) %\u0026gt;%\rmutate(grand_slam = str_replace_all(grand_slam, \u0026quot;_\u0026quot;, \u0026quot; \u0026quot;),\rgrand_slam = str_to_title(grand_slam),\rgrand_slam = str_replace_all(grand_slam, \u0026quot;Us\u0026quot;, \u0026quot;US\u0026quot;)) %\u0026gt;%\rselect(-gender) %\u0026gt;%\rbind_rows(gs_update)\rgs_df2\r# A tibble: 61 x 5\r# year grand_slam name rolling_win_count tournament_date\r# \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;date\u0026gt; # 1 2003 Wimbledon Roger Federer 1 2003-07-14 # 2 2004 Australian Open Roger Federer 2 2004-01-10 # 3 2004 Wimbledon Roger Federer 3 2004-07-14 # 4 2004 US Open Roger Federer 4 2004-09-09 # 5 2005 French Open Rafael Nadal 1 2005-06-09 # 6 2005 Wimbledon Roger Federer 5 2005-07-14 # 7 2005 US Open Roger Federer 6 2005-09-09 # 8 2006 Australian Open Roger Federer 7 2006-01-10 # 9 2006 French Open Rafael Nadal 2 2006-06-09 # 10 2006 Wimbledon Roger Federer 8 2006-07-14 # ... with 51 more rows\r\rData processing\rI had to do a bit of general data wrangling (isn’t this always the case unfortunately?) to set things up for gganimate. This is all fairly standard stuff so I’ll just show the code below but one thing to note is that for the rank order (current_rank) of the players at each time point, I sorted ascending on rolling_win_count2 rather than descending (as would seem more logical to get the ranking by most slams) because when you use ggplot2::coord_flip(), it puts the highest value (lowest rank) at the top of the graph – so essentially I set it up so that rank 3 is the best and rank 1 is the worst.\n# Expand out for all combinations\rgs_df3 \u0026lt;- gs_df2 %\u0026gt;% arrange(tournament_date) %\u0026gt;% mutate(year = fct_inorder(factor(year)),\rgrand_slam = factor(grand_slam, levels = c(\u0026quot;Australian Open\u0026quot;, \u0026quot;French Open\u0026quot;, \u0026quot;Wimbledon\u0026quot;, \u0026quot;US Open\u0026quot;)),\rname = factor(name, levels = c(\u0026quot;Rafael Nadal\u0026quot;, \u0026quot;Novak Djokovic\u0026quot;, \u0026quot;Roger Federer\u0026quot;))) %\u0026gt;% complete(year, grand_slam, name) %\u0026gt;% replace_na(list(rolling_win_count = 0))\r# Drop tournaments before first slam win or not yet played\rgs_df4 \u0026lt;- gs_df3 %\u0026gt;% filter(!(year == 2003 \u0026amp; grand_slam %in% c(\u0026quot;Australian Open\u0026quot;, \u0026quot;French Open\u0026quot;)),\r!(year == 2022 \u0026amp; grand_slam %in% c(\u0026quot;French Open\u0026quot;, \u0026quot;Wimbledon\u0026quot;, \u0026quot;US Open\u0026quot;))) %\u0026gt;% mutate(yr_slam = paste(year, grand_slam), .before = year)\r# Recalculate rolling win count\rgs_df5 \u0026lt;- gs_df4 %\u0026gt;% mutate(win = as.numeric(rolling_win_count \u0026gt; 0)) %\u0026gt;% group_by(name) %\u0026gt;% mutate(rolling_win_count2 = cumsum(win)) %\u0026gt;% ungroup() # Set the rank for each time point\rgs_df6 \u0026lt;- gs_df5 %\u0026gt;% arrange(year, grand_slam, rolling_win_count2, desc(name)) %\u0026gt;% group_by(yr_slam) %\u0026gt;% mutate(current_rank = row_number()) %\u0026gt;% ungroup()\rselect(gs_df6, yr_slam, name, rolling_win_count2, current_rank)\r# A tibble: 225 x 4\r# yr_slam name rolling_win_count2 current_rank\r# \u0026lt;chr\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt;\r# 1 2003 Wimbledon Novak Djokovic 0 1\r# 2 2003 Wimbledon Rafael Nadal 0 2\r# 3 2003 Wimbledon Roger Federer 1 3\r# 4 2003 US Open Novak Djokovic 0 1\r# 5 2003 US Open Rafael Nadal 0 2\r# 6 2003 US Open Roger Federer 1 3\r# 7 2004 Australian Open Novak Djokovic 0 1\r# 8 2004 Australian Open Rafael Nadal 0 2\r# 9 2004 Australian Open Roger Federer 2 3\r# 10 2004 French Open Novak Djokovic 0 1\r# ... with 215 more rows\r\rggimage\rNext I prepared some cartoon faces for the 3 players to go on the ends of the bars and stored these on Github so they can be loaded into R with the help of the ggimage package. I won’t go into much detail on the image processing side but the online tools I used to help with this are all in the references section of this blog post.\nlibrary(ggimage)\rimg_rafa \u0026lt;- \u0026quot;https://raw.githubusercontent.com/alan-y/img/master/rafa2.png\u0026quot;\rimg_novak \u0026lt;- \u0026quot;https://raw.githubusercontent.com/alan-y/img/master/novak2.png\u0026quot;\rimg_roger \u0026lt;- \u0026quot;https://raw.githubusercontent.com/alan-y/img/master/roger2.png\u0026quot;\rgs_df7 \u0026lt;- gs_df6 %\u0026gt;% mutate(img_player = case_when(\rname == \u0026quot;Rafael Nadal\u0026quot; ~ img_rafa,\rname == \u0026quot;Novak Djokovic\u0026quot; ~ img_novak,\rname == \u0026quot;Roger Federer\u0026quot; ~ img_roger,\r))\rselect(gs_df7, name, img_player)\r# A tibble: 225 x 2\r# name img_player # \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; # 1 Novak Djokovic https://raw.githubusercontent.com/alan-y/img/master/novak2.png\r# 2 Rafael Nadal https://raw.githubusercontent.com/alan-y/img/master/rafa2.png # 3 Roger Federer https://raw.githubusercontent.com/alan-y/img/master/roger2.png\r# 4 Novak Djokovic https://raw.githubusercontent.com/alan-y/img/master/novak2.png\r# 5 Rafael Nadal https://raw.githubusercontent.com/alan-y/img/master/rafa2.png # 6 Roger Federer https://raw.githubusercontent.com/alan-y/img/master/roger2.png\r# 7 Novak Djokovic https://raw.githubusercontent.com/alan-y/img/master/novak2.png\r# 8 Rafael Nadal https://raw.githubusercontent.com/alan-y/img/master/rafa2.png # 9 Roger Federer https://raw.githubusercontent.com/alan-y/img/master/roger2.png\r# 10 Novak Djokovic https://raw.githubusercontent.com/alan-y/img/master/novak2.png\r# ... with 215 more rows\r\rgganimate\rFirstly I’ll mention that for the gganimate package to work well, you’ll also need to install the gifski package. To get things ready for the animated plot in plot_df, I just had to make a couple of minor manipulations. Then everything up to the use of transition_states() in the code below is standard ggplot2 code except maybe the use of geom_image() to add the cartoon faces to the end of the bars (note that I subtract 0.5 from rolling_win_count as the function doesn’t seem to have a nudge_y argument even though it has one for nudge_x) and the use of {closest_state} in the subtitle – this tracks the variable that the animation transitions over which for me, is yr_slam, i.e. the combination of year and grand slam name. The fill colours are from scale_fill_hue() but manually picked so that the fill colour of each player’s bar matches their favourite surface.\nFor transition_states(), the transition_length() is the relative length of the transition and state_length() is the relative length of the pause at the states (I stole this from the help page); I set wrap = FALSE as I don’t want the last state to transition into the first when looping the animation. I am not sure how much difference the ease_aes(\"quadratic-in-out\") makes here to be honest but that’s what I used. In general I know this function is for messing around with the effects applied to how frames/states transition into one another. If somebody can give me a good layman’s explanation of these functions, I’d be grateful if you can do so in the comments.\nIn the animate() function, I set nframes = 500. Some things to note here are that the default is only 50 frames so if you have more than 50 states (and I do as I have more than 50 year-slam combinations) then you need to set this to a larger number but this number should be suitably larger so the animation looks smoother. I set end_pause to 30 frames so that it pauses at the end for a little bit. Finally I applied very specific width and height as I wanted to add something to the end of the animation which happened to have these dimensions – that’s a surprise which you will see!\nlibrary(gganimate)\rplot_df \u0026lt;- gs_df7 %\u0026gt;% select(-rolling_win_count) %\u0026gt;% rename(rolling_win_count = rolling_win_count2) %\u0026gt;% mutate(yr_slam = fct_inorder(factor(yr_slam)),\rname_count = paste(name, rolling_win_count))\r# Set up ggplot2 theme\rtheme_set(theme_minimal())\rtheme_update(plot.title = element_text(face = \u0026quot;bold\u0026quot;, size = 18),\rplot.subtitle = element_text(size = 14),\rpanel.grid.major.y = element_blank(),\rpanel.grid.minor.y = element_blank(),\rpanel.grid.major.x = element_line(color = \u0026quot;grey75\u0026quot;),\rpanel.grid.minor.x = element_line(color = \u0026quot;grey75\u0026quot;),\rlegend.position = \u0026quot;none\u0026quot;,\raxis.ticks = element_blank(),\raxis.text.y = element_blank())\rbarplot_slams \u0026lt;- ggplot(plot_df, aes(x = current_rank, y = rolling_win_count, fill = name)) +\rgeom_bar(stat = \u0026quot;identity\u0026quot;, width = 0.3, colour = \u0026quot;black\u0026quot;) +\rgeom_text(aes(label = name_count), nudge_x = -0.25, nudge_y = -0.75, size = 3, fontface = \u0026quot;bold\u0026quot;, hjust = 0) +\rgeom_image(aes(image = img_player, y = rolling_win_count - 0.5), size = 0.09) +\rscale_fill_manual(values = c(\u0026quot;#FF7969\u0026quot;, \u0026quot;#569EFF\u0026quot;, \u0026quot;#00B73A\u0026quot;)) +\rscale_y_continuous(limits = c(-0.75, 25), breaks = seq(0, 25, by = 5)) +\rcoord_flip() +\rlabs(title = \u0026quot;Men\u0026#39;s Tennis Grand Slam Singles Championships\u0026quot;,\rsubtitle = \u0026quot;{closest_state}\u0026quot;,\rx = NULL, y = NULL) +\rtransition_states(yr_slam, transition_length = 3, state_length = 1, wrap = FALSE) +\rease_aes(\u0026quot;quadratic-in-out\u0026quot;)\ranimate(barplot_slams, nframes = 500, end_pause = 30, fps = 20, width = 469, height = 334,\rrenderer = gifski_renderer(\u0026quot;barplot_slams.gif\u0026quot;)) \rSo without further ado, here is the final result for your enjoyment.\n\rReferences\rhttps://www.archyworldys.com/before-talking-about-greatest-of-all-time-what-you-need-to-know-about-big-3-tennis\nhttps://www.cutout.pro\nhttps://www.eurosport.com/tennis/watch-historic-moment-rafael-nadal-wins-australian-open-and-claims-historic-21st-grand-slam-singles-_vid1618912/video.shtml\nhttps://www.downloadhelper.net\nhttps://online-video-cutter.com\nhttps://ezgif.com\nhttps://gif.ski\nhttps://gifyu.com\n\r","date":1644710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644710400,"objectID":"faf1b99b5dd6ede6eadca4b3bcdbf974","permalink":"https://alan-y.netlify.com/post/rafa-21-slams/","publishdate":"2022-02-13T00:00:00Z","relpermalink":"/post/rafa-21-slams/","section":"post","summary":"I’ve been a Nadal fan for a long time – right back to the days of the pirate-pants so yeah, really a long time. In all this time, Rafa has never been ahead in the grand slam race vs his biggest rivals… but that finally changed after the 2022 Australian Open! The win there was unexpected and came out of nowhere. The final against Medvedev has to go down as one of the best comebacks ever.","tags":["gganimate","ggimage","ggplot2","Tennis"],"title":"Rafa 21 Grand Slams and gganimate","type":"post"},{"authors":["Kirsten Trayner","Andrew McAuley","Norah Palmateer","Alan Yeung","David Goldberg","Megan Glancy","Carole Hunter","Trina Ritchie","Julie Craik","Fiona Raeburn","Stuart McTaggart","Lee Barnsdale","John Campbell","Samantha Shepherd","Amanda Bradley-Stewart","Rory Gunson","Kate Templeton","Sharon Hutchinson"],"categories":null,"content":"","date":1643587200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643587200,"objectID":"fa9d1fc3dd6fb50ca1b83f74adb3c56a","permalink":"https://alan-y.netlify.com/publication/journal-article-covid_bbv_its/","publishdate":"2022-01-31T00:00:00Z","relpermalink":"/publication/journal-article-covid_bbv_its/","section":"publication","summary":"We examined the impact of the first wave of COVID-19 in Scotland on drug and BBV services.","tags":["COVID-19","BBV","PWID","time-series"],"title":"Examining the impact of the first wave of COVID-19 and associated control measures on interventions to prevent blood-borne viruses among people who inject drugs in Scotland: an interrupted time series study","type":"publication"},{"authors":["Hamish Innes","Scott McDonald","Victoria Hamill","Alan Yeung","John Dillon","Peter Hayes","April Went","Andrew Fraser","Andrew Bathgate","Stephen Barclay","Naveed Janjua","David Goldberg","Sharon Hutchinson"],"categories":null,"content":"","date":1640217600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640217600,"objectID":"3023ce4d9d718774dc9433bfaf4938af","permalink":"https://alan-y.netlify.com/publication/journal-article-hcc-decline/","publishdate":"2021-12-23T00:00:00Z","relpermalink":"/publication/journal-article-hcc-decline/","section":"publication","summary":"This study explores the impact of interferon-free therapies on hepatitis C virus related hepatocellular carcinoma at a population level.","tags":["HCC","HCV","Cirrhosis","DAA"],"title":"Declining incidence of hepatitis C related hepatocellular carcinoma in the era of interferon-free therapies: A population-based cohort study","type":"publication"},{"authors":["Hamish Innes","Philip Johnson","Scott McDonald","Victoria Hamill","Alan Yeung","John Dillon","Peter Hayes","April Went","Stephen Barclay","Andrew Fraser","Andrew Bathgate","David Goldberg","Sharon Hutchinson"],"categories":null,"content":"","date":1637107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637107200,"objectID":"ec0ad7ba07fd5275e2210ec5d7f783e8","permalink":"https://alan-y.netlify.com/publication/journal-article-risk-bias-hcc/","publishdate":"2021-11-17T00:00:00Z","relpermalink":"/publication/journal-article-risk-bias-hcc/","section":"publication","summary":"The goal of this study was to quantify the bias in estimating risk of hepatocellular carcinoma for patients with cirrhosis and cured hepatitis C.","tags":["HCC","HCV","Cirrhosis"],"title":"Competing risk bias in prognostic models predicting hepatocellular carcinoma occurrence: impact on clinical decision making","type":"publication"},{"authors":["Alan Yeung","Norah Palmateer","John Dillon","Scott McDonald","Shanley Smith","Stephen Barclay","Peter Hayes","Rory Gunson","Kate Templeton","David Goldberg","Matthew Hickman","Sharon Hutchinson"],"categories":null,"content":"","date":1633737600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633737600,"objectID":"bbd3ae5cdbdc0602d9c27fe4954cc91c","permalink":"https://alan-y.netlify.com/publication/journal-article-hcv_reinf/","publishdate":"2021-10-09T00:00:00Z","relpermalink":"/publication/journal-article-hcv_reinf/","section":"publication","summary":"We estimated HCV reinfection rates among PWID in Scotland pre and post-introduction of DAAs.","tags":["HCV","DAA","PWID","Reinfection"],"title":"Population-level estimates of hepatitis C reinfection post scale-up of direct-acting antivirals among people who inject drugs","type":"publication"},{"authors":["Hamish Innes","Peter Jepsen","Scott McDonald","John Dillon","Victoria Hamill","Alan Yeung","Jennifer Benselin","April Went","Andrew Fraser","Andrew Bathgate","M. Azim Ansari","Stephen Barclay","David Goldberg","Peter Hayes","Philip Johnson","Eleanor Barnes","William Irving","Sharon Hutchinson","Indra Neil Guha"],"categories":null,"content":"","date":1633564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633564800,"objectID":"9b21f52ccd5f27d75f3f8cfdf8b6d5ea","permalink":"https://alan-y.netlify.com/publication/journal-article-hcc-model/","publishdate":"2021-10-07T00:00:00Z","relpermalink":"/publication/journal-article-hcc-model/","section":"publication","summary":"We conducted an external validation of six HCC prediction models for UK patients with cirrhosis HCV virological cure.","tags":["HCV","HCC","Cirrhosis"],"title":"Performance of models to predict hepatocellular carcinoma risk among UK patients with cirrhosis and cured hepatitis C infection","type":"publication"},{"authors":["Gillian Burton","Andrew McAuley","Joe Schofield","Alan Yeung","Catriona Matheson","Tessa Parkes"],"categories":null,"content":"","date":1622332800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622332800,"objectID":"a5b4be832c58cfab9130b8fe818a2d9b","permalink":"https://alan-y.netlify.com/publication/journal-article_thn_meta/","publishdate":"2021-05-30T00:00:00Z","relpermalink":"/publication/journal-article_thn_meta/","section":"publication","summary":"This study aimed to assess the prevalence of ownership and carriage of Take-Home Naloxone internationally among people who use drugs","tags":["Drugs","PWUD","Naloxone","Meta-analysis"],"title":"A systematic review and meta-analysis of the prevalence of take-home naloxone (THN) ownership and carriage","type":"publication"},{"authors":["Norah Palmateer","Andrew McAuley","John Dillon","Scott McDonald","Alan Yeung","Shanley Smith","Stephen Barclay","Peter Hayes","Samantha Shepherd","Rory Gunson","David Goldberg","Matthew Hickman","Sharon Hutchinson"],"categories":null,"content":"","date":1614643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614643200,"objectID":"c234ba8c5e825741a3a872663b63ad2c","permalink":"https://alan-y.netlify.com/publication/journal-article-hcv_prev_daa/","publishdate":"2021-03-02T00:00:00Z","relpermalink":"/publication/journal-article-hcv_prev_daa/","section":"publication","summary":"We assessed the impact of rapid DAA scale‐up to PWID delivered through community services in the Tayside region of Scotland.","tags":["HCV","DAA","PWID"],"title":"Reduction in the population prevalence of HCV viraemia among people who inject drugs associated with scale-up of direct-acting antiviral therapy in community drug services: real world data","type":"publication"},{"authors":["Ceilidh Grimshaw","Claudia Estcourt","Rak Nandwani","Alan Yeung","David Henderson","John Saunders"],"categories":null,"content":"","date":1610496000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610496000,"objectID":"da14cca924d2a4b538f1cccc7804d17d","permalink":"https://alan-y.netlify.com/publication/journal-article-prep-char/","publishdate":"2021-01-13T00:00:00Z","relpermalink":"/publication/journal-article-prep-char/","section":"publication","summary":"The study reviewed characteristics of individuals newly diagnosed with HIV following implementation of a national PrEP programme to inform future delivery and broader HIV prevention strategies.","tags":["HIV","PrEP"],"title":"Implementation of a national HIV pre-exposure prophylaxis service is associated with changes in characteristics of people with newly diagnosed HIV: a retrospective cohort study","type":"publication"},{"authors":["Claudia Estcourt","Alan Yeung","Rak Nandwani","David Goldberg","Beth Cullen","Nicola Steedman","Lesley Wallace","Sharon Hutchinson"],"categories":null,"content":"","date":1607299200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607299200,"objectID":"ae2b781d9c13337b4c093271f443e442","permalink":"https://alan-y.netlify.com/publication/journal-article-prep-incidence/","publishdate":"2020-12-07T00:00:00Z","relpermalink":"/publication/journal-article-prep-incidence/","section":"publication","summary":"The study evaluated Scotland's national HIV PrEP programme in relation to PrEP uptake and associated population-level impact on HIV incidence among MSM.","tags":["HIV","PrEP","Incidence"],"title":"Population-level effectiveness of a national HIV pre-exposure prophylaxis programme in MSM","type":"publication"},{"authors":null,"categories":["R"],"content":"\rA question came up recently at work about how to use a filter statement entered as a complete string variable inside dplyr’s filter() function – for example dplyr::filter(my_data, \"var1 == 'a'\"). There does not seem to be much out there on this and I was not sure how to do it either but luckily jakeybob had a neat solution that seems to work well.\nsome_data %\u0026gt;% filter(eval(rlang::parse_expr(selection_statement)))\rLet’s see it in action using the iris flowers dataset. First note how many records there are for each species (n = 50 for each) so we can check that the filtering has worked later.\nlibrary(tidyverse)\riris2 \u0026lt;- as_tibble(iris)\rcount(iris2, Species)\r# # A tibble: 3 x 2\r# Species n\r# \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt;\r# 1 setosa 50\r# 2 versicolor 50\r# 3 virginica 50\rNow filter to get only setosa records and we can see only 50 records so that’s worked.\nselection_statement \u0026lt;- \u0026quot;Species == \u0026#39;setosa\u0026#39;\u0026quot;\riris2 %\u0026gt;% filter(rlang::eval_tidy(rlang::parse_expr(selection_statement)))\r# # A tibble: 50 x 5\r# Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r# \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; # 1 5.1 3.5 1.4 0.2 setosa # 2 4.9 3 1.4 0.2 setosa # 3 4.7 3.2 1.3 0.2 setosa # 4 4.6 3.1 1.5 0.2 setosa # 5 5 3.6 1.4 0.2 setosa\rI thought this method might fail if we create a variable called Species in the global environment but it still works completely fine which is great!\nSpecies \u0026lt;- \u0026quot;abc\u0026quot;\riris2 %\u0026gt;% filter(rlang::eval_tidy(rlang::parse_expr(selection_statement)))\r# # A tibble: 50 x 5\r# Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r# \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; # 1 5.1 3.5 1.4 0.2 setosa # 2 4.9 3 1.4 0.2 setosa # 3 4.7 3.2 1.3 0.2 setosa # 4 4.6 3.1 1.5 0.2 setosa # 5 5 3.6 1.4 0.2 setosa\rSo it makes me wonder why there is nothing much out there on this? My feeling is that something will make this method fail but what is it? Where does it fail? Let me know in the comments if you know please, thanks!\n","date":1589328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589328000,"objectID":"02029c9cbbf3e427db29e4394f618b72","permalink":"https://alan-y.netlify.com/post/filtering-string-dplyr/","publishdate":"2020-05-13T00:00:00Z","relpermalink":"/post/filtering-string-dplyr/","section":"post","summary":"A question came up recently at work about how to use a filter statement entered as a complete string variable inside dplyr’s filter() function – for example dplyr::filter(my_data, \"var1 == 'a'\"). There does not seem to be much out there on this and I was not sure how to do it either but luckily jakeybob had a neat solution that seems to work well.\nsome_data %\u0026gt;% filter(eval(rlang::parse_expr(selection_statement)))\rLet’s see it in action using the iris flowers dataset.","tags":["tidy-evaluation"],"title":"Filtering with string statements in dplyr","type":"post"},{"authors":null,"categories":["R"],"content":"\rThis is just a small note (mainly for myself but hopefully may be of some use to a few others!) to remind of how to update a package on a drat repo.\nCreate the source file for the package you want to host on the drat repo using devtools::build().\rClone the drat repo hosting the package (in my case https://github.com/alan-y/drat).\rUse drat::insertPackage(\"package-source.tar.gz\", getwd()) to add the package to the drat repo (getwd() works for me if my working directory is at the top level of the drat repo). Note this also updates the PACKAGES file that contains details on the packages hosted in the drat repo.\rGit push the package to all branches (master and gh-pages) using git push origin --all. It is particularly important that changes are pushed to the gh-pages branch in order for this to work.\r\rAfter this, packages can be installed using, for example:\ndrat::addRepo(\u0026quot;alan-y\u0026quot;)\rinstall.packages(\u0026quot;phstemplates\u0026quot;)\rIf you want the drat repo to be available at startup drat::add() or drat::addRepo() can be added to a .Rprofile file.\n","date":1588464000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588464000,"objectID":"8b64b44defc6876c0e94dba15d7c35d3","permalink":"https://alan-y.netlify.com/post/updating-packages-on-a-drat-repo/","publishdate":"2020-05-03T00:00:00Z","relpermalink":"/post/updating-packages-on-a-drat-repo/","section":"post","summary":"This is just a small note (mainly for myself but hopefully may be of some use to a few others!) to remind of how to update a package on a drat repo.\nCreate the source file for the package you want to host on the drat repo using devtools::build().\rClone the drat repo hosting the package (in my case https://github.com/alan-y/drat).\rUse drat::insertPackage(\"package-source.tar.gz\", getwd()) to add the package to the drat repo (getwd() works for me if my working directory is at the top level of the drat repo).","tags":["R-packages"],"title":"Updating packages on a drat repo","type":"post"},{"authors":["Sharon Hutchinson","Heather Valerio","Scott McDonald","Alan Yeung","Kevin Pollock","Shanley Smith","Stephen Barclay","John Dillon","Raymond Fox","Peter Bramley","Andrew Fraser","Nicholas Kennedy","Rory Gunson","Kate Templeton","Hamish Innes","Allan McLeod","Amanda Weir","Peter Hayes","David Goldberg"],"categories":null,"content":"","date":1585180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585180800,"objectID":"4bfb547c26423ef874e7ff5d562b15d5","permalink":"https://alan-y.netlify.com/publication/journal-article-hcv_daa_dc/","publishdate":"2020-03-26T00:00:00Z","relpermalink":"/publication/journal-article-hcv_daa_dc/","section":"publication","summary":"We examined the impact of the introduction of direct-acting antiviral (DAA) therapies on hepatitis C related decompensated cirrhosis (DC) through analysis of population-based data from Scotland.","tags":["HCV","DAA","Cirrhosis"],"title":"Population impact of direct-acting antiviral treatment on new presentations of hepatitis C-related decompensated cirrhosis: a national record-linkage study","type":"publication"},{"authors":null,"categories":["R"],"content":"\r\rDownloading the data\rShiny App\r\r\rI recently saw this great post on Nathan Yau’s FlowingData website which guesses a person’s name based on what the name starts with. It also needs you to select a gender and a decade for when you were born before it can guess. Of course, it isn’t really a guess and is really just based on proportions calculated after restricting the data to what has been selected.\nIt uses data from the Social Security Administration in America so results more specifically apply to the US. I thought it’d be cool to see how it looks for Scottish data which is available from the National Records of Scotland (NRS). I’ve embedded the Shiny app below into an iframe but you can view the app in it’s own page by going to https://alan-y.shinyapps.io/name_guess. I used a little bit of css to make the iframe responsive (resizes based on the amount of screen/window space available). The app is hosted on shinyapps.io on a free account so if nobody visits it for a while, it will no longer be available (unless I restart it). So apologies if you happen to visit this page further down the line and it’s not working!\nThe R code I used to download and wrangle the data as well as create the Shiny app is provided further down the page. I hope the app is interesting to some people and my acknowledgements again, to Nathan Yau as this is clearly based off his work.\n\n\rDownloading the data\rFirst I identified the webpages from the NRS website that contained the required babynames csv files and then scraped the links to all the csv files with help from the rvest package. I created some helper functions (one to grab the csv links and one to read the csv files into R and tidy them up) to use with the map() functions from purrr.\nlibrary(tidyverse)\rlibrary(janitor)\rlibrary(rvest)\r# Helper functions\rget_csv_links \u0026lt;- function(link) {\rread_html(link) %\u0026gt;% html_nodes(\u0026quot;a\u0026quot;) %\u0026gt;% html_attr(\u0026quot;href\u0026quot;) %\u0026gt;% str_subset(\u0026quot;\\\\.csv\u0026quot;) %\u0026gt;% paste0(\u0026quot;https://www.nrscotland.gov.uk/\u0026quot;, .)\r}\rread_babynames \u0026lt;- function(link, yr) {\rb \u0026lt;- read_csv(link, skip = 6) %\u0026gt;% remove_empty() %\u0026gt;% select(-contains(\u0026quot;Position\u0026quot;)) %\u0026gt;% clean_names()\rboy \u0026lt;- b %\u0026gt;%\rselect(1:2) %\u0026gt;%\rset_names(c(\u0026quot;name\u0026quot;, \u0026quot;number_of_babies\u0026quot;)) %\u0026gt;% mutate(gender = \u0026quot;boy\u0026quot;)\rgirl \u0026lt;- b %\u0026gt;%\rselect(3:4) %\u0026gt;%\rset_names(c(\u0026quot;name\u0026quot;, \u0026quot;number_of_babies\u0026quot;)) %\u0026gt;%\rmutate(gender = \u0026quot;girl\u0026quot;)\rbind_rows(boy, girl) %\u0026gt;% mutate(year = yr) %\u0026gt;% filter(!is.na(number_of_babies))\r}\r# List of webpages containing the csv files\rpages \u0026lt;- c(\u0026quot;https://www.nrscotland.gov.uk/statistics-and-data/statistics/statistics-by-theme/vital-events/names/babies-first-names/full-lists-of-babies-first-names-archive/full-lists-of-babies-first-names-1974-to-1979\u0026quot;,\r\u0026quot;https://www.nrscotland.gov.uk/statistics-and-data/statistics/statistics-by-theme/vital-events/names/babies-first-names/full-lists-of-babies-first-names-archive/full-lists-of-babies-first-names-1980-to-1989\u0026quot;,\r\u0026quot;https://www.nrscotland.gov.uk/statistics-and-data/statistics/statistics-by-theme/vital-events/names/babies-first-names/full-lists-of-babies-first-names-archive/full-lists-of-babies-first-names-1990-to-1999\u0026quot;,\r\u0026quot;https://www.nrscotland.gov.uk/statistics-and-data/statistics/statistics-by-theme/vital-events/names/babies-first-names/full-lists-of-babies-first-names-2000-to-2009\u0026quot;,\r\u0026quot;https://www.nrscotland.gov.uk/statistics-and-data/statistics/statistics-by-theme/vital-events/names/babies-first-names/full-lists-of-babies-first-names-2010-to-2014\u0026quot;)\rcsv_links \u0026lt;- map(pages, get_csv_links) %\u0026gt;% unlist()\r# Find the years for each csv file\ryr \u0026lt;- parse_number(str_extract(csv_links, \u0026quot;[0-9]+\\\\.csv\u0026quot;)) %\u0026gt;% if_else(is.na(.), 2018, .) %\u0026gt;% if_else(. \u0026lt; 1000, . + 2000, .)\rbabynames \u0026lt;- map2_df(csv_links, yr, read_babynames)\rbabynames2 \u0026lt;- babynames %\u0026gt;% mutate(decade = paste0(str_sub(year, 1, 3), \u0026quot;0s\u0026quot;)) %\u0026gt;% group_by(decade, gender, name) %\u0026gt;% summarise(number_of_babies = sum(number_of_babies)) %\u0026gt;% ungroup()\r# Save as rds so it can be quickly read in for the Shiny app\rsaveRDS(babynames2, \u0026quot;babynames.rds\u0026quot;)\r\rShiny App\rI created the Shiny app by amending the Shiny template available in RStudio as required – all fairly straightforward stuff and nothing fancy involved at all!\n# Shiny App: Scotland\u0026#39;s most popular babynames by decade\rlibrary(shiny)\rlibrary(dplyr)\rlibrary(ggplot2)\rlibrary(scales)\rlibrary(stringr)\rtheme_set(theme_minimal(base_size = 14))\rbabynames \u0026lt;- readRDS(\u0026quot;babynames.rds\u0026quot;)\rui \u0026lt;- fluidPage(\rtitlePanel(\u0026quot;Scotland\u0026#39;s Most Popular Babynames\u0026quot;),\rsidebarLayout(\rsidebarPanel(\rselectInput(\u0026quot;decade\u0026quot;, \u0026quot;Born in Decade:\u0026quot;,\rc(\u0026quot;1970s\u0026quot; = \u0026quot;1970s\u0026quot;,\r\u0026quot;1980s\u0026quot; = \u0026quot;1980s\u0026quot;,\r\u0026quot;1990s\u0026quot; = \u0026quot;1990s\u0026quot;,\r\u0026quot;2000s\u0026quot; = \u0026quot;2000s\u0026quot;,\r\u0026quot;2010s\u0026quot; = \u0026quot;2010s\u0026quot;)),\rradioButtons(\u0026quot;gender\u0026quot;, \u0026quot;Gender:\u0026quot;,\rc(\u0026quot;Boy\u0026quot; = \u0026quot;boy\u0026quot;,\r\u0026quot;Girl\u0026quot; = \u0026quot;girl\u0026quot;)),\rtextInput(\u0026quot;name_start\u0026quot;, \u0026quot;Name starts with\u0026quot;, \u0026quot;\u0026quot;),\r),\rmainPanel(\rplotOutput(\u0026quot;barPlot\u0026quot;)\r)\r)\r)\rserver \u0026lt;- function(input, output) {\routput$barPlot \u0026lt;- renderPlot({\rbabynames %\u0026gt;% filter(decade == input$decade,\rgender == input$gender,\rstr_detect(name, paste0(\u0026quot;^\u0026quot;, str_to_title(input$name_start)))) %\u0026gt;% arrange(desc(number_of_babies)) %\u0026gt;% mutate(perc = number_of_babies / sum(.$number_of_babies),\rname = factor(name, levels = rev(.$name))) %\u0026gt;% slice(1:20) %\u0026gt;% ggplot(aes(x = name, y = perc)) +\rgeom_bar(stat = \u0026quot;identity\u0026quot;, fill = \u0026quot;orange\u0026quot;, width = 0.7) +\rscale_y_continuous(labels = percent, limits = c(0, 1)) +\rlabs(x = NULL, y = NULL,\rcaption = \u0026quot;Source: National Records of Scotland\\nBabynames Data 1974-2018\u0026quot;) +\rcoord_flip() +\rtheme(panel.grid.major.y = element_blank())\r})\r}\rshinyApp(ui = ui, server = server)\r\r","date":1579910400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579910400,"objectID":"78ec440914d10d75d7f6f2a867a6a964","permalink":"https://alan-y.netlify.com/post/scot-babynames/","publishdate":"2020-01-25T00:00:00Z","relpermalink":"/post/scot-babynames/","section":"post","summary":"Downloading the data\rShiny App\r\r\rI recently saw this great post on Nathan Yau’s FlowingData website which guesses a person’s name based on what the name starts with. It also needs you to select a gender and a decade for when you were born before it can guess. Of course, it isn’t really a guess and is really just based on proportions calculated after restricting the data to what has been selected.","tags":["Shiny"],"title":"Scotland's Most Popular Babynames","type":"post"},{"authors":null,"categories":["R"],"content":"\r\rHow resources are grouped in CKAN\rInitialising ckanr and exploring groups of resources\rConnect to CKAN with dplyr and download from one resource\rDownloading all resources from a dataset\r\r\rIn previous blog posts (Hacking dbplyr for CKAN, Getting Open Data into R from CKAN) I have been exploring how to download data from the NHS Scotland open data platform into R. I’ve recently discovered that ROpenSci has a package to help with just this called ckanr and I wish I’d known about it earlier as it is really pretty handy! It certainly would’ve saved me some time if I’d know about it earlier but I suppose the positive I can take from it is that some of the functions in ckanr perform similar functions to the ideas I had so I guess that shows that my ideas are not completely wacky!\nHow resources are grouped in CKAN\rBefore we start testing out some code from ckanr, it is important to consider how resources (I am going to call the individual data items such as specific csv files hosted on CKAN as ‘resources’ but I am not sure if this is necessarily correct) on CKAN are grouped up as this helps to understand the design of some functions within ckanr. Resources can be grouped within ‘Datasets’, ‘Groups’, ‘Tags’ and ‘Themes’ (and possibly more that I don’t yet know about). Out of these, it is clear to me that ckanr offers functions for exploring resources by all of these groupings except themes (although I could also be mistaken about this). With this out of the way, let’s delve into some code.\nFigure: How resources are grouped in CKAN.\r\r\rInitialising ckanr and exploring groups of resources\rThere are, of course, many different data portals that are powered by CKAN so the first thing we need to do with the ckanr package is to tell it which URL to use by default with ckanr_setup(). Note that if you are working in a place where you need to use a proxy to connect R to the internet, this can also be set within ckanr_setup() using the proxy argument.\nlibrary(tidyverse)\rlibrary(ckanr)\rckanr_setup(url = \u0026quot;https://www.opendata.nhs.scot\u0026quot;)\rNow we can explore the groupings available in the NHS Scotland CKAN website with group_list(), package_list() and tag_list(); from the Figure above, these correspond to ‘Groups’, ‘datasets’ and ‘Tags’ respectively. Note that I only show 10 records in each case to keep things concise.\n# View available groups and packages/datasets\rgroup_list(as = \u0026quot;table\u0026quot;)[1:10]\r# [1] \u0026quot;acute-hospital-activity\u0026quot; \u0026quot;cancer\u0026quot; # [3] \u0026quot;child-health\u0026quot; \u0026quot;dental-care\u0026quot; # [5] \u0026quot;deprivation\u0026quot; \u0026quot;emergency-care\u0026quot; # [7] \u0026quot;general-practice\u0026quot; \u0026quot;geography\u0026quot; # [9] \u0026quot;hospital-activity\u0026quot; \u0026quot;infection-disease-and-virus-surveillance\u0026quot; package_list(as = \u0026quot;table\u0026quot;)[1:10]\r# [1] \u0026quot;18-weeks-referral-to-treatment\u0026quot; # [2] \u0026quot;27-30-month-review-statistics\u0026quot; # [3] \u0026quot;alcohol-related-hospital-statistics-scotland\u0026quot; # [4] \u0026quot;allied-health-professionals-musculoskeletal-waiting-times\u0026quot;\r# [5] \u0026quot;allied-health-professional-vacancies\u0026quot; # [6] \u0026quot;annual-cancer-incidence\u0026quot; # [7] \u0026quot;births-in-scottish-hospitals\u0026quot; # [8] \u0026quot;cancelled-planned-operations\u0026quot; # [9] \u0026quot;cancer-mortality\u0026quot; # [10] \u0026quot;cancer-waiting-times\u0026quot; tag_list(as = \u0026quot;table\u0026quot;)$name[1:10]\r# [1] \u0026quot;31 day\u0026quot; \u0026quot;62 day\u0026quot; # [3] \u0026quot;address\u0026quot; \u0026quot;adolescent\u0026quot; # [5] \u0026quot;adult\u0026quot; \u0026quot;age\u0026quot; # [7] \u0026quot;agenda for change\u0026quot; \u0026quot;agenda for change band\u0026quot;\r# [9] \u0026quot;ahp\u0026quot; \u0026quot;ailment\u0026quot; \rBeing able to see the names related to different groupings is useful if you want to download data from all resources in a particular group. I’ll give an example of doing this later but first I want to mimic some of the things I done in previous blog posts but using ckanr.\n\rConnect to CKAN with dplyr and download from one resource\rLet’s demonstrate downloading from one resource using the fairly small Patients Referred dataset within Allied Health Professionals - Musculoskeletal Waiting Times which has resource ID 3988df43-3516-4190-93da-16189db7329a. We start by using src_ckan() to create a connection to CKAN (similar to how you would do so for other non-CKAN databases). From there, you can download data in a similar way to when using dbplyr but using a CKAN resource ID instead of a database table name.\nckan \u0026lt;- src_ckan(\u0026quot;https://www.opendata.nhs.scot\u0026quot;)\rres_id \u0026lt;- \u0026quot;3988df43-3516-4190-93da-16189db7329a\u0026quot;\rdplyr::tbl(src = ckan$con, from = res_id) %\u0026gt;% as_tibble()\r# A tibble: 1,115 x 9\r# `_id` HBT2014 ReferralsPerOne~ `_full_text` Specialty NumberOfReferra~ NumberOfReferra~\r# \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; # 1 1 S08000~ 2890. \u0026#39;2015q3\u0026#39;:9 ~ All AHP ~ 8904 d # 2 2 S08000~ 411. \u0026#39;1267\u0026#39;:5 \u0026#39;2~ Chiropod~ 1267 \u0026quot;\u0026quot; # 3 3 S08000~ 94.4 \u0026#39;2015q3\u0026#39;:3 ~ Occupati~ 291 \u0026quot;\u0026quot; # 4 4 S08000~ 178. \u0026#39;178.17\u0026#39;:5 ~ Orthotics 549 \u0026quot;\u0026quot; # 5 5 S08000~ 2206. \u0026#39;2015q3\u0026#39;:2 ~ Physioth~ 6797 \u0026quot;\u0026quot; # 6 6 S08000~ 1530. \u0026#39;1472\u0026#39;:7 \u0026#39;1~ All AHP ~ 1472 d # 7 7 S08000~ 165. \u0026#39;159\u0026#39;:1 \u0026#39;16~ Orthotics 159 \u0026quot;\u0026quot; # 8 8 S08000~ 1365. \u0026#39;1313\u0026#39;:2 \u0026#39;1~ Physioth~ 1313 \u0026quot;\u0026quot; # 9 9 S08000~ 2562. \u0026#39;2015q3\u0026#39;:7 ~ All AHP ~ 3212 d # 10 10 S08000~ 197. \u0026#39;197.02\u0026#39;:1 ~ Chiropod~ 247 \u0026quot;\u0026quot; # # ... with 1,105 more rows, and 2 more variables: Quarter \u0026lt;chr\u0026gt;,\r# # ReferralsPerOneHundredThousandPopulationQF \u0026lt;chr\u0026gt;\rThe variables look like they’ve been downloaded in a bit of a random order and that _full_text variable seems to have appeared so this makes me think that ckanr is using SQL to download the data. This is easy enough to confirm.\ngetAnywhere(tbl.src_ckan)\rfunction (src, from, ..., name = NULL) {\rif (is.null(name)) {\rtbl_sql(\u0026quot;ckan\u0026quot;, src = src, from = sql(from), ...)\r}\relse {\rtbl_sql(subclass = \u0026quot;ckan\u0026quot;, src = src, from = sql(sprintf(\u0026quot;SELECT * FROM \\\u0026quot;%s\\\u0026quot;\u0026quot;, name)))\r}\r}\rNow let’s try combining this with some basic dplyr functions like select() and filter().\ndplyr::tbl(src = ckan$con, from = res_id) %\u0026gt;% select(Quarter, HBT2014) %\u0026gt;% filter(HBT2014 == \u0026quot;S08000015\u0026quot;) %\u0026gt;% as_tibble()\r# A tibble: 89 x 2\r# Quarter HBT2014 # \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; # 1 2015Q3 S08000015\r# 2 2015Q3 S08000015\r# 3 2015Q3 S08000015\r# 4 2015Q3 S08000015\r# 5 2015Q3 S08000015\r# 6 2015Q4 S08000015\r# 7 2015Q4 S08000015\r# 8 2015Q4 S08000015\r# 9 2015Q4 S08000015\r# 10 2015Q4 S08000015\r# # ... with 79 more rows\r# Warning messages:\r# 1: Translator is missing window variants of the following aggregate functions:\r# * all\r# * any\r# * cor\r# * cov\r# * paste\r# * sd\r# # 2: Translator is missing window variants of the following aggregate functions:\r# * all\r# * any\r# * cor\r# * cov\r# * paste\r# * sd\r# # 3: Translator is missing window variants of the following aggregate functions:\r# * all\r# * any\r# * cor\r# * cov\r# * paste\r# * sd\rWe get a long list of warnings explaining what you cannot do with the SQL translation available in ckanr but otherwise, works great!\n\rDownloading all resources from a dataset\rOften, a dataset on CKAN contains many resources related to the same thing. For example, the Consultant Vacancies dataset (remember you can see all available ‘Datasets’ using package_list()) contains different csv files for vacancies at different time points.\ncons_vac \u0026lt;- package_show(\u0026quot;consultant-vacancies\u0026quot;, as = \u0026quot;table\u0026quot;)$resources\rcons_vac %\u0026gt;% select(name, id)\r# name id\r# 1 Vacancies June 2019 16e27935-325c-471b-89dc-d41c84b3a744\r# 2 Vacancies March 2019 ca67b2a4-b2f3-4420-8b77-3771c53b01f4\r# 3 Vacancies December 2018 5da80103-4da8-4694-a8b5-2332dfc43e25\r# 4 Vacancies September 2018 91d7b780-f2cb-47fb-919f-1c165ed7d301\r# 5 Vacancies June 2018 e874f6f4-6cf5-402c-af1d-2d4f26cc669f\r# 6 Vacancies March 2018 415c2f86-db7c-4c12-9a64-0cd9cf0d9118\rNow if you extract the required resource IDs, you can download all of the datasets with some help from the fantastic purrr package.\nid_list \u0026lt;- cons_vac$id\r# Download each resource into a list item\rcons_vac_list \u0026lt;- map(id_list, ~as_tibble(dplyr::tbl(src = ckan$con, from = .x)))\r# Check how many variables in each resource\rmap_dbl(cons_vac_list, length)\r# [1] 12 12 12 14 15 12\r# Not all resources have the same structure\r# Check variable names for a couple that differ\rmap(cons_vac_list[3:4], names)\r# [[1]]\r# [1] \u0026quot;WorkforceRegionGrouping\u0026quot; \u0026quot;HB2014\u0026quot; # [3] \u0026quot;HB2014QF\u0026quot; \u0026quot;TotalVacancies\u0026quot; # [5] \u0026quot;_full_text\u0026quot; \u0026quot;Specialty\u0026quot; # [7] \u0026quot;VacanciesGreater6Months\u0026quot; \u0026quot;Date\u0026quot; # [9] \u0026quot;SpecialtyQF\u0026quot; \u0026quot;_id\u0026quot; # [11] \u0026quot;Establishment\u0026quot; \u0026quot;StaffInPost\u0026quot; # # [[2]]\r# [1] \u0026quot;WorkforceRegionGrouping\u0026quot; \u0026quot;HB2014\u0026quot; # [3] \u0026quot;HB2014QF\u0026quot; \u0026quot;TotalVacancies\u0026quot; # [5] \u0026quot;TotalVacanciesQF\u0026quot; \u0026quot;_full_text\u0026quot; # [7] \u0026quot;Specialty\u0026quot; \u0026quot;EstablishmentQF\u0026quot; # [9] \u0026quot;VacanciesGreater6Months\u0026quot; \u0026quot;Date\u0026quot; # [11] \u0026quot;SpecialtyQF\u0026quot; \u0026quot;_id\u0026quot; # [13] \u0026quot;Establishment\u0026quot; \u0026quot;StaffInPost\u0026quot;\r# TotalVacanciesQF and EstablishmentQF not in resource 3 but are in resource 4\r# Combine just the first 3 resources which look like they all have the same structure\rbind_rows(cons_vac_list[1:3])\r# A tibble: 1,822 x 12\r# WorkforceRegion~ HB2014 HB2014QF TotalVacancies `_full_text`\r# \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; # 1 National Bodies~ SB0806 \u0026quot;\u0026quot; 0 \u0026#39;0\u0026#39;:9 \u0026#39;1.4\u0026#39;~\r# 2 Scotland S9200~ d 0 \u0026#39;0\u0026#39;:5 \u0026#39;2019~\r# 3 Scotland S9200~ d 0 \u0026#39;0\u0026#39;:5 \u0026#39;2.1\u0026#39;~\r# 4 National Bodies~ SB0807 \u0026quot;\u0026quot; 0 \u0026#39;0\u0026#39;:9 \u0026#39;0.3\u0026#39;~\r# 5 North S0800~ \u0026quot;\u0026quot; 0 \u0026#39;0\u0026#39;:5 \u0026#39;0.1\u0026#39;~\r# 6 National Bodies~ SB0808 \u0026quot;\u0026quot; 0 \u0026#39;0\u0026#39;:9 \u0026#39;1.2\u0026#39;~\r# 7 East S0800~ \u0026quot;\u0026quot; 0 \u0026#39;0\u0026#39;:3 \u0026#39;12.1~\r# 8 East S0800~ \u0026quot;\u0026quot; 0 \u0026#39;0\u0026#39;:3 \u0026#39;1.7\u0026#39;~\r# 9 National Bodies~ SB0804 \u0026quot;\u0026quot; 0 \u0026#39;0\u0026#39;:1 \u0026#39;1\u0026#39;:9~\r# 10 National Bodies~ SB0807 \u0026quot;\u0026quot; 0 \u0026#39;0\u0026#39;:9 \u0026#39;0.4\u0026#39;~\r# ... with 1,812 more rows, and 7 more variables: Specialty \u0026lt;chr\u0026gt;,\r# VacanciesGreater6Months \u0026lt;dbl\u0026gt;, Date \u0026lt;dbl\u0026gt;, SpecialtyQF \u0026lt;chr\u0026gt;,\r# `_id` \u0026lt;chr\u0026gt;, Establishment \u0026lt;dbl\u0026gt;, StaffInPost \u0026lt;dbl\u0026gt;\rSo that is a basic workflow using ckanr alongside functions from purrr for combining related resources into one dataset. I’ve also presented some ways of checking consistency in the structure of those datasets (an essential step when trying to do something like this) and in this case, not all of the datasets were the same so I just combined the most recent 3 datasets for consultant vacancies at the end for simplicity here; in reality you might want to look at ways to make all of the data consistent first and then combine them up but I’ll leave that data wrangling exercise up to the interested reader.\nMy final verdict: ckanr is definitely recommended for working with data from CKAN!\n\r","date":1573516800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573516800,"objectID":"c4da2972839499f2d89960a8021c7a92","permalink":"https://alan-y.netlify.com/post/trying-ckanr/","publishdate":"2019-11-12T00:00:00Z","relpermalink":"/post/trying-ckanr/","section":"post","summary":"How resources are grouped in CKAN\rInitialising ckanr and exploring groups of resources\rConnect to CKAN with dplyr and download from one resource\rDownloading all resources from a dataset\r\r\rIn previous blog posts (Hacking dbplyr for CKAN, Getting Open Data into R from CKAN) I have been exploring how to download data from the NHS Scotland open data platform into R. I’ve recently discovered that ROpenSci has a package to help with just this called ckanr and I wish I’d known about it earlier as it is really pretty handy!","tags":["API","open-data"],"title":"Trying the ckanr Package","type":"post"},{"authors":["Matthew Hickman","John Dillon","Lawrie Elliott","Daniela De Angelis","Peter Vickerman","Graham Foster","Peter Donnan","Ann Eriksen","Paul Flowers","David Goldberg","William Hollingworth","Samreen Ijaz","David Liddell","Sema Mandal","Natasha Martin","Lewis Beer","Kate Drysdale","Hannah Fraser","Rachel Glass","Lesley Graham","Rory Gunson","Emma Hamilton","Helen Harris","Magdalena Harris","Ross Harris","Ellen Heinsbroek","Vivian Hope","Jeremy Horwood","Sarah Karen Inglis","Hamish Innes","Athene Lane","Jade Meadows","Andrew McAuley","Chris Metcalfe","Stephanie Migchelsen","Alex Murray","Gareth Myring","Norah Palmateer","Anne Presanis","Andrew Radley","Mary Ramsay","Pantelis Samartsidis","Ruth Simmons","Katy Sinka","Gabriele Vojt","Zoe Ward","David Whiteley","Alan Yeung","Sharon Hutchinson"],"categories":null,"content":"","date":1569283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569283200,"objectID":"1840d7847e4d27acaeec1efbf85151d8","permalink":"https://alan-y.netlify.com/publication/journal-article_hcv_epitope_protocol/","publishdate":"2019-09-24T00:00:00Z","relpermalink":"/publication/journal-article_hcv_epitope_protocol/","section":"publication","summary":"This is a protocol paper for a natural experiment that looks at the population impact of scaling up hepatitis C treatment with direct acting antiviral treatments as a way to prevent disease transmission and reduce prevalence/incidence among people who inject drugs.","tags":["HCV","PWID"],"title":"Evaluating the population impact of hepatitis C direct acting antiviral treatment as prevention for people who inject drugs (EPIToPe) – a natural experiment (protocol)","type":"publication"},{"authors":null,"categories":["R"],"content":"\r\rA Learning Exercise\rWorkflow\r\r\rI created my first ever R package and got it released onto CRAN in March 2019. It’s taken me a while to get round to actually writing about this which tells me that despite many years of trying to overcome procrastination, I’m obviously still not there! The package is actually an RStudio addin called objectremover that helps you to quickly remove objects stored in memory (specifically objects saved in the Global environment) within an R session. The main features include removing objects by\n\rStarting pattern of object name\rEnding pattern of object name\rRegular expression\rObject type (dataframe, function and other)\r\rThis is a quick demo of objectremover in action.\nI made sure to include a couple of safety features to help ensure that you don’t remove objects by mistake. Firstly, it displays what objects will be removed based on the options you’ve selected in real-time and when you click ‘Done’, another warning popup box appears to get a second confirmation that you want to remove these objects. I put this warning popup in as you could remove all saved objects (perhaps by mistake) if, for example, you use a regular expression with no pattern.\nI recently also got objectremover added to the list of addins started and maintained by Dean Attali.\nA Learning Exercise\rCreating this package was largely a learning exercise for me and I really learned loads in the process. To create the package, I tried the usethis package for the first time to help get various things set up. When I got to the stage where the package was mostly developed, I tested that the package builds successfully in various operating systems and R versions using Travis CI and the R-hub builder (again, this was the first time I’ve used these tools). A continous integration service like Travis is useful for ensuring that the package still builds properly whenever you make changes to the package and push onto Github. I even had a go at creating a hex sticker for the package (with the help of the hexsticker package) and anybody that knows me at all knows that this isn’t the sort of thing I’m good at! But I’m happy I gave it a go as that’s the only way to get better.\nWhen I submitted to CRAN, the package got knocked back a few times but I followed the wise advice of Hadley Wickham to not take any criticism personally (particularly as the CRAN maintainers are very busy people and have a hard job) and just tackled all the obstacles in a respectful manner. This advice probably applies to many things in life beyond building R packages so I try to follow this approach as much as humanly possible (but as I am actually human, it stands to reason that I still fail in this regard – and more often than I’d like as well unfortunately!).\n\rWorkflow\rThe idea for the package came about as I tend to create a lot of temporary objects in R as I work through analyses and I just wanted a quick way to remove these objects. I often call these objects with names starting with the letter ‘z’ so that they will be easy to spot. This was something I learned from my former PhD supervisor and has actually become pretty invaluable as naming things is something that can sometimes cause me more stress and take up more energy than you would imagine for something this basic and fundamental! So having a way of removing the need for this decision-making helps to focus on solving problems quickly rather than putting energy into things such as naming objects.\nHaving said this, I do always go through my code carefully after I’ve solved the problems I’m working on and tidy the script up to make sure I can understand everything I’ve done. This process is sometimes known as code refactoring. It is something that is sometimes overlooked but is really important for ensuring that you and others can better understand what a script is doing. This quote sums up the benefits pretty well.\n\rBy continuously improving the design of code, we make it easier and easier to work with. This is in sharp contrast to what typically happens: little refactoring and a great deal of attention paid to expediently adding new features. If you get into the hygienic habit of refactoring continuously, you’ll find that it is easier to extend and maintain code.\n— Joshua Kerievsky\n\rPart of what I do for this includes putting in section breaks into my script (in RStudio, the shortcut to do this is ctrl+shift+R) to split things into more manageable blocks. I’ll also give meaningful names to objects that I do want to track, particularly for longer projects. For example, there may be several data processing stages involved in going from a raw dataset up to the dataset you use for analysis. I will usually create a number of temporary objects (beginning with ‘z’) that help me get to the analysis dataset (often via various joins between datasets). In this case, the raw and analysis datasets would get meaningful names and the temporary objects could be removed. At the end, I may save the raw and analysis datasets into an R workspace (or as RDS format) that can be easily loaded into scripts created for other parts of a long project.\nAnyway that’s just an example of a workflow that I sometimes use and find pretty efficient for long projects. I’m sure there are many other great ways to work efficiently in creating outputs for long projects so if you know of some, please let me know as I always like to hear about ways to work efficiently in R. Oh and of course, I hope some people find objectremover useful!\n\r","date":1565568000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565568000,"objectID":"04d847e5ca608b8a74d4baa67c346977","permalink":"https://alan-y.netlify.com/post/objectremover-rstudio-addin/","publishdate":"2019-08-12T00:00:00Z","relpermalink":"/post/objectremover-rstudio-addin/","section":"post","summary":"A Learning Exercise\rWorkflow\r\r\rI created my first ever R package and got it released onto CRAN in March 2019. It’s taken me a while to get round to actually writing about this which tells me that despite many years of trying to overcome procrastination, I’m obviously still not there! The package is actually an RStudio addin called objectremover that helps you to quickly remove objects stored in memory (specifically objects saved in the Global environment) within an R session.","tags":["RStudio","Addins"],"title":"objectremover RStudio Addin","type":"post"},{"authors":null,"categories":["R"],"content":"\r\rAim\rCreate a dummy database\rTest dbplyr’s SQL translation\rModify dbplyr’s SQL translation\rTesting the dbplyr hack\rConcluding notes\r\r\rAt the end of my first post on CKAN discussing how to use the CKAN API to extract data from the NHS open data platform directly into R, I talked about how it would be neat to write some wrapper functions to make this process a little simpler. Well another idea came to my mind that I think would be even more cool to get working – would it be possible to hack the SQL translation from dbplyr to make it work effectively for extracting data from CKAN?\nJust for background info, dbplyr is a package that lets you use dplyr code to interact with databases (a database backend for dplyr), which saves you learning SQL (I still recommend that people learn SQL though as it is likely to come in useful anyway!). One of the conveniences of using dbplyr is that you can take advantage of some of the dplyr’s helper functions (e.g starts_with(), ends_with()) to assist with tasks such as selecting variables – a task which can be quite tedious in SQL as you must list all of the variables you want to extract.\nAim\rThe aim here is not to be too ambitious for the hack but to just get the select() and filter() functions to work for this hack. My feeling is that if you can get these features working, then you should be able to easily extract just the variables and rows of data you want from CKAN using dplyr code and this is hopefully sufficient for most people. This should be a good starting point for helping people to not download entire datasets when they don’t need to. Anyway, with the brief intro out of the way, let’s see if we can get this little hack working!\n\rCreate a dummy database\rSince datasets held on CKAN will not be identified by dbplyr as a ‘database’, we have to create a sort of dummy database within R so that it identifies a CKAN resource as a database. To do this, I created a function called ckan_nhs_init(). This function simply downloads one row of data from a CKAN resource and stores this in an in-memory SQLite database. The key thing here is that extracting one row of data will give us a list of all the variable names for the dummy database. In the code below, please note that I have loaded some required packages to make the function work (if it turns out later that this idea is actually not bad, I’ll write up the code more appropriately for packaging up).\nlibrary(tidyverse)\rlibrary(dbplyr)\rlibrary(httr)\rlibrary(jsonlite)\rckan_nhs_init \u0026lt;- function(id) {\rurl \u0026lt;- paste0(\u0026quot;https://www.opendata.nhs.scot/api/3/action/\u0026quot;,\r\u0026quot;datastore_search?\u0026quot;,\r\u0026quot;resource_id=\u0026quot;, id,\r\u0026quot;\u0026amp;limit=1\u0026quot;)\rstatus \u0026lt;- status_code(GET(url))\rstopifnot(str_detect(status, \u0026quot;^2\u0026quot;))\rdf \u0026lt;- fromJSON(url)$result$records\rcopy_to(src_memdb(), df, name = id, overwrite = TRUE)\r}\r\rTest dbplyr’s SQL translation\rAfter creating a dummy database (and thus, successfully fooling dbplyr into believing that a CKAN resource is a database), we have to make some modifications to the SQL translation from dbplyr so that the SQL query actually works for interacting with the CKAN API. First let’s test a couple of simple queries to see what dbplyr’s SQL translation produces. We’ll use the Data Zone (2011) Population Estimates dataset (resource ID c505f490-c201-44bd-abd1-1bd7a64285ee) for testing throughout this post. So what does the SQL translation look like when we just use select()?\nid \u0026lt;- \u0026quot;c505f490-c201-44bd-abd1-1bd7a64285ee\u0026quot;\rckan_nhs_init(id) %\u0026gt;% select(Year, DZ2011) %\u0026gt;% show_query()\r# \u0026lt;SQL\u0026gt;\r# SELECT `Year`, `DZ2011`\r# FROM `c505f490-c201-44bd-abd1-1bd7a64285ee`\rImmediately I can see that the CKAN API isn’t going to like those backticks (`) around the variable and database names so we’ll have to remove them. We’ll also have to remove the line breaks (\\n). Now let’s test the SQL translation for filter().\nckan_nhs_init(id) %\u0026gt;%\rfilter(Year == 2011L)\r# \u0026lt;SQL\u0026gt;\r# SELECT *\r# FROM `c505f490-c201-44bd-abd1-1bd7a64285ee`\r# WHERE (`Year` = 2011)\rNow I can see that the CKAN API isn’t going to like those brackets around the WHERE statement so we’ll also have to remove them. Lastly let’s test the translation for a select() combined with a filter().\n# select() and then filter()\rckan_nhs_init(id) %\u0026gt;% select(Year, DZ2011) %\u0026gt;% filter(Year == 2011L) %\u0026gt;% show_query()\r# \u0026lt;SQL\u0026gt;\r# SELECT *\r# FROM (SELECT `Year`, `DZ2011`\r# FROM `c505f490-c201-44bd-abd1-1bd7a64285ee`)\r# WHERE (`Year` = 2011)\r# filter() and then select()\rckan_nhs_init(id) %\u0026gt;% filter(Year == 2011L) %\u0026gt;% select(Year, DZ2011) %\u0026gt;% show_query()\r# \u0026lt;SQL\u0026gt;\r# SELECT `Year`, `DZ2011`\r# FROM `c505f490-c201-44bd-abd1-1bd7a64285ee`\r# WHERE (`Year` = 2011)\rFrom here, we can see that when using filter() and then select(), the query looks fairly concise but when using select() and then filter(), we have some work to do to remove the unnecessary SELECT * FROM at the beginning (note that this SQL is perfectly good normally but it won’t be for the CKAN API). In any case, I think we now have all the information we need to modify dbplyr’s SQL translation to make it work for CKAN.\n\rModify dbplyr’s SQL translation\rUsing the information just attained, I created the ckan_nhs_extract() function to make the required modifications to the SQL translation. Note that in the function I use sql_render() instead of show_query() as I need the SQL query as a string variable in R rather than just printed to the console. I’ve also added a warning message using cat() to warn the user that some queries may take a while.\nckan_nhs_extract \u0026lt;- function(db_qry) {\rdb_qry \u0026lt;- sql_render(db_qry) %\u0026gt;%\rstr_replace_all(\u0026quot;`\u0026quot;, \u0026#39;\u0026quot;\u0026#39;) %\u0026gt;%\rstr_replace_all(\u0026quot;\\n\u0026quot;, \u0026quot; \u0026quot;)\r# Check if there is more than one SELECT statement\rn_select \u0026lt;- str_count(db_qry, \u0026quot;SELECT\u0026quot;)\r# Remove unnecessary SELECT statement if needed\rif (n_select \u0026gt; 1) {\rdb_qry \u0026lt;- str_remove(db_qry, \u0026quot;^(SELECT \\\\* FROM )\u0026quot;)\r}\rdb_qry \u0026lt;- str_remove_all(db_qry, \u0026quot;\\\\(|\\\\)\u0026quot;)\rdb_qry \u0026lt;- URLencode(db_qry)\rdb_qry \u0026lt;- paste0(\u0026quot;https://www.opendata.nhs.scot/api/3/action/\u0026quot;,\r\u0026quot;datastore_search_sql?\u0026quot;,\r\u0026quot;sql=\u0026quot;,\rdb_qry)\rcat(\u0026quot;Extracting: this may take a while\\n\\n\u0026quot;)\ras_tibble(fromJSON(db_qry)$result$records)\r}\r\rTesting the dbplyr hack\rTo test this hack, we will make a simple query using select() and then filter() which is the more complicated scenario.\nckan_nhs_init(id) %\u0026gt;%\rselect(Year, DZ2011) %\u0026gt;%\rfilter(Year == 2011, DZ2011 == \u0026quot;S92000003\u0026quot;) %\u0026gt;%\rckan_nhs_extract()\r# Extracting: this may take a while\r# # # A tibble: 2 x 2\r# DZ2011 Year # \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;\r# 1 S92000003 2011 # 2 S92000003 2011 \rThis produces the desired result so it’s a job well done for now!\n\rConcluding notes\rThis hack needs a lot more testing as there are probably lots of things that could potentially break it (but obviously I’m hoping not!). There’s also a niggling issue in that I don’t yet know how to remove an in-memory SQLite database from R (or whether this is even possible) which I guess should be done after you’ve extracted the data you need just to clean things up nicely in R. But in saying that, it likely isn’t a big issue as src_memdb() has been specifically designed for creating a temporary in-memory database so everything will of course, be cleaned up after you exit your R session anyway. If this hack turns out to be useful and doesn’t break too easily, I may put in a bit of effort to package it up onto Github later. Please let me know what you think if you ever use it!\n\r","date":1562457600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562457600,"objectID":"faddaf0ad6c857da1cd63add5253adea","permalink":"https://alan-y.netlify.com/post/ckan-dbplyr/","publishdate":"2019-07-07T00:00:00Z","relpermalink":"/post/ckan-dbplyr/","section":"post","summary":"Aim\rCreate a dummy database\rTest dbplyr’s SQL translation\rModify dbplyr’s SQL translation\rTesting the dbplyr hack\rConcluding notes\r\r\rAt the end of my first post on CKAN discussing how to use the CKAN API to extract data from the NHS open data platform directly into R, I talked about how it would be neat to write some wrapper functions to make this process a little simpler.","tags":["API","open-data"],"title":"Hacking dbplyr for CKAN","type":"post"},{"authors":null,"categories":["R"],"content":"\r\rPreamble\rOpen Data in Scotland\rQuerying CKAN\r\rQuerying with Custom JSON\rQuerying with SQL\r\rConclusions and Further Ideas\r\r\rPreamble\rI’ve got lots of rough pieces of R code written as I’ve been exploring/testing various things in the past. A lot of this is currently stored in a pretty disorganised fashion so I thought it would be a good idea to start writing some of these up into blog posts – at the very least, this should make it easier for me to find things later! To start with, I am writing a short post here about how to download data from the CKAN API directly into R – CKAN is an open source data portal platform (basically a tool for making open data websites) and the reason I became interested in it is because this is the platform that NHS Scotland has chosen to host their open data.\n\rOpen Data in Scotland\rIt is becoming increasingly important for public sector organisations to make their data open. In Scotland, this is clear from the Scottish Government’s open data strategy. They believe that providing open data not only aids transparency, but should also result in wider social and economic benefits in the long run. My opinion generally matches this but I feel that one thing to be wary of is the potential for users to interpret data incorrectly so therefore I feel it is absolutely crucial to provide as much information as possible about the datasets (i.e. provide comprehensive metadata). On balance, the upsides of providing open data should definitely outweigh the downsides, particularly if pragmatic steps are taken to mitigate potential issues such as using the data incorrectly which can lead to producing misleading analyses.\nMuch work needs to be done on the open data front in Scotland. The level of open data provision by organisations in Scotland is currently lagging behind other parts of the UK in terms of the number of open datasets available but also in terms of how up-to-date the datasets provided are (see this blog post written in February 2019 by Ian Watt for more on this). Encouragingly though the situation is improving. NHS Scotland is contributing to this improvement by launching their open data platform (which I will simply refer to as CKAN from hereafter). All of the data held on this platform is licensed under the UK Open Government Licence (OGL). What you can and can’t do with the data is well described there in detail but to me, the gist of it seems to be that you can more or less do what you want with the data as long as you properly acknowledge the source (please read the detail though rather than just taking my word for it!).\n\rQuerying CKAN\rEach dataset held on CKAN is assigned a resource ID which uniquely identifies it and to make a query on a particular dataset, you will need to know this. The resource ID can be found in the Additional Information section once you are on a dataset’s page. As an example, let’s say we are interested in downloading data about Data Zone (2011) Population Estimates (this gives data on population estimates for all 6,976 data zones (2011) in Scotland from 2011 to 2017), then, the resource ID for this is c505f490-c201-44bd-abd1-1bd7a64285ee. Note that this resource ID is also contained in the weblink for the dataset so you do not actually need to navigate down to the Additional Information section to find it.\nThere are three querying methods that you can use which are Custom JSON, SQL and HTSQL. Each of these methods supports different features but I will only discuss some basic querying using Custom JSON and SQL here. The basic idea of making a query on the CKAN API is that you build this into the web URL and the form of the URL will depend on the querying method you decide to use.\nQuerying with Custom JSON\rFor Custom JSON, the URL should take the form\nhttps://www.opendata.nhs.scot/api/3/action/ +\ndatastore_search? +\nresource_id=long-id-number +\n\u0026amp;your-CustomJSON-query\nLet’s test this in R by downloading the Data Zone (2011) Population Estimates dataset. Two R packages are required to help with this: httr and jsonlite. The httr package is needed to work with the API and jsonlite is needed to convert the downloaded JSON data into an R object. I will also load the tidyverse package for good measure!\nlibrary(httr)\rlibrary(jsonlite)\rlibrary(tidyverse)\rurl \u0026lt;- paste0(\u0026quot;https://www.opendata.nhs.scot/api/3/action/\u0026quot;,\r\u0026quot;datastore_search?\u0026quot;,\r\u0026quot;resource_id=c505f490-c201-44bd-abd1-1bd7a64285ee\u0026quot;)\rpage \u0026lt;- GET(url) # API request\rstatus_code(page) # # Check that the call is successful\r# [1] 200\r# This means it was successful\r# Status codes:\r# 1XX - Informational\r# 2XX - Success!\r# 3XX - Client Error (something’s not right on your end)\r# 4XX - Server Error (something’s not right on their end)\r# Download the JSON data and convert to an R list\rdz2011_list \u0026lt;- fromJSON(url)\r# Extract the actual data from the list\rdz2011 \u0026lt;- dz2011_list$result$records\rglimpse(dz2011, width = 50)\r# Observations: 100\r# Variables: 97\r# $ `_id` \u0026lt;int\u0026gt; 178, 179, 180, 181, 182, 18...\r# $ Year \u0026lt;int\u0026gt; 2011, 2011, 2011, 2011, 201...\r# $ DZ2011 \u0026lt;chr\u0026gt; \u0026quot;S01006593\u0026quot;, \u0026quot;S01006594\u0026quot;, \u0026quot;...\r# $ DZ2011QF \u0026lt;chr\u0026gt; \u0026quot; \u0026quot;, \u0026quot; \u0026quot;, \u0026quot; \u0026quot;, \u0026quot; \u0026quot;, \u0026quot; \u0026quot;, \u0026quot; ...\r# $ Sex \u0026lt;chr\u0026gt; \u0026quot;Female\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Female\u0026quot;,...\r# $ AllAges \u0026lt;int\u0026gt; 325, 252, 296, 478, 454, 36...\r# $ Age0 \u0026lt;int\u0026gt; 2, 2, 6, 8, 2, 4, 4, 3, 1, ...\r# $ Age1 \u0026lt;int\u0026gt; 4, 4, 0, 3, 4, 2, 6, 1, 3, ...\r# $ Age2 \u0026lt;int\u0026gt; 2, 2, 3, 1, 4, 4, 4, 1, 2, ...\r# $ Age3 \u0026lt;int\u0026gt; 6, 1, 0, 5, 1, 4, 4, 2, 1, ...\rNote that when I used the glimpse() function, I’ve only shown the first 10 variables as this dataset contains 97 variables and I wanted to keep the output fairly concise (I will do the same for the rest of the examples in this post where appropriate). A further thing to note is that the default setting using Custom JSON is to download only the first 100 records from the dataset which you can also see from the number of observations in the output of glimpse(); if you want to download more rows than this you need to explicitly set this in the query. For example, if you wanted the first 150 rows you can simply add this query into the URL.\nurl_150r \u0026lt;- paste0(url, \u0026quot;\u0026amp;limit=150\u0026quot;)\rdz2011_list_150r \u0026lt;- fromJSON(url_150r)\rdz2011_150r \u0026lt;- dz2011_list_150r$result$records\rglimpse(dz2011_150r, width = 50)\r# Observations: 150\r# Variables: 97\r# $ `_id` \u0026lt;int\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 1...\r# $ Year \u0026lt;int\u0026gt; 2011, 2011, 2011, 2011, 2011...\r# $ DZ2011 \u0026lt;chr\u0026gt; \u0026quot;S92000003\u0026quot;, \u0026quot;S92000003\u0026quot;, \u0026quot;S...\r# $ DZ2011QF \u0026lt;chr\u0026gt; \u0026quot;d\u0026quot;, \u0026quot;d\u0026quot;, \u0026quot; \u0026quot;, \u0026quot; \u0026quot;, \u0026quot; \u0026quot;, \u0026quot; \u0026quot;...\r# $ Sex \u0026lt;chr\u0026gt; \u0026quot;Male\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;F...\r# $ AllAges \u0026lt;int\u0026gt; 2570300, 2729600, 419, 463, ...\r# $ Age0 \u0026lt;int\u0026gt; 30877, 29488, 3, 10, 4, 4, 9...\r# $ Age1 \u0026lt;int\u0026gt; 29388, 28294, 5, 8, 6, 0, 3,...\r# $ Age2 \u0026lt;int\u0026gt; 30189, 29190, 5, 7, 1, 3, 4,...\r# $ Age3 \u0026lt;int\u0026gt; 30173, 29061, 5, 7, 5, 6, 1,...\rI am not yet sure how to set up the query in Custom JSON so that it just downloads all the records but I suppose you could just set the limit to a very high number that you know will cover everything.\n\rQuerying with SQL\rTo query with SQL you will obviously need to know how to write SQL queries. I won’t be discussing SQL queries here as the focus is on using the CKAN API. For SQL, the URL should take the form\nhttps://www.opendata.nhs.scot/api/3/action/ +\ndatastore_search_sql? +\nsql= +\nyour-SQL-query\nThere are a couple of quirks about how to make SQL query work in R. You need to enclose the name of the resource ID in speech marks (“resource-ID”) so if like me, your default method of creating strings is to use speech marks rather than the apostrophe character (’), you will need to escape the speech mark using the backslash (\\“). Similarly, you need to enclose other things such as variable names in speech marks when making more complicated queries. You also need to percent-encode your special characters to make them work as a URL – luckily the URLencode() function makes this easy!\n# Download the whole dataset using a SQL query\rurl_sql \u0026lt;- paste0(\u0026quot;https://www.opendata.nhs.scot/api/3/action/\u0026quot;,\r\u0026quot;datastore_search_sql?\u0026quot;,\r\u0026quot;sql=\u0026quot;,\rURLencode(\u0026quot;SELECT * from \\\u0026quot;c505f490-c201-44bd-abd1-1bd7a64285ee\\\u0026quot;\u0026quot;))\rdz2011_list_sql \u0026lt;- fromJSON(url_sql)\rdz2011_sql \u0026lt;- dz2011_list_sql$result$records\rglimpse(dz2011_sql, width = 50)\r# Observations: 97,678\r# Variables: 98\r# $ Age28 \u0026lt;chr\u0026gt; \u0026quot;33649\u0026quot;, \u0026quot;35002\u0026quot;, \u0026quot;12\u0026quot;, \u0026quot;6\u0026quot;, \u0026quot;6...\r# $ Age29 \u0026lt;chr\u0026gt; \u0026quot;33865\u0026quot;, \u0026quot;35698\u0026quot;, \u0026quot;8\u0026quot;, \u0026quot;10\u0026quot;, \u0026quot;1...\r# $ Age26 \u0026lt;chr\u0026gt; \u0026quot;34410\u0026quot;, \u0026quot;35491\u0026quot;, \u0026quot;6\u0026quot;, \u0026quot;11\u0026quot;, \u0026quot;1...\r# $ Age27 \u0026lt;chr\u0026gt; \u0026quot;33302\u0026quot;, \u0026quot;34274\u0026quot;, \u0026quot;11\u0026quot;, \u0026quot;7\u0026quot;, \u0026quot;5...\r# $ Age24 \u0026lt;chr\u0026gt; \u0026quot;35129\u0026quot;, \u0026quot;36098\u0026quot;, \u0026quot;9\u0026quot;, \u0026quot;7\u0026quot;, \u0026quot;1\u0026quot;...\r# $ Age25 \u0026lt;chr\u0026gt; \u0026quot;35166\u0026quot;, \u0026quot;35492\u0026quot;, \u0026quot;6\u0026quot;, \u0026quot;6\u0026quot;, \u0026quot;2\u0026quot;...\r# $ Age22 \u0026lt;chr\u0026gt; \u0026quot;36117\u0026quot;, \u0026quot;36450\u0026quot;, \u0026quot;6\u0026quot;, \u0026quot;3\u0026quot;, \u0026quot;3\u0026quot;...\r# $ Age23 \u0026lt;chr\u0026gt; \u0026quot;36710\u0026quot;, \u0026quot;37038\u0026quot;, \u0026quot;4\u0026quot;, \u0026quot;3\u0026quot;, \u0026quot;3\u0026quot;...\r# $ Age20 \u0026lt;chr\u0026gt; \u0026quot;37785\u0026quot;, \u0026quot;37513\u0026quot;, \u0026quot;5\u0026quot;, \u0026quot;3\u0026quot;, \u0026quot;6\u0026quot;...\r# $ Age21 \u0026lt;chr\u0026gt; \u0026quot;36354\u0026quot;, \u0026quot;36386\u0026quot;, \u0026quot;3\u0026quot;, \u0026quot;9\u0026quot;, \u0026quot;4\u0026quot;...\rNotice that when you use SQL to query CKAN, all 97,678 records are downloaded from the dataset (unless you explicitly tell it not to) so therefore, the query took much longer to finish. The data has been extracted but with a couple of strange issues. The variables are in a weird order and there are 98 variables here instead of the 97 we got previously – it seems to have extracted a variable called _full_text. I don’t know why it does this but I suppose these issues can be sorted out easily enough with some dplyr. Let’s also make a query to download just one variable to demonstrate how to write a marginally more complicated SQL query.\n# Download only the DZ2011 variable\rurl_sql_1v \u0026lt;- paste0(\u0026quot;https://www.opendata.nhs.scot/api/3/action/\u0026quot;,\r\u0026quot;datastore_search_sql?\u0026quot;,\r\u0026quot;sql=\u0026quot;,\rURLencode(\u0026quot;SELECT \\\u0026quot;DZ2011\\\u0026quot; from \\\u0026quot;c505f490-c201-44bd-abd1-1bd7a64285ee\\\u0026quot;\u0026quot;))\rdz2011_list_1v \u0026lt;- fromJSON(url_sql_1v)\rdz2011_1v \u0026lt;- dz2011_list_1v$result$records\rglimpse(dz2011_1v, width = 50)\r# Observations: 97,678\r# Variables: 1\r# $ DZ2011 \u0026lt;chr\u0026gt; \u0026quot;S92000003\u0026quot;, \u0026quot;S92000003\u0026quot;, \u0026quot;S01...\rNo issues with this query and everything was extracted as expected.\n\r\rConclusions and Further Ideas\rThis post has given a little bit of background to open data in Scotland as well as an introduction to downloading NHS Scotland open data directly into R using simple queries with the CKAN API but there are, of course, much fancier things that you can do when constructing queries (e.g. joins on datasets using SQL or using the API to search CKAN for datasets with a particular tag) which I’ve not covered. I may cover some of these in a future post but for now, the interested reader can trawl through the CKAN user guide to find out more about features like that! As a final point, I think it would be neat to write some wrapper functions in R to make it easier to make queries to CKAN (this could even be packaged up) – it might be a future project! I envision that this would work similarly to the opendatascot package which has been built to help with extracting data from statistics.gov.scot. Anyway that’s for another day.\n\r","date":1559692800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559692800,"objectID":"7149297561a91e05356ef3976d28d8f9","permalink":"https://alan-y.netlify.com/post/ckan-api/","publishdate":"2019-06-05T00:00:00Z","relpermalink":"/post/ckan-api/","section":"post","summary":"Preamble\rOpen Data in Scotland\rQuerying CKAN\r\rQuerying with Custom JSON\rQuerying with SQL\r\rConclusions and Further Ideas\r\r\rPreamble\rI’ve got lots of rough pieces of R code written as I’ve been exploring/testing various things in the past. A lot of this is currently stored in a pretty disorganised fashion so I thought it would be a good idea to start writing some of these up into blog posts – at the very least, this should make it easier for me to find things later!","tags":["open-data","API"],"title":"Getting Open Data into R from CKAN","type":"post"},{"authors":null,"categories":["R"],"content":"\rI am very excited to hear that there are attempts to create a brand new R user group in Glasgow! I had just talked in Post Number One about my guilt at not having been able to attend EdinbR as often as I wished but it should be much easier for me to find time to attend a group based in Glasgow. If you are based in (or near) Glasgow and would like to join the R community, this sounds like the place to be – I hope this idea takes off! This is the blurb from their meetup page.\n\rThis group is for people who use R (or want to start to). This meetup is a first attempt to get together people in Glasgow interested in R, meet and decide how to go about the organisation. There are several R User around the world and would be nice to ave one in Glasgow as well.\n\r","date":1558396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558396800,"objectID":"b4706a8411ad127cef0837c154b12b9c","permalink":"https://alan-y.netlify.com/post/glasgow-r-user-group/","publishdate":"2019-05-21T00:00:00Z","relpermalink":"/post/glasgow-r-user-group/","section":"post","summary":"I am very excited to hear that there are attempts to create a brand new R user group in Glasgow! I had just talked in Post Number One about my guilt at not having been able to attend EdinbR as often as I wished but it should be much easier for me to find time to attend a group based in Glasgow. If you are based in (or near) Glasgow and would like to join the R community, this sounds like the place to be – I hope this idea takes off!","tags":["R-events"],"title":"Glasgow R User Group","type":"post"},{"authors":null,"categories":null,"content":"","date":1558224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558224000,"objectID":"299a077dcf7d88d57edc9080508f2dd4","permalink":"https://alan-y.netlify.com/bio/","publishdate":"2019-05-19T00:00:00Z","relpermalink":"/bio/","section":"","summary":"Biography","tags":null,"title":"Bio","type":"widget_page"},{"authors":null,"categories":["Personal"],"content":"\rI suppose this is my hello world post – I’ve never been good at getting my messages out there (I’m minimally active on social media, etc) but this is part of my attempt to rectify that a little. I have wanted to start a blog for a long time and in fact, I previously started one but failed to keep it going (hopefully this time it’ll be different!). I had called that one ‘Quietly Analysing’ which was mostly inspired from a quote by Ian Hacking in 1936.\n\rThe quiet statisticians have changed our world - not by discovering new facts or technical developments but by changing the ways we reason, experiment and form our opinions about it.\n\rIt’s still one of my favourite quotes about statistics but I won’t be continuing with that name as this will be more of a personal/professional website for myself. That blog no longer exists so this is effectively a new start for me. I intend to use this website as a place where I can refer others to my academic and analytical work/projects (e.g. at conferences and for current/future employers) but also as a place where I can write up things to aid my own learning and share with others. Occasionally I may write something personal. This point about writing is important as I’ve always felt that I need to get better at writing so hopefully just trying to do this more will help me improve.\nAs part of this, I am also hoping to contribute more as a member of the R community – a community that I have always found to be warm, friendly and welcoming. Since I am from Scotland I have to give a particular mention to EdinbR, who have been doing a great job of promoting R in Scotland (and I have to shamefully admit that I haven’t been able to be a part of as much as I wish).\nI am still fairly new to using web tools so still count myself as a beginner in this area and I’m basically learning as I go. Therefore, I really have to acknowledge some people who have created amazing tools and resources that have helped me immensely in getting this website up and running. I am very grateful to Yihui Xie for creating blogdown (and so many other fantastic tools such as RMarkdown and bookdown) which I am using to create this website; to George Cushen for the Hugo Academic template; to Alison Presmanes Hill, Amber Thomas and Leslie Myint for their useful tips in setting up with blogdown and the Hugo Academic template.\n","date":1558224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558224000,"objectID":"05d21a22b1d3ec6d5a2b8d40ed9054b5","permalink":"https://alan-y.netlify.com/post/post-number-one/","publishdate":"2019-05-19T00:00:00Z","relpermalink":"/post/post-number-one/","section":"post","summary":"I suppose this is my hello world post – I’ve never been good at getting my messages out there (I’m minimally active on social media, etc) but this is part of my attempt to rectify that a little. I have wanted to start a blog for a long time and in fact, I previously started one but failed to keep it going (hopefully this time it’ll be different!). I had called that one ‘Quietly Analysing’ which was mostly inspired from a quote by Ian Hacking in 1936.","tags":["blogdown"],"title":"Post Number One","type":"post"},{"authors":null,"categories":null,"content":"A short list of resources and tips to help with learning some R basics, with particular focus on the tidyverse.\n","date":1557187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557187200,"objectID":"ebd4532e37170e64dce6a691910d4cb0","permalink":"https://alan-y.netlify.com/project/r-resources-tips/","publishdate":"2019-05-07T00:00:00Z","relpermalink":"/project/r-resources-tips/","section":"project","summary":"A short list of resources and tips to help with learning some R basics, with particular focus on the tidyverse.","tags":["R","training","tidyverse","bookdown"],"title":"R Training Resources and Tips","type":"project"},{"authors":["Andrew McAuley","Alan Yeung","Avril Taylor","Sharon Hutchinson","David Goldberg","Alison Munro"],"categories":null,"content":"","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554076800,"objectID":"f3271044d70efa814415c7cf65bb0804","permalink":"https://alan-y.netlify.com/publication/journal-article_nps_hcv/","publishdate":"2019-04-01T00:00:00Z","relpermalink":"/publication/journal-article_nps_hcv/","section":"publication","summary":"This study provides one of the first epidemiological analyses of the association between NPS injecting and HCV among a population level sample of PWID.","tags":["NPS","HCV"],"title":"Emergence of Novel Psychoactive Substance injecting associated with rapid rise in the population prevalence of hepatitis C virus","type":"publication"},{"authors":null,"categories":null,"content":"","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554076800,"objectID":"0a8735df14b40aaad239ebb3b6de7871","permalink":"https://alan-y.netlify.com/project/phstemplates/","publishdate":"2019-04-01T00:00:00Z","relpermalink":"/project/phstemplates/","section":"project","summary":"An R package containing standard templates for use by Public Health Scotland.","tags":["R","RStudio"],"title":"phstemplates","type":"project"},{"authors":[],"categories":null,"content":"\rredoc is an R package by Noam Ross that enables a two-way R Markdown-Microsoft Word workflow. It generates Word documents that can be de-rendered back into R Markdown, retaining edits on the Word document, including tracked changes.\n\rUPDATE: redoc was updated on May 5, 2019 so some aspects of the talk are now out-of-date. For example undoc() has been replaced by dedoc() and redoc_diff() lets you view changes more easily.\n","date":1553598000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553598000,"objectID":"8f74dc77ac4858075f49e0bdccdc9acb","permalink":"https://alan-y.netlify.com/talk/redoc/","publishdate":"2019-03-26T00:00:00Z","relpermalink":"/talk/redoc/","section":"talk","summary":"A quick summary and demo of my experience of using the redoc package.","tags":[],"title":"Redoc","type":"talk"},{"authors":null,"categories":null,"content":"","date":1551830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551830400,"objectID":"b494bfc6cf4b9df782f9445003c40739","permalink":"https://alan-y.netlify.com/project/objectremover/","publishdate":"2019-03-06T00:00:00Z","relpermalink":"/project/objectremover/","section":"project","summary":"An RStudio addin to assist with removing objects from the global environment. Features include removing objects according to name patterns and object type.","tags":["R","RStudio"],"title":"objectremover RStudio Addin","type":"project"},{"authors":["Health Protection Scotland","Information Services Division"],"categories":null,"content":"The Report was prepared by a writing committee stemming from Scotland’s National HIV PrEP Coordinating Group. It has been written on behalf of the National Coordination Group and its subgroups (see Appendix 1 of the report for details).\nMy main contributions to the report were to chapter 5: Evaluating the Impact of HIV PrEP.\n","date":1551139200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551139200,"objectID":"951fb3c140d9d5fdddafaa2946870698","permalink":"https://alan-y.netlify.com/publication/report-hiv_prep_year_one/","publishdate":"2019-02-26T00:00:00Z","relpermalink":"/publication/report-hiv_prep_year_one/","section":"publication","summary":"This report looks at the first year of the HIV PrEP programme in Scotland, covering the period from July 2017 to June 2018.","tags":["HIV"],"title":"Implementation of HIV PrEP in Scotland: First Year Report","type":"publication"},{"authors":null,"categories":null,"content":"Any original content created by me for this website such as blog posts are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"https://alan-y.netlify.com/privacy/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/privacy/","section":"","summary":"Any original content created by me for this website such as blog posts are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.","tags":null,"title":"Privacy Policy","type":"page"},{"authors":["Norah Palmateer","David Goldberg","Alison Munro","Avril Taylor","Alan Yeung","Lesley Wallace","Alan Mitchell","Samantha Shepherd","Rory Gunson","Celia Aitken","Sharon Hutchinson"],"categories":null,"content":"","date":1500076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1500076800,"objectID":"7a52a8ecfd7427e070b7f48b8e66a7ce","permalink":"https://alan-y.netlify.com/publication/journal-article_hbv_prison/","publishdate":"2017-07-15T00:00:00Z","relpermalink":"/publication/journal-article_hbv_prison/","section":"publication","summary":"This study examines the impact of the HBV vaccination programme for prisoners in Scotland among people who inject drugs (PWID) in the community","tags":["HBV","PWID","prison","vaccination"],"title":"Association between universal hepatitis B prison vaccination, vaccine uptake and hepatitis B infection among people who inject drugs","type":"publication"},{"authors":["Alan Yeung","Amanda Weir","Hannah Austin","Kirsty Morrison","Donald Inverarity","Jim Sherval","Naomi Henderson","Shruti Joshi","Roisin Ure","Andrew McAuley"],"categories":null,"content":"","date":1497052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497052800,"objectID":"3ede482164159232eb5e36a91b30baab","permalink":"https://alan-y.netlify.com/publication/journal-article_nps_tcdo/","publishdate":"2017-06-10T00:00:00Z","relpermalink":"/publication/journal-article_nps_tcdo/","section":"publication","summary":"In April 2015, the UK government enacted a temporary class drug order (TCDO) on ethylphenidate in response to reported harms associated with its use, in particular an outbreak of infections among people who inject drugs (PWID) in Lothian, Scotland.","tags":["NPS","PWID","time-series"],"title":"Assessing the impact of a temporary class drug order on ethylphenidate-related infections among people who inject drugs in Lothian, Scotland: an interrupted time-series analysis","type":"publication"},{"authors":["Lesley Wallace","Alan Yeung","Kirsten Trayner","Beth Cullen","Kate Templeton","Celia Aitken","Sharon Hutchinson","David Goldberg"],"categories":null,"content":"","date":1484611200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1484611200,"objectID":"e539e8ca253c8b89f047ed2947f1496a","permalink":"https://alan-y.netlify.com/publication/report-hbv2015_hps/","publishdate":"2017-01-17T00:00:00Z","relpermalink":"/publication/report-hbv2015_hps/","section":"publication","summary":"This report looks at the epidemiology of hepatitis B in Scotland up to 2015.","tags":["HBV"],"title":"Hepatitis B infection in Scotland: 2015","type":"publication"},{"authors":["Alan Yeung","Chris Robertson"],"categories":null,"content":" Chapter List:  Introduction Tuberculosis in Scotland  Finding Potential Strain Clusters  Characteristics of 2009 Pandemic Influenza in Scotland Methods of Estimating Reproductive Numbers (Literature Review) Estimation of Reproductive Numbers for 2009 Pandemic Influenza in Scotland  Spatial Method  Studies of Influenza Vaccine Effectiveness (Literature Review) Influenza Vaccine Effectiveness in Scotland  Season 2011-12 and 2012-13  Conclusions  ","date":1469318400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1469318400,"objectID":"3bbaff791be1d67f99d1269bde41adc9","permalink":"https://alan-y.netlify.com/publication/phd-thesis/","publishdate":"2016-07-24T00:00:00Z","relpermalink":"/publication/phd-thesis/","section":"publication","summary":"This thesis applies and develops statistical methods to studies of vaccine-preventable disease outbreaks in Scotland and aims to aid in the detection and management of outbreaks.","tags":["statistics","vaccination"],"title":"Statistical Applications in the Analysis of Vaccine Preventable Diseases","type":"publication"}]