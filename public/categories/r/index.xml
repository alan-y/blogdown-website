<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Alan Yeung</title>
    <link>https://alan-y.netlify.com/categories/r/</link>
    <description>Recent content in R on Alan Yeung</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019 Alan Yeung</copyright>
    <lastBuildDate>Sun, 05 Nov 2023 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://alan-y.netlify.com/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Grouped Sequences in dplyr</title>
      <link>https://alan-y.netlify.com/post/2023-11-05-grouped-sequences-in-dplyr/</link>
      <pubDate>Sun, 05 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/2023-11-05-grouped-sequences-in-dplyr/</guid>
      <description>


&lt;p&gt;For a piece of work I had to calculate the number of matches that a team plays away from home in a row, which we will call &lt;code&gt;days_on_the_road&lt;/code&gt;. I was not sure how to do this with &lt;code&gt;dplyr&lt;/code&gt; but it’s basically a ‘grouped sequence’. For this post, I’ve created some dummy data to illustrate this idea. The &lt;code&gt;num_matches_away&lt;/code&gt; variable is what we want to mimic using some data manipulation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

sports_df &amp;lt;- tibble::tribble(
  ~team,    ~date,        ~home_or_away, ~num_matches_away,
  &amp;quot;Team A&amp;quot;, &amp;quot;07/10/2022&amp;quot;, &amp;quot;H&amp;quot;,           0L,
  &amp;quot;Team A&amp;quot;, &amp;quot;14/10/2022&amp;quot;, &amp;quot;A&amp;quot;,           1L,
  &amp;quot;Team A&amp;quot;, &amp;quot;21/10/2022&amp;quot;, &amp;quot;A&amp;quot;,           2L,
  &amp;quot;Team A&amp;quot;, &amp;quot;28/10/2022&amp;quot;, &amp;quot;H&amp;quot;,           0L,
  &amp;quot;Team A&amp;quot;, &amp;quot;04/11/2022&amp;quot;, &amp;quot;A&amp;quot;,           1L,
  &amp;quot;Team A&amp;quot;, &amp;quot;11/11/2022&amp;quot;, &amp;quot;A&amp;quot;,           2L,
  &amp;quot;Team A&amp;quot;, &amp;quot;18/11/2022&amp;quot;, &amp;quot;A&amp;quot;,           3L,
  &amp;quot;Team A&amp;quot;, &amp;quot;25/11/2022&amp;quot;, &amp;quot;H&amp;quot;,           0L,
  &amp;quot;Team A&amp;quot;, &amp;quot;02/12/2022&amp;quot;, &amp;quot;H&amp;quot;,           0L,
  &amp;quot;Team A&amp;quot;, &amp;quot;09/12/2022&amp;quot;, &amp;quot;H&amp;quot;,           0L,
  &amp;quot;Team B&amp;quot;, &amp;quot;07/10/2022&amp;quot;, &amp;quot;H&amp;quot;,           0L,
  &amp;quot;Team B&amp;quot;, &amp;quot;14/10/2022&amp;quot;, &amp;quot;A&amp;quot;,           1L,
  &amp;quot;Team B&amp;quot;, &amp;quot;21/10/2022&amp;quot;, &amp;quot;A&amp;quot;,           2L,
  &amp;quot;Team B&amp;quot;, &amp;quot;28/10/2022&amp;quot;, &amp;quot;A&amp;quot;,           3L,
  &amp;quot;Team B&amp;quot;, &amp;quot;04/11/2022&amp;quot;, &amp;quot;H&amp;quot;,           0L,
  &amp;quot;Team B&amp;quot;, &amp;quot;11/11/2022&amp;quot;, &amp;quot;A&amp;quot;,           1L,
  &amp;quot;Team B&amp;quot;, &amp;quot;18/11/2022&amp;quot;, &amp;quot;A&amp;quot;,           2L,
  &amp;quot;Team B&amp;quot;, &amp;quot;25/11/2022&amp;quot;, &amp;quot;H&amp;quot;,           0L,
  &amp;quot;Team B&amp;quot;, &amp;quot;02/12/2022&amp;quot;, &amp;quot;H&amp;quot;,           0L,
  &amp;quot;Team B&amp;quot;, &amp;quot;09/12/2022&amp;quot;, &amp;quot;A&amp;quot;,           1L
) %&amp;gt;%      
  mutate(date = as.Date(date, &amp;quot;%d/%m/%Y&amp;quot;)) %&amp;gt;% 
  arrange(team, date)

sports_df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 20 × 4
##    team   date       home_or_away num_matches_away
##    &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt;                   &amp;lt;int&amp;gt;
##  1 Team A 2022-10-07 H                           0
##  2 Team A 2022-10-14 A                           1
##  3 Team A 2022-10-21 A                           2
##  4 Team A 2022-10-28 H                           0
##  5 Team A 2022-11-04 A                           1
##  6 Team A 2022-11-11 A                           2
##  7 Team A 2022-11-18 A                           3
##  8 Team A 2022-11-25 H                           0
##  9 Team A 2022-12-02 H                           0
## 10 Team A 2022-12-09 H                           0
## 11 Team B 2022-10-07 H                           0
## 12 Team B 2022-10-14 A                           1
## 13 Team B 2022-10-21 A                           2
## 14 Team B 2022-10-28 A                           3
## 15 Team B 2022-11-04 H                           0
## 16 Team B 2022-11-11 A                           1
## 17 Team B 2022-11-18 A                           2
## 18 Team B 2022-11-25 H                           0
## 19 Team B 2022-12-02 H                           0
## 20 Team B 2022-12-09 A                           1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I firstly came up with a complicated solution for this using a combination of &lt;code&gt;slider::slide()&lt;/code&gt; and &lt;code&gt;rle()&lt;/code&gt; (run length encoding).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sports_df2 &amp;lt;- sports_df %&amp;gt;% 
  group_by(team) %&amp;gt;% 
  mutate(days_on_road = unlist(slider::slide(rle(home_or_away)$length, ~1:.x)),
         days_on_road = if_else(home_or_away == &amp;quot;H&amp;quot;, 0L, days_on_road)) %&amp;gt;% 
  ungroup()

identical(sports_df2$days_on_road, sports_df$num_matches_away)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These are some pretty cool functions and it was nice to know &lt;code&gt;rle()&lt;/code&gt; existed but I was never really happy with this solution as it seemed overly complex and it’s difficult to understand what the code is doing by simply reading it. So I asked a colleague to try to solve this problem and they came up with a better solution which I’m grateful for! It involves using a combination of &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;seq_len()&lt;/code&gt; which is a whole lot simpler to understand in my opinion.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sports_df3 &amp;lt;- sports_df2 %&amp;gt;%
  mutate(away = cumsum(home_or_away == &amp;quot;H&amp;quot;)) %&amp;gt;%
  group_by(team, home_or_away, away) %&amp;gt;%
  mutate(days_on_road = seq_len(n())) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(days_on_road = if_else(home_or_away == &amp;quot;H&amp;quot;, 0L, days_on_road))

identical(sports_df3$days_on_road, sports_df$num_matches_away)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I hope this is useful for some of you out there coding with R!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A couple of case_when() tricks</title>
      <link>https://alan-y.netlify.com/post/couple-of-casewhen-tricks/</link>
      <pubDate>Mon, 09 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/couple-of-casewhen-tricks/</guid>
      <description>


&lt;div id=&#34;combining-case_when-and-across&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Combining case_when() and across()&lt;/h2&gt;
&lt;p&gt;If you want to use &lt;code&gt;case_when()&lt;/code&gt; and &lt;code&gt;across()&lt;/code&gt; different variables, then here is an example that can do this with the help of the &lt;code&gt;get()&lt;/code&gt; and &lt;code&gt;cur_column()&lt;/code&gt; functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

iris_df &amp;lt;- as_tibble(iris) %&amp;gt;% 
  mutate(flag_Petal.Length = as.integer(Petal.Length &amp;gt; 1.5),
         flag_Petal.Width = as.integer(Petal.Width &amp;gt; 0.2))

iris_df %&amp;gt;% 
  mutate(across(c(Petal.Length, Petal.Width),
                ~case_when(
                  get(glue::glue(&amp;quot;flag_{cur_column()}&amp;quot;)) == 1 ~ NA_real_,
                  TRUE ~ .x
                ))) %&amp;gt;% 
    select(contains(&amp;quot;Petal&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 150 × 4
##    Petal.Length Petal.Width flag_Petal.Length flag_Petal.Width
##           &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;             &amp;lt;int&amp;gt;            &amp;lt;int&amp;gt;
##  1          1.4         0.2                 0                0
##  2          1.4         0.2                 0                0
##  3          1.3         0.2                 0                0
##  4          1.5         0.2                 0                0
##  5          1.4         0.2                 0                0
##  6         NA          NA                   1                1
##  7          1.4        NA                   0                1
##  8          1.5         0.2                 0                0
##  9          1.4         0.2                 0                0
## 10          1.5         0.1                 0                0
## # ℹ 140 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Is there any way to use this with a function from the &lt;code&gt;rlang&lt;/code&gt; packages instead of &lt;code&gt;get()&lt;/code&gt;? It’s a little beyond my current understanding of tidy evaluation but let me know in the comments if you know please.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;combining-case_when-with-if_any-and-if_all&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Combining case_when() with if_any() and if_all()&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;if_any()&lt;/code&gt; and &lt;code&gt;if_all()&lt;/code&gt; functions can be used to save typing lots of variables (as these allow the use of &lt;code&gt;tidyselect&lt;/code&gt; helpers) within &lt;code&gt;case_when()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df1 &amp;lt;- tibble(var1 = c(1, 0, 1, NA),
              var2 = c(1, 0, 0, NA))

df1 %&amp;gt;% 
  mutate(category = case_when(
    if_any(c(var1, var2), ~.x &amp;gt; 0) ~ 1, 
    if_all(c(var1, var2), is.na) ~ NA_real_,
    TRUE ~ 0
  ))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 × 3
##    var1  var2 category
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1     1     1        1
## 2     0     0        0
## 3     1     0        1
## 4    NA    NA       NA&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Summarising Dates with Missing Values</title>
      <link>https://alan-y.netlify.com/post/summarising-dates-with-missing-values/</link>
      <pubDate>Mon, 02 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/summarising-dates-with-missing-values/</guid>
      <description>


&lt;p&gt;This blog post is just a note that when you try to do a grouped summary of a date variable but some groups have &lt;strong&gt;all&lt;/strong&gt; missing values, it will return &lt;code&gt;Inf&lt;/code&gt;. This means that the summary will not show up as an &lt;code&gt;NA&lt;/code&gt; and this can cause issues in analysis if you are not careful.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

df &amp;lt;- tibble::tribble(
    ~id,          ~dt,
    1L, &amp;quot;01/01/2001&amp;quot;,
    1L,           NA,
    2L,           NA,
    2L,           NA
) %&amp;gt;% 
    mutate(dt = dmy(dt))

z1 &amp;lt;- df %&amp;gt;% 
    group_by(id) %&amp;gt;% 
    summarise(dt_min = min(dt, na.rm = TRUE),
              .groups = &amp;quot;drop&amp;quot;)

z1
# A tibble: 2 × 2
#      id dt_min    
#   &amp;lt;int&amp;gt; &amp;lt;date&amp;gt;    
# 1     1 2001-01-01
# 2     2 Inf

sum(is.na(z1$dt_min))
# [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are a couple of ways around this. Firstly you can use an &lt;code&gt;if()&lt;/code&gt; statement.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;z2 &amp;lt;- df %&amp;gt;% 
    group_by(id) %&amp;gt;% 
    summarise(dt_min = if (all(is.na(dt))) NA_Date_ else min(dt, na.rm = TRUE),
              .groups = &amp;quot;drop&amp;quot;)

z2
# A tibble: 2 × 2
#      id dt_min    
#   &amp;lt;int&amp;gt; &amp;lt;date&amp;gt;    
# 1     1 2001-01-01
# 2     2 NA  
sum(is.na(z2$dt_min))
# [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or you can summary functions from the &lt;a href=&#34;https://cran.r-project.org/web/packages/hablar/vignettes/hablar.html&#34;&gt;&lt;code&gt;hablar&lt;/code&gt;&lt;/a&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;z3 &amp;lt;- df %&amp;gt;% 
    group_by(id) %&amp;gt;% 
    summarise(dt_min = hablar::min_(dt),
              .groups = &amp;quot;drop&amp;quot;)

z3
# A tibble: 2 × 2
#      id dt_min    
#   &amp;lt;int&amp;gt; &amp;lt;date&amp;gt;    
# 1     1 2001-01-01
# 2     2 NA  
sum(is.na(z3$dt_min))
# [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Is there a reason why R decides to return &lt;code&gt;Inf&lt;/code&gt; when summarising dates? Are there any other solutions to summarising date variables that contain missing values? Leave me a comment if you know thanks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rafa 21 Grand Slams and gganimate</title>
      <link>https://alan-y.netlify.com/post/rafa-21-slams/</link>
      <pubDate>Sun, 13 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/rafa-21-slams/</guid>
      <description>


&lt;p&gt;I’ve been a Nadal fan for a long time – right back to the days of the &lt;a href=&#34;https://www.tennis365.com/tennis-features/t365-recall-when-the-pirate-pants-wearing-rafael-nadal-came-of-age-on-clay&#34;&gt;pirate-pants&lt;/a&gt; so yeah, really a long time. In all this time, Rafa has never been ahead in the grand slam race vs his biggest rivals… but that finally changed after the 2022 Australian Open! The win there was unexpected and came out of nowhere. The final against Medvedev has to go down as one of the best comebacks ever.&lt;/p&gt;
&lt;p&gt;It’s already been &lt;code&gt;as.Date(&#34;2022-02-13&#34;) - as.Date(&#34;2022-01-30&#34;)&lt;/code&gt; (14 days) since he won that record 21st grand slam so I thought it has to be about time to do something to mark the achievement. Something that’s been on my list of things to learn is &lt;a href=&#34;https://gganimate.com&#34;&gt;gganimate&lt;/a&gt; which is a very cool R package so I thought I’d take the opportunity here. My goal is to create an animated barplot, showing Rafa on top at the very end.&lt;/p&gt;
&lt;div id=&#34;getting-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Getting the data&lt;/h2&gt;
&lt;p&gt;I started by using &lt;a href=&#34;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv&#34;&gt;this data on grand slam wins&lt;/a&gt; from &lt;a href=&#34;https://www.emilykuehler.com/portfolio/barchart-race&#34;&gt;this blog post by Emily Kuehler&lt;/a&gt; and filtering for just the data on the big 3 male players: Nadal, Djokovic and Federer. Since the grand slam data there does not go all the way up to the 2022 Australian Open, I had to manually add that in by looking up the required information on &lt;a href=&#34;https://en.wikipedia.org&#34;&gt;Wikipedia&lt;/a&gt; and binding that to the end.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(readxl)

gs_df &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv&amp;quot;, 
                  show_col_types = FALSE)

gs_update &amp;lt;- tibble::tribble(
    ~year,       ~grand_slam,            ~name, ~rolling_win_count, ~tournament_date,
    2019,     &amp;quot;French Open&amp;quot;,   &amp;quot;Rafael Nadal&amp;quot;,                18,     &amp;quot;26/05/2019&amp;quot;,
    2019,       &amp;quot;Wimbledon&amp;quot;, &amp;quot;Novak Djokovic&amp;quot;,                16,     &amp;quot;01/07/2019&amp;quot;,
    2019,         &amp;quot;US Open&amp;quot;,   &amp;quot;Rafael Nadal&amp;quot;,                19,     &amp;quot;26/08/2019&amp;quot;,
    2020, &amp;quot;Australian Open&amp;quot;, &amp;quot;Novak Djokovic&amp;quot;,                17,     &amp;quot;20/01/2020&amp;quot;,
    2020,     &amp;quot;French Open&amp;quot;,   &amp;quot;Rafael Nadal&amp;quot;,                20,     &amp;quot;27/09/2020&amp;quot;,
    2021, &amp;quot;Australian Open&amp;quot;, &amp;quot;Novak Djokovic&amp;quot;,                18,     &amp;quot;08/02/2021&amp;quot;,
    2021,     &amp;quot;French Open&amp;quot;, &amp;quot;Novak Djokovic&amp;quot;,                19,     &amp;quot;30/05/2021&amp;quot;,
    2021,       &amp;quot;Wimbledon&amp;quot;, &amp;quot;Novak Djokovic&amp;quot;,                20,     &amp;quot;28/07/2021&amp;quot;,
    2022, &amp;quot;Australian Open&amp;quot;,   &amp;quot;Rafael Nadal&amp;quot;,                21,     &amp;quot;17/01/2022&amp;quot;
) %&amp;gt;% 
    mutate(tournament_date = as.Date(tournament_date, &amp;quot;%d/%m/%Y&amp;quot;))

gs_df2 &amp;lt;- gs_df %&amp;gt;%
    filter(name %in% c(&amp;quot;Rafael Nadal&amp;quot;, &amp;quot;Novak Djokovic&amp;quot;, &amp;quot;Roger Federer&amp;quot;)) %&amp;gt;%
    mutate(grand_slam = str_replace_all(grand_slam, &amp;quot;_&amp;quot;, &amp;quot; &amp;quot;),
           grand_slam = str_to_title(grand_slam),
           grand_slam = str_replace_all(grand_slam, &amp;quot;Us&amp;quot;, &amp;quot;US&amp;quot;)) %&amp;gt;%
    select(-gender) %&amp;gt;%
    bind_rows(gs_update)

gs_df2
# A tibble: 61 x 5
#     year grand_slam      name          rolling_win_count tournament_date
#    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;chr&amp;gt;                     &amp;lt;dbl&amp;gt; &amp;lt;date&amp;gt;         
#  1  2003 Wimbledon       Roger Federer                 1 2003-07-14     
#  2  2004 Australian Open Roger Federer                 2 2004-01-10     
#  3  2004 Wimbledon       Roger Federer                 3 2004-07-14     
#  4  2004 US Open         Roger Federer                 4 2004-09-09     
#  5  2005 French Open     Rafael Nadal                  1 2005-06-09     
#  6  2005 Wimbledon       Roger Federer                 5 2005-07-14     
#  7  2005 US Open         Roger Federer                 6 2005-09-09     
#  8  2006 Australian Open Roger Federer                 7 2006-01-10     
#  9  2006 French Open     Rafael Nadal                  2 2006-06-09     
# 10  2006 Wimbledon       Roger Federer                 8 2006-07-14     
# ... with 51 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data processing&lt;/h2&gt;
&lt;p&gt;I had to do a bit of general data wrangling (isn’t this always the case unfortunately?) to set things up for gganimate. This is all fairly standard stuff so I’ll just show the code below but one thing to note is that for the rank order (&lt;code&gt;current_rank&lt;/code&gt;) of the players at each time point, I sorted ascending on &lt;code&gt;rolling_win_count2&lt;/code&gt; rather than descending (as would seem more logical to get the ranking by most slams) because when you use &lt;code&gt;ggplot2::coord_flip()&lt;/code&gt;, it puts the highest value (lowest rank) at the top of the graph – so essentially I set it up so that rank 3 is the best and rank 1 is the worst.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Expand out for all combinations
gs_df3 &amp;lt;- gs_df2 %&amp;gt;% 
    arrange(tournament_date) %&amp;gt;% 
    mutate(year = fct_inorder(factor(year)),
           grand_slam = factor(grand_slam, 
                               levels = c(&amp;quot;Australian Open&amp;quot;, &amp;quot;French Open&amp;quot;, 
                                          &amp;quot;Wimbledon&amp;quot;, &amp;quot;US Open&amp;quot;)),
           name = factor(name, levels = c(&amp;quot;Rafael Nadal&amp;quot;, &amp;quot;Novak Djokovic&amp;quot;, 
                                          &amp;quot;Roger Federer&amp;quot;))) %&amp;gt;% 
    complete(year, grand_slam, name) %&amp;gt;% 
    replace_na(list(rolling_win_count = 0))

# Drop tournaments before first slam win or not yet played
gs_df4 &amp;lt;- gs_df3 %&amp;gt;% 
    filter(!(year == 2003 &amp;amp; grand_slam %in% c(&amp;quot;Australian Open&amp;quot;, &amp;quot;French Open&amp;quot;)),
           !(year == 2022 &amp;amp; grand_slam %in% c(&amp;quot;French Open&amp;quot;, &amp;quot;Wimbledon&amp;quot;, &amp;quot;US Open&amp;quot;))) %&amp;gt;% 
    mutate(yr_slam = paste(year, grand_slam), .before = year)

# Recalculate rolling win count
gs_df5 &amp;lt;- gs_df4 %&amp;gt;% 
    mutate(win = as.numeric(rolling_win_count &amp;gt; 0)) %&amp;gt;% 
    group_by(name) %&amp;gt;% 
    mutate(rolling_win_count2 = cumsum(win)) %&amp;gt;% 
    ungroup() 

# Set the rank for each time point
gs_df6 &amp;lt;- gs_df5 %&amp;gt;% 
    arrange(year, grand_slam, rolling_win_count2, desc(name)) %&amp;gt;% 
    group_by(yr_slam) %&amp;gt;% 
    mutate(current_rank = row_number()) %&amp;gt;% 
    ungroup()

select(gs_df6, yr_slam, name, rolling_win_count2, current_rank)
# A tibble: 225 x 4
#    yr_slam              name           rolling_win_count2 current_rank
#    &amp;lt;chr&amp;gt;                &amp;lt;fct&amp;gt;                       &amp;lt;dbl&amp;gt;        &amp;lt;int&amp;gt;
#  1 2003 Wimbledon       Novak Djokovic                  0            1
#  2 2003 Wimbledon       Rafael Nadal                    0            2
#  3 2003 Wimbledon       Roger Federer                   1            3
#  4 2003 US Open         Novak Djokovic                  0            1
#  5 2003 US Open         Rafael Nadal                    0            2
#  6 2003 US Open         Roger Federer                   1            3
#  7 2004 Australian Open Novak Djokovic                  0            1
#  8 2004 Australian Open Rafael Nadal                    0            2
#  9 2004 Australian Open Roger Federer                   2            3
# 10 2004 French Open     Novak Djokovic                  0            1
# ... with 215 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ggimage&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;ggimage&lt;/h2&gt;
&lt;p&gt;Next I prepared some cartoon faces for the 3 players to go on the ends of the bars and stored these on Github so they can be loaded into R with the help of the &lt;a href=&#34;https://github.com/GuangchuangYu/ggimage&#34;&gt;ggimage&lt;/a&gt; package. I won’t go into much detail on the image processing side but the online tools I used to help with this are all in the references section of this blog post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggimage)

img_rafa &amp;lt;- &amp;quot;https://raw.githubusercontent.com/alan-y/img/master/rafa2.png&amp;quot;
img_novak &amp;lt;- &amp;quot;https://raw.githubusercontent.com/alan-y/img/master/novak2.png&amp;quot;
img_roger &amp;lt;- &amp;quot;https://raw.githubusercontent.com/alan-y/img/master/roger2.png&amp;quot;

gs_df7 &amp;lt;- gs_df6 %&amp;gt;% 
    mutate(img_player = case_when(
        name == &amp;quot;Rafael Nadal&amp;quot; ~ img_rafa,
        name == &amp;quot;Novak Djokovic&amp;quot; ~ img_novak,
        name == &amp;quot;Roger Federer&amp;quot; ~ img_roger,
    ))

select(gs_df7, name, img_player)
# A tibble: 225 x 2
#    name           img_player                                                    
#    &amp;lt;fct&amp;gt;          &amp;lt;chr&amp;gt;                                                         
#  1 Novak Djokovic https://raw.githubusercontent.com/alan-y/img/master/novak2.png
#  2 Rafael Nadal   https://raw.githubusercontent.com/alan-y/img/master/rafa2.png 
#  3 Roger Federer  https://raw.githubusercontent.com/alan-y/img/master/roger2.png
#  4 Novak Djokovic https://raw.githubusercontent.com/alan-y/img/master/novak2.png
#  5 Rafael Nadal   https://raw.githubusercontent.com/alan-y/img/master/rafa2.png 
#  6 Roger Federer  https://raw.githubusercontent.com/alan-y/img/master/roger2.png
#  7 Novak Djokovic https://raw.githubusercontent.com/alan-y/img/master/novak2.png
#  8 Rafael Nadal   https://raw.githubusercontent.com/alan-y/img/master/rafa2.png 
#  9 Roger Federer  https://raw.githubusercontent.com/alan-y/img/master/roger2.png
# 10 Novak Djokovic https://raw.githubusercontent.com/alan-y/img/master/novak2.png
# ... with 215 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;gganimate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;gganimate&lt;/h2&gt;
&lt;p&gt;Firstly I’ll mention that for the gganimate package to work well, you’ll also need to install the &lt;a href=&#34;https://cran.r-project.org/web/packages/gifski/index.html&#34;&gt;gifski&lt;/a&gt; package. To get things ready for the animated plot in &lt;code&gt;plot_df&lt;/code&gt;, I just had to make a couple of minor manipulations. Then everything up to the use of &lt;code&gt;transition_states()&lt;/code&gt; in the code below is standard ggplot2 code except maybe the use of &lt;code&gt;geom_image()&lt;/code&gt; to add the cartoon faces to the end of the bars (note that I subtract 0.5 from &lt;code&gt;rolling_win_count&lt;/code&gt; as the function doesn’t seem to have a &lt;code&gt;nudge_y&lt;/code&gt; argument even though it has one for &lt;code&gt;nudge_x&lt;/code&gt;) and the use of &lt;code&gt;{closest_state}&lt;/code&gt; in the subtitle – this tracks the variable that the animation transitions over which for me, is &lt;code&gt;yr_slam&lt;/code&gt;, i.e. the combination of year and grand slam name. The fill colours are from &lt;code&gt;scale_fill_hue()&lt;/code&gt; but manually picked so that the fill colour of each player’s bar matches their favourite surface.&lt;/p&gt;
&lt;p&gt;For &lt;code&gt;transition_states()&lt;/code&gt;, the &lt;code&gt;transition_length()&lt;/code&gt; is the relative length of the transition and &lt;code&gt;state_length()&lt;/code&gt; is the relative length of the pause at the states (I stole this from the help page); I set &lt;code&gt;wrap = FALSE&lt;/code&gt; as I don’t want the last state to transition into the first when looping the animation. I am not sure how much difference the &lt;code&gt;ease_aes(&#34;quadratic-in-out&#34;)&lt;/code&gt; makes here to be honest but that’s what I used. In general I know this function is for messing around with the effects applied to how frames/states transition into one another. &lt;strong&gt;If somebody can give me a good layman’s explanation of these functions, I’d be grateful if you can do so in the comments.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the &lt;code&gt;animate()&lt;/code&gt; function, I set &lt;code&gt;nframes = 500&lt;/code&gt;. Some things to note here are that the default is only 50 frames so if you have more than 50 states (and I do as I have more than 50 year-slam combinations) then you need to set this to a larger number but this number should be &lt;em&gt;suitably&lt;/em&gt; larger so the animation looks smoother. I set &lt;code&gt;end_pause&lt;/code&gt; to 30 frames so that it pauses at the end for a little bit. Finally I applied very specific &lt;code&gt;width&lt;/code&gt; and &lt;code&gt;height&lt;/code&gt; as I wanted to add something to the end of the animation which happened to have these dimensions – that’s a surprise which you will see!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gganimate)

plot_df &amp;lt;- gs_df7 %&amp;gt;% 
    select(-rolling_win_count) %&amp;gt;% 
    rename(rolling_win_count = rolling_win_count2) %&amp;gt;% 
    mutate(yr_slam = fct_inorder(factor(yr_slam)),
           name_count = paste(name, rolling_win_count))

# Set up ggplot2 theme
theme_set(theme_minimal())
theme_update(plot.title = element_text(face = &amp;quot;bold&amp;quot;, size = 18),
             plot.subtitle = element_text(size = 14),
             panel.grid.major.y = element_blank(),
             panel.grid.minor.y = element_blank(),
             panel.grid.major.x = element_line(color = &amp;quot;grey75&amp;quot;),
             panel.grid.minor.x = element_line(color = &amp;quot;grey75&amp;quot;),
             legend.position = &amp;quot;none&amp;quot;,
             axis.ticks = element_blank(),
             axis.text.y =  element_blank())

barplot_slams &amp;lt;- ggplot(plot_df, 
                        aes(x = current_rank, y = rolling_win_count, 
                            fill = name)) +
    geom_bar(stat = &amp;quot;identity&amp;quot;, width = 0.3, colour = &amp;quot;black&amp;quot;) +
    geom_text(aes(label = name_count), 
              nudge_x = -0.25, nudge_y = -0.75, 
              size = 3, fontface = &amp;quot;bold&amp;quot;, hjust = 0) +
    geom_image(aes(image = img_player, y = rolling_win_count - 0.5), size = 0.09) +
    scale_fill_manual(values = c(&amp;quot;#FF7969&amp;quot;, &amp;quot;#569EFF&amp;quot;, &amp;quot;#00B73A&amp;quot;)) +
    scale_y_continuous(limits = c(-0.75, 25), breaks = seq(0, 25, by = 5)) +
    coord_flip() +
    labs(title = &amp;quot;Men&amp;#39;s Tennis Grand Slam Singles Championships&amp;quot;,
         subtitle = &amp;quot;{closest_state}&amp;quot;,
         x = NULL, y = NULL) +
    transition_states(yr_slam, transition_length = 3, state_length = 1, 
                      wrap = FALSE) +
    ease_aes(&amp;quot;quadratic-in-out&amp;quot;)

animate(barplot_slams, nframes = 500, end_pause = 30, fps = 20, 
        width = 469, height = 334,
        renderer = gifski_renderer(&amp;quot;barplot_slams.gif&amp;quot;)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So without further ado, here is the final result for your enjoyment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://alan-y.netlify.com/img/barplot_slams2.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.archyworldys.com/before-talking-about-greatest-of-all-time-what-you-need-to-know-about-big-3-tennis&#34; class=&#34;uri&#34;&gt;https://www.archyworldys.com/before-talking-about-greatest-of-all-time-what-you-need-to-know-about-big-3-tennis&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cutout.pro&#34; class=&#34;uri&#34;&gt;https://www.cutout.pro&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.eurosport.com/tennis/watch-historic-moment-rafael-nadal-wins-australian-open-and-claims-historic-21st-grand-slam-singles-_vid1618912/video.shtml&#34; class=&#34;uri&#34;&gt;https://www.eurosport.com/tennis/watch-historic-moment-rafael-nadal-wins-australian-open-and-claims-historic-21st-grand-slam-singles-_vid1618912/video.shtml&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.downloadhelper.net&#34; class=&#34;uri&#34;&gt;https://www.downloadhelper.net&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://online-video-cutter.com&#34; class=&#34;uri&#34;&gt;https://online-video-cutter.com&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://ezgif.com&#34; class=&#34;uri&#34;&gt;https://ezgif.com&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://gif.ski&#34; class=&#34;uri&#34;&gt;https://gif.ski&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://gifyu.com&#34; class=&#34;uri&#34;&gt;https://gifyu.com&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Filtering with string statements in dplyr</title>
      <link>https://alan-y.netlify.com/post/filtering-string-dplyr/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/filtering-string-dplyr/</guid>
      <description>


&lt;p&gt;A question came up recently at work about how to use a filter statement entered as a complete string variable inside dplyr’s &lt;code&gt;filter()&lt;/code&gt; function – for example &lt;code&gt;dplyr::filter(my_data, &#34;var1 == &#39;a&#39;&#34;)&lt;/code&gt;. There does not seem to be much out there on this and I was not sure how to do it either but luckily &lt;a href=&#34;https://github.com/jakeybob&#34;&gt;jakeybob&lt;/a&gt; had a neat solution that seems to work well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;some_data %&amp;gt;% 
    filter(eval(rlang::parse_expr(selection_statement)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see it in action using the &lt;code&gt;iris&lt;/code&gt; flowers dataset. First note how many records there are for each species (&lt;em&gt;n&lt;/em&gt; = 50 for each) so we can check that the filtering has worked later.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

iris2 &amp;lt;- as_tibble(iris)
count(iris2, Species)
# # A tibble: 3 x 2
#   Species        n
#   &amp;lt;fct&amp;gt;      &amp;lt;int&amp;gt;
# 1 setosa        50
# 2 versicolor    50
# 3 virginica     50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now filter to get only setosa records and we can see only 50 records so that’s worked.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;selection_statement &amp;lt;- &amp;quot;Species == &amp;#39;setosa&amp;#39;&amp;quot;

iris2 %&amp;gt;% 
    filter(rlang::eval_tidy(rlang::parse_expr(selection_statement)))
# # A tibble: 50 x 5
#    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
#           &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;  
#  1          5.1         3.5          1.4         0.2 setosa 
#  2          4.9         3            1.4         0.2 setosa 
#  3          4.7         3.2          1.3         0.2 setosa 
#  4          4.6         3.1          1.5         0.2 setosa 
#  5          5           3.6          1.4         0.2 setosa&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I thought this method might fail if we create a variable called &lt;code&gt;Species&lt;/code&gt; in the global environment but it still works completely fine which is great!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Species &amp;lt;- &amp;quot;abc&amp;quot;

iris2 %&amp;gt;% 
    filter(rlang::eval_tidy(rlang::parse_expr(selection_statement)))
# # A tibble: 50 x 5
#    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
#           &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;  
#  1          5.1         3.5          1.4         0.2 setosa 
#  2          4.9         3            1.4         0.2 setosa 
#  3          4.7         3.2          1.3         0.2 setosa 
#  4          4.6         3.1          1.5         0.2 setosa 
#  5          5           3.6          1.4         0.2 setosa&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So it makes me wonder why there is nothing much out there on this? My feeling is that something will make this method fail but what is it? Where does it fail? Let me know in the comments if you know please, thanks!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Updating packages on a drat repo</title>
      <link>https://alan-y.netlify.com/post/updating-packages-on-a-drat-repo/</link>
      <pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/updating-packages-on-a-drat-repo/</guid>
      <description>


&lt;p&gt;This is just a small note (mainly for myself but hopefully may be of some use to a few others!) to remind of how to update a package on a &lt;a href=&#34;https://github.com/eddelbuettel/drat&#34;&gt;drat&lt;/a&gt; repo.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create the source file for the package you want to host on the drat repo using &lt;code&gt;devtools::build()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Clone the drat repo hosting the package (in my case &lt;a href=&#34;https://github.com/alan-y/drat&#34; class=&#34;uri&#34;&gt;https://github.com/alan-y/drat&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;drat::insertPackage(&#34;package-source.tar.gz&#34;, getwd())&lt;/code&gt; to add the package to the drat repo (&lt;code&gt;getwd()&lt;/code&gt; works for me if my working directory is at the top level of the drat repo). Note this also updates the &lt;code&gt;PACKAGES&lt;/code&gt; file that contains details on the packages hosted in the drat repo.&lt;/li&gt;
&lt;li&gt;Git push the package to all branches (master and gh-pages) using &lt;code&gt;git push origin --all&lt;/code&gt;. It is particularly important that changes are pushed to the gh-pages branch in order for this to work.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After this, packages can be installed using, for example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;drat::addRepo(&amp;quot;alan-y&amp;quot;)
install.packages(&amp;quot;phstemplates&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want the drat repo to be available at startup &lt;code&gt;drat::add()&lt;/code&gt; or &lt;code&gt;drat::addRepo()&lt;/code&gt; can be added to a &lt;code&gt;.Rprofile&lt;/code&gt; file.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scotland&#39;s Most Popular Babynames</title>
      <link>https://alan-y.netlify.com/post/scot-babynames/</link>
      <pubDate>Sat, 25 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/scot-babynames/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#downloading-the-data&#34; id=&#34;toc-downloading-the-data&#34;&gt;Downloading the data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#shiny-app&#34; id=&#34;toc-shiny-app&#34;&gt;Shiny App&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;I recently saw this &lt;a href=&#34;https://flowingdata.com/2020/01/21/name-guess&#34;&gt;great post on Nathan Yau’s FlowingData website&lt;/a&gt; which &lt;em&gt;guesses&lt;/em&gt; a person’s name based on what the name starts with. It also needs you to select a gender and a decade for when you were born before it can guess. Of course, it isn’t really a guess and is really just based on proportions calculated after restricting the data to what has been selected.&lt;/p&gt;
&lt;p&gt;It uses data from the Social Security Administration in America so results more specifically apply to the US. I thought it’d be cool to see how it looks for Scottish data which is available from the &lt;a href=&#34;https://www.nrscotland.gov.uk/statistics-and-data/statistics/statistics-by-theme/vital-events/names/babies-first-names&#34;&gt;National Records of Scotland (NRS)&lt;/a&gt;. I’ve embedded the Shiny app below into an &lt;a href=&#34;https://www.w3schools.com/html/html_iframe.asp&#34;&gt;iframe&lt;/a&gt; but you can view the app in it’s own page by going to &lt;a href=&#34;https://alan-y.shinyapps.io/name_guess&#34; class=&#34;uri&#34;&gt;https://alan-y.shinyapps.io/name_guess&lt;/a&gt;. I used a little bit of &lt;a href=&#34;https://stackoverflow.com/questions/17838607/making-an-iframe-responsive&#34;&gt;css to make the iframe &lt;em&gt;responsive&lt;/em&gt;&lt;/a&gt; (resizes based on the amount of screen/window space available). The app is hosted on &lt;a href=&#34;https://www.shinyapps.io&#34;&gt;shinyapps.io&lt;/a&gt; on a free account so if nobody visits it for a while, it will no longer be available (unless I restart it). So apologies if you happen to visit this page further down the line and it’s not working!&lt;/p&gt;
&lt;p&gt;The R code I used to download and wrangle the data as well as create the Shiny app is provided further down the page. I hope the app is interesting to some people and my acknowledgements again, to Nathan Yau as this is clearly based off his work.&lt;/p&gt;
&lt;div class=&#34;wrapper&#34;&gt;
&lt;p&gt;&lt;iframe src=&#34;https://alan-y.shinyapps.io/name_guess&#34; width=&#34;800&#34; height=&#34;575&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;downloading-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Downloading the data&lt;/h2&gt;
&lt;p&gt;First I identified the webpages from the NRS website that contained the required babynames csv files and then scraped the links to all the csv files with help from the &lt;a href=&#34;https://rvest.tidyverse.org&#34;&gt;rvest&lt;/a&gt; package. I created some helper functions (one to grab the csv links and one to read the csv files into R and tidy them up) to use with the &lt;code&gt;map()&lt;/code&gt; functions from purrr.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(janitor)
library(rvest)

# Helper functions
get_csv_links &amp;lt;- function(link) {
  read_html(link) %&amp;gt;% 
    html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% 
    html_attr(&amp;quot;href&amp;quot;) %&amp;gt;% 
    str_subset(&amp;quot;\\.csv&amp;quot;) %&amp;gt;% 
    paste0(&amp;quot;https://www.nrscotland.gov.uk/&amp;quot;, .)
}

read_babynames &amp;lt;- function(link, yr) {
  b &amp;lt;- read_csv(link, skip = 6) %&amp;gt;% 
    remove_empty() %&amp;gt;% 
    select(-contains(&amp;quot;Position&amp;quot;)) %&amp;gt;% 
    clean_names()

  boy &amp;lt;- b %&amp;gt;%
    select(1:2) %&amp;gt;%
    set_names(c(&amp;quot;name&amp;quot;, &amp;quot;number_of_babies&amp;quot;)) %&amp;gt;% 
    mutate(gender = &amp;quot;boy&amp;quot;)

  girl &amp;lt;- b %&amp;gt;%
    select(3:4) %&amp;gt;%
    set_names(c(&amp;quot;name&amp;quot;, &amp;quot;number_of_babies&amp;quot;)) %&amp;gt;%
    mutate(gender = &amp;quot;girl&amp;quot;)

  bind_rows(boy, girl) %&amp;gt;% 
    mutate(year = yr) %&amp;gt;% 
    filter(!is.na(number_of_babies))
}

# List of webpages containing the csv files
pages &amp;lt;- c(&amp;quot;https://www.nrscotland.gov.uk/statistics-and-data/statistics/statistics-by-theme/vital-events/names/babies-first-names/full-lists-of-babies-first-names-archive/full-lists-of-babies-first-names-1974-to-1979&amp;quot;,
           &amp;quot;https://www.nrscotland.gov.uk/statistics-and-data/statistics/statistics-by-theme/vital-events/names/babies-first-names/full-lists-of-babies-first-names-archive/full-lists-of-babies-first-names-1980-to-1989&amp;quot;,
           &amp;quot;https://www.nrscotland.gov.uk/statistics-and-data/statistics/statistics-by-theme/vital-events/names/babies-first-names/full-lists-of-babies-first-names-archive/full-lists-of-babies-first-names-1990-to-1999&amp;quot;,
           &amp;quot;https://www.nrscotland.gov.uk/statistics-and-data/statistics/statistics-by-theme/vital-events/names/babies-first-names/full-lists-of-babies-first-names-2000-to-2009&amp;quot;,
           &amp;quot;https://www.nrscotland.gov.uk/statistics-and-data/statistics/statistics-by-theme/vital-events/names/babies-first-names/full-lists-of-babies-first-names-2010-to-2014&amp;quot;)

csv_links &amp;lt;- map(pages, get_csv_links) %&amp;gt;% 
  unlist()

# Find the years for each csv file
yr &amp;lt;- parse_number(str_extract(csv_links, &amp;quot;[0-9]+\\.csv&amp;quot;)) %&amp;gt;% 
  if_else(is.na(.), 2018, .) %&amp;gt;% 
  if_else(. &amp;lt; 1000, . + 2000, .)

babynames &amp;lt;- map2_df(csv_links, yr, read_babynames)

babynames2 &amp;lt;- babynames %&amp;gt;% 
  mutate(decade = paste0(str_sub(year, 1, 3), &amp;quot;0s&amp;quot;)) %&amp;gt;% 
  group_by(decade, gender, name) %&amp;gt;% 
  summarise(number_of_babies = sum(number_of_babies)) %&amp;gt;% 
  ungroup()

# Save as rds so it can be quickly read in for the Shiny app
saveRDS(babynames2, &amp;quot;babynames.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;shiny-app&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Shiny App&lt;/h2&gt;
&lt;p&gt;I created the Shiny app by amending the Shiny template available in RStudio as required – all fairly straightforward stuff and nothing fancy involved at all!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Shiny App: Scotland&amp;#39;s most popular babynames by decade

library(shiny)
library(dplyr)
library(ggplot2)
library(scales)
library(stringr)
theme_set(theme_minimal(base_size = 14))

babynames &amp;lt;- readRDS(&amp;quot;babynames.rds&amp;quot;)


ui &amp;lt;- fluidPage(
    
    titlePanel(&amp;quot;Scotland&amp;#39;s Most Popular Babynames&amp;quot;),
    
    sidebarLayout(
        sidebarPanel(
            selectInput(&amp;quot;decade&amp;quot;, &amp;quot;Born in Decade:&amp;quot;,
                        c(&amp;quot;1970s&amp;quot; = &amp;quot;1970s&amp;quot;,
                          &amp;quot;1980s&amp;quot; = &amp;quot;1980s&amp;quot;,
                          &amp;quot;1990s&amp;quot; = &amp;quot;1990s&amp;quot;,
                          &amp;quot;2000s&amp;quot; = &amp;quot;2000s&amp;quot;,
                          &amp;quot;2010s&amp;quot; = &amp;quot;2010s&amp;quot;)),
            radioButtons(&amp;quot;gender&amp;quot;, &amp;quot;Gender:&amp;quot;,
                         c(&amp;quot;Boy&amp;quot; = &amp;quot;boy&amp;quot;,
                           &amp;quot;Girl&amp;quot; = &amp;quot;girl&amp;quot;)),
            
            textInput(&amp;quot;name_start&amp;quot;, &amp;quot;Name starts with&amp;quot;, &amp;quot;&amp;quot;),
        ),
        
        mainPanel(
            plotOutput(&amp;quot;barPlot&amp;quot;)
        )
    )
)


server &amp;lt;- function(input, output) {
    
    output$barPlot &amp;lt;- renderPlot({
        babynames %&amp;gt;% 
            filter(decade == input$decade,
                   gender == input$gender,
                   str_detect(name, paste0(&amp;quot;^&amp;quot;, str_to_title(input$name_start)))) %&amp;gt;% 
            arrange(desc(number_of_babies)) %&amp;gt;% 
            mutate(perc = number_of_babies / sum(.$number_of_babies),
                   name = factor(name, levels = rev(.$name))) %&amp;gt;% 
            slice(1:20) %&amp;gt;% 
            ggplot(aes(x = name, y = perc)) +
            geom_bar(stat = &amp;quot;identity&amp;quot;, fill = &amp;quot;orange&amp;quot;, width = 0.7) +
            scale_y_continuous(labels = percent, limits = c(0, 1)) +
            labs(x = NULL, y = NULL,
                 caption = &amp;quot;Source: National Records of Scotland\nBabynames Data 1974-2018&amp;quot;) +
            coord_flip() +
            theme(panel.grid.major.y = element_blank())
    })
}


shinyApp(ui = ui, server = server)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Trying the ckanr Package</title>
      <link>https://alan-y.netlify.com/post/trying-ckanr/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/trying-ckanr/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#how-resources-are-grouped-in-ckan&#34; id=&#34;toc-how-resources-are-grouped-in-ckan&#34;&gt;How resources are grouped in CKAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#initialising-ckanr-and-exploring-groups-of-resources&#34; id=&#34;toc-initialising-ckanr-and-exploring-groups-of-resources&#34;&gt;Initialising ckanr and exploring groups of resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#connect-to-ckan-with-dplyr-and-download-from-one-resource&#34; id=&#34;toc-connect-to-ckan-with-dplyr-and-download-from-one-resource&#34;&gt;Connect to CKAN with dplyr and download from one resource&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#downloading-all-resources-from-a-dataset&#34; id=&#34;toc-downloading-all-resources-from-a-dataset&#34;&gt;Downloading all resources from a dataset&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;In previous blog posts (&lt;a href=&#34;../ckan-dbplyr&#34;&gt;Hacking dbplyr for CKAN&lt;/a&gt;, &lt;a href=&#34;../ckan-api&#34;&gt;Getting Open Data into R from CKAN&lt;/a&gt;) I have been exploring how to download data from the &lt;a href=&#34;https://www.opendata.nhs.scot&#34;&gt;NHS Scotland open data platform&lt;/a&gt; into R. I’ve recently discovered that &lt;a href=&#34;https://ropensci.org&#34;&gt;ROpenSci&lt;/a&gt; has a package to help with just this called &lt;a href=&#34;https://docs.ropensci.org/ckanr&#34;&gt;ckanr&lt;/a&gt; and I wish I’d known about it earlier as it is really pretty handy! It certainly would’ve saved me some time if I’d know about it earlier but I suppose the positive I can take from it is that some of the functions in ckanr perform similar functions to the ideas I had so I guess that shows that my ideas are not completely wacky!&lt;/p&gt;
&lt;div id=&#34;how-resources-are-grouped-in-ckan&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How resources are grouped in CKAN&lt;/h2&gt;
&lt;p&gt;Before we start testing out some code from ckanr, it is important to consider how resources (&lt;em&gt;I am going to call the individual data items such as specific csv files hosted on CKAN as ‘resources’ but I am not sure if this is necessarily correct&lt;/em&gt;) on CKAN are grouped up as this helps to understand the design of some functions within ckanr. Resources can be grouped within ‘Datasets’, ‘Groups’, ‘Tags’ and ‘Themes’ (and possibly more that I don’t yet know about). Out of these, it is clear to me that ckanr offers functions for exploring resources by all of these groupings except themes (although I could also be mistaken about this). With this out of the way, let’s delve into some code.&lt;/p&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;https://alan-y.netlify.com/img/ckan_groupings.PNG&#34; style=&#34;width:75.0%&#34; alt=&#34;Figure: How resources are grouped in CKAN.&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;&lt;strong&gt;Figure&lt;/strong&gt;: How resources are grouped in CKAN.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;initialising-ckanr-and-exploring-groups-of-resources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Initialising ckanr and exploring groups of resources&lt;/h2&gt;
&lt;p&gt;There are, of course, many different data portals that are powered by CKAN so the first thing we need to do with the ckanr package is to tell it which URL to use by default with &lt;code&gt;ckanr_setup()&lt;/code&gt;. Note that if you are working in a place where you need to use a proxy to connect R to the internet, this can also be set within &lt;code&gt;ckanr_setup()&lt;/code&gt; using the &lt;code&gt;proxy&lt;/code&gt; argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(ckanr)

ckanr_setup(url = &amp;quot;https://www.opendata.nhs.scot&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can explore the groupings available in the NHS Scotland CKAN website with &lt;code&gt;group_list()&lt;/code&gt;, &lt;code&gt;package_list()&lt;/code&gt; and &lt;code&gt;tag_list()&lt;/code&gt;; from the Figure above, these correspond to ‘Groups’, ‘datasets’ and ‘Tags’ respectively. Note that I only show 10 records in each case to keep things concise.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# View available groups and packages/datasets
group_list(as = &amp;quot;table&amp;quot;)[1:10]
#  [1] &amp;quot;acute-hospital-activity&amp;quot;                  &amp;quot;cancer&amp;quot;                                  
#  [3] &amp;quot;child-health&amp;quot;                             &amp;quot;dental-care&amp;quot;                             
#  [5] &amp;quot;deprivation&amp;quot;                              &amp;quot;emergency-care&amp;quot;                          
#  [7] &amp;quot;general-practice&amp;quot;                         &amp;quot;geography&amp;quot;                               
#  [9] &amp;quot;hospital-activity&amp;quot;                        &amp;quot;infection-disease-and-virus-surveillance&amp;quot;                             

package_list(as = &amp;quot;table&amp;quot;)[1:10]
#  [1] &amp;quot;18-weeks-referral-to-treatment&amp;quot;                           
#  [2] &amp;quot;27-30-month-review-statistics&amp;quot;                            
#  [3] &amp;quot;alcohol-related-hospital-statistics-scotland&amp;quot;             
#  [4] &amp;quot;allied-health-professionals-musculoskeletal-waiting-times&amp;quot;
#  [5] &amp;quot;allied-health-professional-vacancies&amp;quot;                     
#  [6] &amp;quot;annual-cancer-incidence&amp;quot;                                  
#  [7] &amp;quot;births-in-scottish-hospitals&amp;quot;                             
#  [8] &amp;quot;cancelled-planned-operations&amp;quot;                             
#  [9] &amp;quot;cancer-mortality&amp;quot;                                         
# [10] &amp;quot;cancer-waiting-times&amp;quot;                  

tag_list(as = &amp;quot;table&amp;quot;)$name[1:10]
# [1] &amp;quot;31 day&amp;quot;                 &amp;quot;62 day&amp;quot;                
# [3] &amp;quot;address&amp;quot;                &amp;quot;adolescent&amp;quot;            
# [5] &amp;quot;adult&amp;quot;                  &amp;quot;age&amp;quot;                   
# [7] &amp;quot;agenda for change&amp;quot;      &amp;quot;agenda for change band&amp;quot;
# [9] &amp;quot;ahp&amp;quot;                    &amp;quot;ailment&amp;quot;        &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Being able to see the names related to different groupings is useful if you want to download data from all resources in a particular group. I’ll give an &lt;a href=&#34;#downloading-all-resources-from-a-dataset&#34;&gt;example of doing this later&lt;/a&gt; but first I want to mimic some of the things I done in previous blog posts but using ckanr.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;connect-to-ckan-with-dplyr-and-download-from-one-resource&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Connect to CKAN with dplyr and download from one resource&lt;/h2&gt;
&lt;p&gt;Let’s demonstrate downloading from one resource using the fairly small &lt;a href=&#34;https://www.opendata.nhs.scot/dataset/allied-health-professionals-musculoskeletal-waiting-times/resource/3988df43-3516-4190-93da-16189db7329a&#34;&gt;Patients Referred&lt;/a&gt; dataset within &lt;a href=&#34;https://www.opendata.nhs.scot/dataset/allied-health-professionals-musculoskeletal-waiting-times&#34;&gt;Allied Health Professionals - Musculoskeletal Waiting Times&lt;/a&gt; which has resource ID &lt;code&gt;3988df43-3516-4190-93da-16189db7329a&lt;/code&gt;. We start by using &lt;code&gt;src_ckan()&lt;/code&gt; to create a connection to CKAN (similar to how you would do so for other non-CKAN databases). From there, you can download data in a similar way to when using &lt;a href=&#34;https://dbplyr.tidyverse.org&#34;&gt;dbplyr&lt;/a&gt; but using a CKAN resource ID instead of a database table name.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ckan &amp;lt;- src_ckan(&amp;quot;https://www.opendata.nhs.scot&amp;quot;)
res_id &amp;lt;- &amp;quot;3988df43-3516-4190-93da-16189db7329a&amp;quot;

dplyr::tbl(src = ckan$con, from = res_id) %&amp;gt;% 
  as_tibble()

# A tibble: 1,115 x 9
#    `_id` HBT2014 ReferralsPerOne~ `_full_text` Specialty NumberOfReferra~ NumberOfReferra~
#    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           
#  1 1     S08000~           2890.  &amp;#39;2015q3&amp;#39;:9 ~ All AHP ~             8904 d               
#  2 2     S08000~            411.  &amp;#39;1267&amp;#39;:5 &amp;#39;2~ Chiropod~             1267 &amp;quot;&amp;quot;              
#  3 3     S08000~             94.4 &amp;#39;2015q3&amp;#39;:3 ~ Occupati~              291 &amp;quot;&amp;quot;              
#  4 4     S08000~            178.  &amp;#39;178.17&amp;#39;:5 ~ Orthotics              549 &amp;quot;&amp;quot;              
#  5 5     S08000~           2206.  &amp;#39;2015q3&amp;#39;:2 ~ Physioth~             6797 &amp;quot;&amp;quot;              
#  6 6     S08000~           1530.  &amp;#39;1472&amp;#39;:7 &amp;#39;1~ All AHP ~             1472 d               
#  7 7     S08000~            165.  &amp;#39;159&amp;#39;:1 &amp;#39;16~ Orthotics              159 &amp;quot;&amp;quot;              
#  8 8     S08000~           1365.  &amp;#39;1313&amp;#39;:2 &amp;#39;1~ Physioth~             1313 &amp;quot;&amp;quot;              
#  9 9     S08000~           2562.  &amp;#39;2015q3&amp;#39;:7 ~ All AHP ~             3212 d               
# 10 10    S08000~            197.  &amp;#39;197.02&amp;#39;:1 ~ Chiropod~              247 &amp;quot;&amp;quot;              
# # ... with 1,105 more rows, and 2 more variables: Quarter &amp;lt;chr&amp;gt;,
# #   ReferralsPerOneHundredThousandPopulationQF &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variables look like they’ve been downloaded in a bit of a random order and that &lt;code&gt;_full_text&lt;/code&gt; variable seems to have appeared so this makes me think that ckanr is using &lt;a href=&#34;../ckan-api/#querying-with-sql&#34;&gt;SQL to download the data&lt;/a&gt;. This is easy enough to confirm.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;getAnywhere(tbl.src_ckan)

function (src, from, ..., name = NULL) 
{
    if (is.null(name)) {
        tbl_sql(&amp;quot;ckan&amp;quot;, src = src, from = sql(from), ...)
    }
    else {
        tbl_sql(subclass = &amp;quot;ckan&amp;quot;, src = src, from = sql(sprintf(&amp;quot;SELECT * FROM \&amp;quot;%s\&amp;quot;&amp;quot;, 
            name)))
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s try combining this with some basic dplyr functions like &lt;code&gt;select()&lt;/code&gt; and &lt;code&gt;filter()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dplyr::tbl(src = ckan$con, from = res_id) %&amp;gt;% 
  select(Quarter, HBT2014) %&amp;gt;% 
  filter(HBT2014 == &amp;quot;S08000015&amp;quot;) %&amp;gt;% 
  as_tibble()

# A tibble: 89 x 2
#    Quarter HBT2014  
#    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    
#  1 2015Q3  S08000015
#  2 2015Q3  S08000015
#  3 2015Q3  S08000015
#  4 2015Q3  S08000015
#  5 2015Q3  S08000015
#  6 2015Q4  S08000015
#  7 2015Q4  S08000015
#  8 2015Q4  S08000015
#  9 2015Q4  S08000015
# 10 2015Q4  S08000015
# # ... with 79 more rows
# Warning messages:
# 1: Translator is missing window variants of the following aggregate functions:
# * all
# * any
# * cor
# * cov
# * paste
# * sd
#  
# 2: Translator is missing window variants of the following aggregate functions:
# * all
# * any
# * cor
# * cov
# * paste
# * sd
#  
# 3: Translator is missing window variants of the following aggregate functions:
# * all
# * any
# * cor
# * cov
# * paste
# * sd&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We get a long list of warnings explaining what you cannot do with the SQL translation available in ckanr but otherwise, works great!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;downloading-all-resources-from-a-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Downloading all resources from a dataset&lt;/h2&gt;
&lt;p&gt;Often, a dataset on CKAN contains many resources related to the same thing. For example, the &lt;a href=&#34;https://www.opendata.nhs.scot/dataset/consultant-vacancies&#34;&gt;Consultant Vacancies&lt;/a&gt; dataset (remember you can see all available ‘Datasets’ using &lt;code&gt;package_list()&lt;/code&gt;) contains different csv files for vacancies at different time points.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cons_vac &amp;lt;- package_show(&amp;quot;consultant-vacancies&amp;quot;, as = &amp;quot;table&amp;quot;)$resources
cons_vac %&amp;gt;% 
  select(name, id)
#                       name                                   id
# 1      Vacancies June 2019 16e27935-325c-471b-89dc-d41c84b3a744
# 2     Vacancies March 2019 ca67b2a4-b2f3-4420-8b77-3771c53b01f4
# 3  Vacancies December 2018 5da80103-4da8-4694-a8b5-2332dfc43e25
# 4 Vacancies September 2018 91d7b780-f2cb-47fb-919f-1c165ed7d301
# 5      Vacancies June 2018 e874f6f4-6cf5-402c-af1d-2d4f26cc669f
# 6     Vacancies March 2018 415c2f86-db7c-4c12-9a64-0cd9cf0d9118&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now if you extract the required resource IDs, you can download all of the datasets with some help from the fantastic &lt;a href=&#34;https://purrr.tidyverse.org&#34;&gt;purrr&lt;/a&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;id_list &amp;lt;- cons_vac$id

# Download each resource into a list item
cons_vac_list &amp;lt;- map(id_list, ~as_tibble(dplyr::tbl(src = ckan$con, from = .x)))

# Check how many variables in each resource
map_dbl(cons_vac_list, length)
# [1] 12 12 12 14 15 12
# Not all resources have the same structure

# Check variable names for a couple that differ
map(cons_vac_list[3:4], names)
# [[1]]
#  [1] &amp;quot;WorkforceRegionGrouping&amp;quot; &amp;quot;HB2014&amp;quot;                 
#  [3] &amp;quot;HB2014QF&amp;quot;                &amp;quot;TotalVacancies&amp;quot;         
#  [5] &amp;quot;_full_text&amp;quot;              &amp;quot;Specialty&amp;quot;              
#  [7] &amp;quot;VacanciesGreater6Months&amp;quot; &amp;quot;Date&amp;quot;                   
#  [9] &amp;quot;SpecialtyQF&amp;quot;             &amp;quot;_id&amp;quot;                    
# [11] &amp;quot;Establishment&amp;quot;           &amp;quot;StaffInPost&amp;quot;            
# 
# [[2]]
#  [1] &amp;quot;WorkforceRegionGrouping&amp;quot; &amp;quot;HB2014&amp;quot;                 
#  [3] &amp;quot;HB2014QF&amp;quot;                &amp;quot;TotalVacancies&amp;quot;         
#  [5] &amp;quot;TotalVacanciesQF&amp;quot;        &amp;quot;_full_text&amp;quot;             
#  [7] &amp;quot;Specialty&amp;quot;               &amp;quot;EstablishmentQF&amp;quot;        
#  [9] &amp;quot;VacanciesGreater6Months&amp;quot; &amp;quot;Date&amp;quot;                   
# [11] &amp;quot;SpecialtyQF&amp;quot;             &amp;quot;_id&amp;quot;                    
# [13] &amp;quot;Establishment&amp;quot;           &amp;quot;StaffInPost&amp;quot;

# TotalVacanciesQF and EstablishmentQF not in resource 3 but are in resource 4

# Combine just the first 3 resources which look like they all have the same structure
bind_rows(cons_vac_list[1:3])
# A tibble: 1,822 x 12
#    WorkforceRegion~ HB2014 HB2014QF TotalVacancies `_full_text`
#    &amp;lt;chr&amp;gt;            &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       
#  1 National Bodies~ SB0806 &amp;quot;&amp;quot;                    0 &amp;#39;0&amp;#39;:9 &amp;#39;1.4&amp;#39;~
#  2 Scotland         S9200~ d                     0 &amp;#39;0&amp;#39;:5 &amp;#39;2019~
#  3 Scotland         S9200~ d                     0 &amp;#39;0&amp;#39;:5 &amp;#39;2.1&amp;#39;~
#  4 National Bodies~ SB0807 &amp;quot;&amp;quot;                    0 &amp;#39;0&amp;#39;:9 &amp;#39;0.3&amp;#39;~
#  5 North            S0800~ &amp;quot;&amp;quot;                    0 &amp;#39;0&amp;#39;:5 &amp;#39;0.1&amp;#39;~
#  6 National Bodies~ SB0808 &amp;quot;&amp;quot;                    0 &amp;#39;0&amp;#39;:9 &amp;#39;1.2&amp;#39;~
#  7 East             S0800~ &amp;quot;&amp;quot;                    0 &amp;#39;0&amp;#39;:3 &amp;#39;12.1~
#  8 East             S0800~ &amp;quot;&amp;quot;                    0 &amp;#39;0&amp;#39;:3 &amp;#39;1.7&amp;#39;~
#  9 National Bodies~ SB0804 &amp;quot;&amp;quot;                    0 &amp;#39;0&amp;#39;:1 &amp;#39;1&amp;#39;:9~
# 10 National Bodies~ SB0807 &amp;quot;&amp;quot;                    0 &amp;#39;0&amp;#39;:9 &amp;#39;0.4&amp;#39;~
# ... with 1,812 more rows, and 7 more variables: Specialty &amp;lt;chr&amp;gt;,
#   VacanciesGreater6Months &amp;lt;dbl&amp;gt;, Date &amp;lt;dbl&amp;gt;, SpecialtyQF &amp;lt;chr&amp;gt;,
#   `_id` &amp;lt;chr&amp;gt;, Establishment &amp;lt;dbl&amp;gt;, StaffInPost &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So that is a basic workflow using ckanr alongside functions from purrr for combining related resources into one dataset. I’ve also presented some ways of checking consistency in the structure of those datasets (an essential step when trying to do something like this) and in this case, not all of the datasets were the same so I just combined the most recent 3 datasets for consultant vacancies at the end for simplicity here; in reality you might want to look at ways to make all of the data consistent first and then combine them up but I’ll leave that data wrangling exercise up to the interested reader.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;My final verdict&lt;/strong&gt;: ckanr is definitely recommended for working with data from CKAN!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>objectremover RStudio Addin</title>
      <link>https://alan-y.netlify.com/post/objectremover-rstudio-addin/</link>
      <pubDate>Mon, 12 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/objectremover-rstudio-addin/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#a-learning-exercise&#34; id=&#34;toc-a-learning-exercise&#34;&gt;A Learning Exercise&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#workflow&#34; id=&#34;toc-workflow&#34;&gt;Workflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;I created my first ever R package and got it released onto CRAN in March 2019. It’s taken me a while to get round to actually writing about this which tells me that despite many years of trying to overcome procrastination, I’m obviously still not there! The package is actually an &lt;a href=&#34;https://rstudio.github.io/rstudioaddins&#34;&gt;RStudio addin&lt;/a&gt; called &lt;a href=&#34;https://github.com/alan-y/objectremover&#34;&gt;objectremover&lt;/a&gt; that helps you to quickly remove objects stored in memory (specifically objects saved in the Global environment) within an R session. The main features include removing objects by&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Starting pattern of object name&lt;/li&gt;
&lt;li&gt;Ending pattern of object name&lt;/li&gt;
&lt;li&gt;Regular expression&lt;/li&gt;
&lt;li&gt;Object type (dataframe, function and other)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a quick demo of objectremover in action.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/alan-y/objectremover/master/inst/img/objectremover_demo.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I made sure to include a couple of safety features to help ensure that you don’t remove objects by mistake. Firstly, it displays what objects will be removed based on the options you’ve selected in real-time and when you click ‘Done’, another warning popup box appears to get a second confirmation that you want to remove these objects. I put this warning popup in as you could remove all saved objects (perhaps by mistake) if, for example, you use a regular expression with no pattern.&lt;/p&gt;
&lt;p&gt;I recently also got objectremover added to the &lt;a href=&#34;https://github.com/daattali/addinslist&#34;&gt;list of addins&lt;/a&gt; started and maintained by &lt;a href=&#34;https://deanattali.com&#34;&gt;Dean Attali&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;a-learning-exercise&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A Learning Exercise&lt;/h2&gt;
&lt;p&gt;Creating this package was largely a learning exercise for me and I really learned loads in the process. To create the package, I tried the &lt;a href=&#34;https://usethis.r-lib.org&#34;&gt;usethis&lt;/a&gt; package for the first time to help get various things set up. When I got to the stage where the package was mostly developed, I tested that the package builds successfully in various operating systems and R versions using &lt;a href=&#34;https://travis-ci.org&#34;&gt;Travis CI&lt;/a&gt; and the &lt;a href=&#34;https://builder.r-hub.io&#34;&gt;R-hub builder&lt;/a&gt; (again, this was the first time I’ve used these tools). A continous integration service like Travis is useful for ensuring that the package still builds properly whenever you make changes to the package and push onto Github. I even had a go at creating a hex sticker for the package (with the help of the &lt;a href=&#34;https://github.com/GuangchuangYu/hexSticker&#34;&gt;hexsticker package&lt;/a&gt;) and anybody that knows me at all knows that this isn’t the sort of thing I’m good at! But I’m happy I gave it a go as that’s the only way to get better.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/alan-y/objectremover/master/inst/img/objectremover_hex.png&#34; style=&#34;width:20.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When I submitted to CRAN, the package got knocked back a few times but I followed the &lt;a href=&#34;http://r-pkgs.had.co.nz/release.html&#34;&gt;wise advice of Hadley Wickham&lt;/a&gt; to not take any criticism personally (particularly as the CRAN maintainers are very busy people and have a hard job) and just tackled all the obstacles in a respectful manner. This advice probably applies to many things in life beyond building R packages so I try to follow this approach as much as humanly possible (but as I am actually human, it stands to reason that I still fail in this regard – and more often than I’d like as well unfortunately!).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;workflow&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Workflow&lt;/h2&gt;
&lt;p&gt;The idea for the package came about as I tend to create a lot of temporary objects in R as I work through analyses and I just wanted a quick way to remove these objects. I often call these objects with names starting with the letter ‘z’ so that they will be easy to spot. This was something I learned from my former PhD supervisor and has actually become pretty invaluable as naming things is something that can sometimes cause me more stress and take up more energy than you would imagine for something this basic and fundamental! So having a way of removing the need for this decision-making helps to focus on solving problems quickly rather than putting energy into things such as naming objects.&lt;/p&gt;
&lt;p&gt;Having said this, I do always go through my code carefully after I’ve solved the problems I’m working on and tidy the script up to make sure I can understand everything I’ve done. This process is sometimes known as &lt;a href=&#34;https://en.wikipedia.org/wiki/Code_refactoring&#34;&gt;code refactoring&lt;/a&gt;. It is something that is sometimes overlooked but is really important for ensuring that you and others can better understand what a script is doing. This quote sums up the benefits pretty well.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;By continuously improving the design of code, we make it easier and easier to work with. This is in sharp contrast to what typically happens: little refactoring and a great deal of attention paid to expediently adding new features. If you get into the hygienic habit of refactoring continuously, you’ll find that it is easier to extend and maintain code.&lt;/p&gt;
&lt;p&gt;— &lt;cite&gt;Joshua Kerievsky&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Part of what I do for this includes putting in section breaks into my script (in RStudio, the shortcut to do this is ctrl+shift+R) to split things into more manageable blocks. I’ll also give meaningful names to objects that I do want to track, particularly for longer projects. For example, there may be several data processing stages involved in going from a raw dataset up to the dataset you use for analysis. I will usually create a number of temporary objects (beginning with ‘z’) that help me get to the &lt;em&gt;analysis dataset&lt;/em&gt; (often via various &lt;a href=&#34;https://dplyr.tidyverse.org/reference/join.html&#34;&gt;joins&lt;/a&gt; between datasets). In this case, the raw and analysis datasets would get meaningful names and the temporary objects could be removed. At the end, I may save the raw and analysis datasets into an R workspace (or as &lt;a href=&#34;https://stackoverflow.com/questions/21370132/r-data-formats-rdata-rda-rds-etc&#34;&gt;RDS format&lt;/a&gt;) that can be easily loaded into scripts created for other parts of a long project.&lt;/p&gt;
&lt;p&gt;Anyway that’s just an example of a workflow that I sometimes use and find pretty efficient for long projects. I’m sure there are many other great ways to work efficiently in creating outputs for long projects so if you know of some, please let me know as I always like to hear about ways to work efficiently in R. Oh and of course, I hope some people find &lt;a href=&#34;https://github.com/alan-y/objectremover&#34;&gt;objectremover&lt;/a&gt; useful!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Hacking dbplyr for CKAN</title>
      <link>https://alan-y.netlify.com/post/ckan-dbplyr/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/ckan-dbplyr/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#aim&#34; id=&#34;toc-aim&#34;&gt;Aim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#create-a-dummy-database&#34; id=&#34;toc-create-a-dummy-database&#34;&gt;Create a dummy database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#test-dbplyrs-sql-translation&#34; id=&#34;toc-test-dbplyrs-sql-translation&#34;&gt;Test dbplyr’s SQL translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modify-dbplyrs-sql-translation&#34; id=&#34;toc-modify-dbplyrs-sql-translation&#34;&gt;Modify dbplyr’s SQL translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#testing-the-dbplyr-hack&#34; id=&#34;toc-testing-the-dbplyr-hack&#34;&gt;Testing the dbplyr hack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#concluding-notes&#34; id=&#34;toc-concluding-notes&#34;&gt;Concluding notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;At the end of my &lt;a href=&#34;../ckan-api&#34;&gt;first post on CKAN&lt;/a&gt; discussing how to use the CKAN API to extract data from the NHS open data platform directly into R, I talked about how it would be neat to write some wrapper functions to make this process a little simpler. Well another idea came to my mind that I think would be even more cool to get working – would it be possible to hack the &lt;a href=&#34;https://dbplyr.tidyverse.org/articles/translation-verb.html&#34;&gt;SQL translation from dbplyr&lt;/a&gt; to make it work effectively for extracting data from CKAN?&lt;/p&gt;
&lt;p&gt;Just for background info, &lt;a href=&#34;https://dbplyr.tidyverse.org&#34;&gt;dbplyr&lt;/a&gt; is a package that lets you use &lt;a href=&#34;https://dplyr.tidyverse.org&#34;&gt;dplyr&lt;/a&gt; code to interact with databases (a database backend for dplyr), which saves you learning SQL (I still recommend that people learn SQL though as it is likely to come in useful anyway!). One of the conveniences of using dbplyr is that you can take advantage of some of the dplyr’s helper functions (e.g &lt;code&gt;starts_with()&lt;/code&gt;, &lt;code&gt;ends_with()&lt;/code&gt;) to assist with tasks such as selecting variables – a task which can be quite tedious in SQL as you must list all of the variables you want to extract.&lt;/p&gt;
&lt;div id=&#34;aim&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Aim&lt;/h2&gt;
&lt;p&gt;The aim here is not to be too ambitious for the hack but to just get the &lt;code&gt;select()&lt;/code&gt; and &lt;code&gt;filter()&lt;/code&gt; functions to work for this hack. My feeling is that if you can get these features working, then you should be able to easily extract just the variables and rows of data you want from CKAN using dplyr code and this is hopefully sufficient for most people. This should be a good starting point for helping people to not download entire datasets when they don’t need to. Anyway, with the brief intro out of the way, let’s see if we can get this little hack working!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-dummy-database&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create a dummy database&lt;/h2&gt;
&lt;p&gt;Since datasets held on CKAN will not be identified by dbplyr as a ‘database’, we have to create a sort of &lt;em&gt;dummy database&lt;/em&gt; within R so that it identifies a CKAN resource as a database. To do this, I created a function called &lt;code&gt;ckan_nhs_init()&lt;/code&gt;. This function simply downloads one row of data from a CKAN resource and stores this in an &lt;a href=&#34;https://www.rdocumentation.org/packages/dplyr/versions/0.5.0/topics/src_memdb&#34;&gt;&lt;em&gt;in-memory SQLite database&lt;/em&gt;&lt;/a&gt;. The key thing here is that extracting one row of data will give us a list of all the variable names for the dummy database. In the code below, please note that I have loaded some required packages to make the function work (if it turns out later that this idea is actually not bad, I’ll write up the code more appropriately for packaging up).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(dbplyr)
library(httr)
library(jsonlite)

ckan_nhs_init &amp;lt;- function(id) {
  url &amp;lt;- paste0(&amp;quot;https://www.opendata.nhs.scot/api/3/action/&amp;quot;,
                &amp;quot;datastore_search?&amp;quot;,
                &amp;quot;resource_id=&amp;quot;, id,
                &amp;quot;&amp;amp;limit=1&amp;quot;)
  status &amp;lt;- status_code(GET(url))
  stopifnot(str_detect(status, &amp;quot;^2&amp;quot;))
  
  df &amp;lt;- fromJSON(url)$result$records
  copy_to(src_memdb(), df, name = id, overwrite = TRUE)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;test-dbplyrs-sql-translation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Test dbplyr’s SQL translation&lt;/h2&gt;
&lt;p&gt;After creating a dummy database (and thus, successfully fooling dbplyr into believing that a CKAN resource is a database), we have to make some modifications to the SQL translation from dbplyr so that the SQL query actually works for interacting with the CKAN API. First let’s test a couple of simple queries to see what dbplyr’s SQL translation produces. We’ll use the Data Zone (2011) Population Estimates dataset (resource ID &lt;code&gt;c505f490-c201-44bd-abd1-1bd7a64285ee&lt;/code&gt;) for testing throughout this post. So what does the SQL translation look like when we just use &lt;code&gt;select()&lt;/code&gt;?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;id &amp;lt;- &amp;quot;c505f490-c201-44bd-abd1-1bd7a64285ee&amp;quot;

ckan_nhs_init(id) %&amp;gt;% 
  select(Year, DZ2011) %&amp;gt;% 
  show_query()
# &amp;lt;SQL&amp;gt;
# SELECT `Year`, `DZ2011`
# FROM `c505f490-c201-44bd-abd1-1bd7a64285ee`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Immediately I can see that the CKAN API isn’t going to like those backticks (&lt;code&gt;`&lt;/code&gt;) around the variable and database names so we’ll have to remove them. We’ll also have to remove the line breaks (&lt;code&gt;\n&lt;/code&gt;). Now let’s test the SQL translation for &lt;code&gt;filter()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ckan_nhs_init(id) %&amp;gt;%
  filter(Year == 2011L)
# &amp;lt;SQL&amp;gt;
# SELECT *
# FROM `c505f490-c201-44bd-abd1-1bd7a64285ee`
# WHERE (`Year` = 2011)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can see that the CKAN API isn’t going to like those brackets around the WHERE statement so we’ll also have to remove them. Lastly let’s test the translation for a &lt;code&gt;select()&lt;/code&gt; combined with a &lt;code&gt;filter()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# select() and then filter()
ckan_nhs_init(id) %&amp;gt;% 
    select(Year, DZ2011) %&amp;gt;% 
    filter(Year == 2011L) %&amp;gt;% 
    show_query()
# &amp;lt;SQL&amp;gt;
# SELECT *
# FROM (SELECT `Year`, `DZ2011`
# FROM `c505f490-c201-44bd-abd1-1bd7a64285ee`)
# WHERE (`Year` = 2011)


# filter() and then select()
ckan_nhs_init(id) %&amp;gt;% 
    filter(Year == 2011L) %&amp;gt;% 
    select(Year, DZ2011) %&amp;gt;% 
    show_query()
# &amp;lt;SQL&amp;gt;
# SELECT `Year`, `DZ2011`
# FROM `c505f490-c201-44bd-abd1-1bd7a64285ee`
# WHERE (`Year` = 2011)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From here, we can see that when using &lt;code&gt;filter()&lt;/code&gt; and then &lt;code&gt;select()&lt;/code&gt;, the query looks fairly concise but when using &lt;code&gt;select()&lt;/code&gt; and then &lt;code&gt;filter()&lt;/code&gt;, we have some work to do to remove the unnecessary &lt;code&gt;SELECT * FROM&lt;/code&gt; at the beginning (note that this SQL is perfectly good normally but it won’t be for the CKAN API). In any case, I think we now have all the information we need to modify dbplyr’s SQL translation to make it work for CKAN.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modify-dbplyrs-sql-translation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modify dbplyr’s SQL translation&lt;/h2&gt;
&lt;p&gt;Using the information just attained, I created the &lt;code&gt;ckan_nhs_extract()&lt;/code&gt; function to make the required modifications to the SQL translation. Note that in the function I use &lt;code&gt;sql_render()&lt;/code&gt; instead of &lt;code&gt;show_query()&lt;/code&gt; as I need the SQL query as a string variable in R rather than just printed to the console. I’ve also added a warning message using &lt;code&gt;cat()&lt;/code&gt; to warn the user that some queries may take a while.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ckan_nhs_extract &amp;lt;- function(db_qry) {
  db_qry &amp;lt;- sql_render(db_qry) %&amp;gt;%
    str_replace_all(&amp;quot;`&amp;quot;, &amp;#39;&amp;quot;&amp;#39;) %&amp;gt;%
    str_replace_all(&amp;quot;\n&amp;quot;, &amp;quot; &amp;quot;)
  
  # Check if there is more than one SELECT statement
  n_select &amp;lt;- str_count(db_qry, &amp;quot;SELECT&amp;quot;)
  
  # Remove unnecessary SELECT statement if needed
  if (n_select &amp;gt; 1) {
    db_qry &amp;lt;- str_remove(db_qry, &amp;quot;^(SELECT \\* FROM )&amp;quot;)
  }
  
  db_qry &amp;lt;- str_remove_all(db_qry, &amp;quot;\\(|\\)&amp;quot;)
  db_qry &amp;lt;- URLencode(db_qry)
  
  db_qry &amp;lt;- paste0(&amp;quot;https://www.opendata.nhs.scot/api/3/action/&amp;quot;,
                   &amp;quot;datastore_search_sql?&amp;quot;,
                   &amp;quot;sql=&amp;quot;,
                   db_qry)
  
  cat(&amp;quot;Extracting: this may take a while\n\n&amp;quot;)
  as_tibble(fromJSON(db_qry)$result$records)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;testing-the-dbplyr-hack&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Testing the dbplyr hack&lt;/h2&gt;
&lt;p&gt;To test this hack, we will make a simple query using &lt;code&gt;select()&lt;/code&gt; and then &lt;code&gt;filter()&lt;/code&gt; which is the more complicated scenario.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ckan_nhs_init(id) %&amp;gt;%
  select(Year, DZ2011) %&amp;gt;%
  filter(Year == 2011, DZ2011 == &amp;quot;S92000003&amp;quot;) %&amp;gt;%
  ckan_nhs_extract()
# Extracting: this may take a while
# 
# # A tibble: 2 x 2
#   DZ2011    Year 
#   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;
# 1 S92000003 2011 
# 2 S92000003 2011 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This produces the desired result so it’s a job well done for now!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;concluding-notes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Concluding notes&lt;/h2&gt;
&lt;p&gt;This hack needs a lot more testing as there are probably lots of things that could potentially break it (but obviously I’m hoping not!). There’s also a niggling issue in that I don’t yet know how to remove an in-memory SQLite database from R (or whether this is even possible) which I guess should be done after you’ve extracted the data you need just to clean things up nicely in R. But in saying that, it likely isn’t a big issue as &lt;code&gt;src_memdb()&lt;/code&gt; has been specifically designed for creating a temporary in-memory database so everything will of course, be cleaned up after you exit your R session anyway. If this hack turns out to be useful and doesn’t break too easily, I may put in a bit of effort to package it up onto Github later. Please let me know what you think if you ever use it!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Getting Open Data into R from CKAN</title>
      <link>https://alan-y.netlify.com/post/ckan-api/</link>
      <pubDate>Wed, 05 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/ckan-api/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#preamble&#34; id=&#34;toc-preamble&#34;&gt;Preamble&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#open-data-in-scotland&#34; id=&#34;toc-open-data-in-scotland&#34;&gt;Open Data in Scotland&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#querying-ckan&#34; id=&#34;toc-querying-ckan&#34;&gt;Querying CKAN&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#querying-with-custom-json&#34; id=&#34;toc-querying-with-custom-json&#34;&gt;Querying with Custom JSON&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#querying-with-sql&#34; id=&#34;toc-querying-with-sql&#34;&gt;Querying with SQL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions-and-further-ideas&#34; id=&#34;toc-conclusions-and-further-ideas&#34;&gt;Conclusions and Further Ideas&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;preamble&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preamble&lt;/h2&gt;
&lt;p&gt;I’ve got lots of rough pieces of R code written as I’ve been exploring/testing various things in the past. A lot of this is currently stored in a pretty disorganised fashion so I thought it would be a good idea to start writing some of these up into blog posts – at the very least, this should make it easier for me to find things later! To start with, I am writing a short post here about how to download data from the CKAN API directly into R – &lt;a href=&#34;https://ckan.org&#34;&gt;CKAN&lt;/a&gt; is an open source data portal platform (basically a tool for making open data websites) and the reason I became interested in it is because this is the platform that &lt;a href=&#34;https://www.opendata.nhs.scot&#34;&gt;NHS Scotland has chosen to host their open data&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;open-data-in-scotland&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Open Data in Scotland&lt;/h2&gt;
&lt;p&gt;It is becoming increasingly important for public sector organisations to make their data open. In Scotland, this is clear from the &lt;a href=&#34;https://www.gov.scot/publications/open-data-strategy&#34;&gt;Scottish Government’s open data strategy&lt;/a&gt;. They believe that providing open data not only aids transparency, but should also result in wider social and economic benefits in the long run. My opinion generally matches this but I feel that one thing to be wary of is the potential for users to interpret data incorrectly so therefore I feel it is absolutely crucial to provide as much information as possible about the datasets (i.e. provide comprehensive metadata). On balance, the upsides of providing open data should definitely outweigh the downsides, particularly if pragmatic steps are taken to mitigate potential issues such as using the data incorrectly which can lead to producing misleading analyses.&lt;/p&gt;
&lt;p&gt;Much work needs to be done on the open data front in Scotland. The level of open data provision by organisations in Scotland is currently lagging behind other parts of the UK in terms of the number of open datasets available but also in terms of how up-to-date the datasets provided are (see &lt;a href=&#34;https://codethecity.co.uk/2019/02/24/scotlands-open-data-february-2019-an-update&#34;&gt;this blog post written in February 2019 by Ian Watt&lt;/a&gt; for more on this). Encouragingly though the situation is improving. NHS Scotland is contributing to this improvement by launching their open data platform (which I will simply refer to as CKAN from hereafter). All of the data held on this platform is licensed under the &lt;a href=&#34;http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3&#34;&gt;UK Open Government Licence (OGL)&lt;/a&gt;. What you can and can’t do with the data is well described there in detail but to me, the gist of it seems to be that you can more or less do what you want with the data as long as you properly acknowledge the source (please read the detail though rather than just taking my word for it!).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;querying-ckan&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Querying CKAN&lt;/h2&gt;
&lt;p&gt;Each dataset held on CKAN is assigned a &lt;code&gt;resource ID&lt;/code&gt; which uniquely identifies it and to make a query on a particular dataset, you will need to know this. The resource ID can be found in the &lt;strong&gt;Additional Information&lt;/strong&gt; section once you are on a dataset’s page. As an example, let’s say we are interested in downloading data about &lt;a href=&#34;https://www.opendata.nhs.scot/dataset/population-estimates/resource/c505f490-c201-44bd-abd1-1bd7a64285ee&#34;&gt;Data Zone (2011) Population Estimates&lt;/a&gt; (this gives data on population estimates for all 6,976 &lt;a href=&#34;https://data.gov.uk/dataset/ab9f1f20-3b7f-4efa-9bd2-239acf63b540/data-zone-boundaries-2011&#34;&gt;data zones (2011) in Scotland&lt;/a&gt; from 2011 to 2017), then, the resource ID for this is &lt;code&gt;c505f490-c201-44bd-abd1-1bd7a64285ee&lt;/code&gt;. Note that this resource ID is also contained in the weblink for the dataset so you do not actually need to navigate down to the Additional Information section to find it.&lt;/p&gt;
&lt;p&gt;There are &lt;a href=&#34;https://docs.ckan.org/en/ckan-2.2.3/datastore.html#datastore-search-htsql&#34;&gt;three querying methods&lt;/a&gt; that you can use which are Custom JSON, SQL and &lt;a href=&#34;http://htsql.org/doc/overview.html#what-is-htsql&#34;&gt;HTSQL&lt;/a&gt;. Each of these methods supports different features but I will only discuss some basic querying using Custom JSON and SQL here. The basic idea of making a query on the CKAN API is that you build this into the web URL and the form of the URL will depend on the querying method you decide to use.&lt;/p&gt;
&lt;div id=&#34;querying-with-custom-json&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Querying with Custom JSON&lt;/h3&gt;
&lt;p&gt;For Custom JSON, the URL should take the form&lt;br /&gt;
&lt;code&gt;https://www.opendata.nhs.scot/api/3/action/&lt;/code&gt; +&lt;br /&gt;
&lt;code&gt;datastore_search?&lt;/code&gt; +&lt;br /&gt;
&lt;code&gt;resource_id=long-id-number&lt;/code&gt; +&lt;br /&gt;
&lt;code&gt;&amp;amp;your-CustomJSON-query&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Let’s test this in R by downloading the Data Zone (2011) Population Estimates dataset. Two R packages are required to help with this: &lt;code&gt;httr&lt;/code&gt; and &lt;code&gt;jsonlite&lt;/code&gt;. The &lt;code&gt;httr&lt;/code&gt; package is needed to work with the API and &lt;code&gt;jsonlite&lt;/code&gt; is needed to convert the downloaded JSON data into an R object. I will also load the tidyverse package for good measure!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(httr)
library(jsonlite)
library(tidyverse)

url &amp;lt;- paste0(&amp;quot;https://www.opendata.nhs.scot/api/3/action/&amp;quot;,
              &amp;quot;datastore_search?&amp;quot;,
              &amp;quot;resource_id=c505f490-c201-44bd-abd1-1bd7a64285ee&amp;quot;)
page &amp;lt;- GET(url) # API request
status_code(page) # # Check that the call is successful
# [1] 200
# This means it was successful

# Status codes:
# 1XX - Informational
# 2XX - Success!
# 3XX - Client Error (something’s not right on your end)
# 4XX - Server Error (something’s not right on their end)

# Download the JSON data and convert to an R list
dz2011_list &amp;lt;- fromJSON(url)
# Extract the actual data from the list
dz2011 &amp;lt;- dz2011_list$result$records
glimpse(dz2011, width = 50)
# Observations: 100
# Variables: 97
# $ `_id`     &amp;lt;int&amp;gt; 178, 179, 180, 181, 182, 18...
# $ Year      &amp;lt;int&amp;gt; 2011, 2011, 2011, 2011, 201...
# $ DZ2011    &amp;lt;chr&amp;gt; &amp;quot;S01006593&amp;quot;, &amp;quot;S01006594&amp;quot;, &amp;quot;...
# $ DZ2011QF  &amp;lt;chr&amp;gt; &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; ...
# $ Sex       &amp;lt;chr&amp;gt; &amp;quot;Female&amp;quot;, &amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;,...
# $ AllAges   &amp;lt;int&amp;gt; 325, 252, 296, 478, 454, 36...
# $ Age0      &amp;lt;int&amp;gt; 2, 2, 6, 8, 2, 4, 4, 3, 1, ...
# $ Age1      &amp;lt;int&amp;gt; 4, 4, 0, 3, 4, 2, 6, 1, 3, ...
# $ Age2      &amp;lt;int&amp;gt; 2, 2, 3, 1, 4, 4, 4, 1, 2, ...
# $ Age3      &amp;lt;int&amp;gt; 6, 1, 0, 5, 1, 4, 4, 2, 1, ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that when I used the &lt;code&gt;glimpse()&lt;/code&gt; function, I’ve only shown the first 10 variables as this dataset contains 97 variables and I wanted to keep the output fairly concise (I will do the same for the rest of the examples in this post where appropriate). A further thing to note is that the default setting using Custom JSON is to download only the first 100 records from the dataset which you can also see from the number of observations in the output of &lt;code&gt;glimpse()&lt;/code&gt;; if you want to download more rows than this you need to explicitly set this in the query. For example, if you wanted the first 150 rows you can simply add this query into the URL.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;url_150r &amp;lt;- paste0(url, &amp;quot;&amp;amp;limit=150&amp;quot;)
dz2011_list_150r &amp;lt;- fromJSON(url_150r)
dz2011_150r &amp;lt;- dz2011_list_150r$result$records
glimpse(dz2011_150r, width = 50)
# Observations: 150
# Variables: 97
# $ `_id`    &amp;lt;int&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 1...
# $ Year     &amp;lt;int&amp;gt; 2011, 2011, 2011, 2011, 2011...
# $ DZ2011   &amp;lt;chr&amp;gt; &amp;quot;S92000003&amp;quot;, &amp;quot;S92000003&amp;quot;, &amp;quot;S...
# $ DZ2011QF &amp;lt;chr&amp;gt; &amp;quot;d&amp;quot;, &amp;quot;d&amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;...
# $ Sex      &amp;lt;chr&amp;gt; &amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;, &amp;quot;Male&amp;quot;, &amp;quot;F...
# $ AllAges  &amp;lt;int&amp;gt; 2570300, 2729600, 419, 463, ...
# $ Age0     &amp;lt;int&amp;gt; 30877, 29488, 3, 10, 4, 4, 9...
# $ Age1     &amp;lt;int&amp;gt; 29388, 28294, 5, 8, 6, 0, 3,...
# $ Age2     &amp;lt;int&amp;gt; 30189, 29190, 5, 7, 1, 3, 4,...
# $ Age3     &amp;lt;int&amp;gt; 30173, 29061, 5, 7, 5, 6, 1,...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I am not yet sure how to set up the query in Custom JSON so that it just downloads all the records but I suppose you could just set the limit to a very high number that you know will cover everything.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;querying-with-sql&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Querying with SQL&lt;/h3&gt;
&lt;p&gt;To query with SQL you will obviously need to know how to write SQL queries. I won’t be discussing SQL queries here as the focus is on using the CKAN API. For SQL, the URL should take the form&lt;br /&gt;
&lt;code&gt;https://www.opendata.nhs.scot/api/3/action/&lt;/code&gt; +&lt;br /&gt;
&lt;code&gt;datastore_search_sql?&lt;/code&gt; +&lt;br /&gt;
&lt;code&gt;sql=&lt;/code&gt; +&lt;br /&gt;
&lt;code&gt;your-SQL-query&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;There are a couple of quirks about how to make SQL query work in R. You need to enclose the name of the resource ID in speech marks (“resource-ID”) so if like me, your default method of creating strings is to use speech marks rather than the apostrophe character (’), you will need to escape the speech mark using the backslash (\“). Similarly, you need to enclose other things such as variable names in speech marks when making more complicated queries. You also need to &lt;a href=&#34;https://en.wikipedia.org/wiki/Percent-encoding&#34;&gt;percent-encode&lt;/a&gt; your special characters to make them work as a URL – luckily the &lt;code&gt;URLencode()&lt;/code&gt; function makes this easy!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Download the whole dataset using a SQL query
url_sql &amp;lt;- paste0(&amp;quot;https://www.opendata.nhs.scot/api/3/action/&amp;quot;,
                  &amp;quot;datastore_search_sql?&amp;quot;,
                  &amp;quot;sql=&amp;quot;,
                  URLencode(&amp;quot;SELECT * from \&amp;quot;c505f490-c201-44bd-abd1-1bd7a64285ee\&amp;quot;&amp;quot;))

dz2011_list_sql &amp;lt;- fromJSON(url_sql)
dz2011_sql &amp;lt;- dz2011_list_sql$result$records
glimpse(dz2011_sql, width = 50)
# Observations: 97,678
# Variables: 98
# $ Age28 &amp;lt;chr&amp;gt; &amp;quot;33649&amp;quot;, &amp;quot;35002&amp;quot;, &amp;quot;12&amp;quot;, &amp;quot;6&amp;quot;, &amp;quot;6...
# $ Age29 &amp;lt;chr&amp;gt; &amp;quot;33865&amp;quot;, &amp;quot;35698&amp;quot;, &amp;quot;8&amp;quot;, &amp;quot;10&amp;quot;, &amp;quot;1...
# $ Age26 &amp;lt;chr&amp;gt; &amp;quot;34410&amp;quot;, &amp;quot;35491&amp;quot;, &amp;quot;6&amp;quot;, &amp;quot;11&amp;quot;, &amp;quot;1...
# $ Age27 &amp;lt;chr&amp;gt; &amp;quot;33302&amp;quot;, &amp;quot;34274&amp;quot;, &amp;quot;11&amp;quot;, &amp;quot;7&amp;quot;, &amp;quot;5...
# $ Age24 &amp;lt;chr&amp;gt; &amp;quot;35129&amp;quot;, &amp;quot;36098&amp;quot;, &amp;quot;9&amp;quot;, &amp;quot;7&amp;quot;, &amp;quot;1&amp;quot;...
# $ Age25 &amp;lt;chr&amp;gt; &amp;quot;35166&amp;quot;, &amp;quot;35492&amp;quot;, &amp;quot;6&amp;quot;, &amp;quot;6&amp;quot;, &amp;quot;2&amp;quot;...
# $ Age22 &amp;lt;chr&amp;gt; &amp;quot;36117&amp;quot;, &amp;quot;36450&amp;quot;, &amp;quot;6&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;3&amp;quot;...
# $ Age23 &amp;lt;chr&amp;gt; &amp;quot;36710&amp;quot;, &amp;quot;37038&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;3&amp;quot;...
# $ Age20 &amp;lt;chr&amp;gt; &amp;quot;37785&amp;quot;, &amp;quot;37513&amp;quot;, &amp;quot;5&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;6&amp;quot;...
# $ Age21 &amp;lt;chr&amp;gt; &amp;quot;36354&amp;quot;, &amp;quot;36386&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;9&amp;quot;, &amp;quot;4&amp;quot;...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that when you use SQL to query CKAN, all 97,678 records are downloaded from the dataset (unless you explicitly tell it not to) so therefore, the query took much longer to finish. The data has been extracted but with a couple of strange issues. The variables are in a weird order and there are 98 variables here instead of the 97 we got previously – it seems to have extracted a variable called &lt;code&gt;_full_text&lt;/code&gt;. I don’t know why it does this but I suppose these issues can be sorted out easily enough with some dplyr. Let’s also make a query to download just one variable to demonstrate how to write a marginally more complicated SQL query.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Download only the DZ2011 variable
url_sql_1v &amp;lt;- paste0(&amp;quot;https://www.opendata.nhs.scot/api/3/action/&amp;quot;,
                     &amp;quot;datastore_search_sql?&amp;quot;,
                     &amp;quot;sql=&amp;quot;,
                     URLencode(&amp;quot;SELECT \&amp;quot;DZ2011\&amp;quot; from \&amp;quot;c505f490-c201-44bd-abd1-1bd7a64285ee\&amp;quot;&amp;quot;))

dz2011_list_1v &amp;lt;- fromJSON(url_sql_1v)
dz2011_1v &amp;lt;- dz2011_list_1v$result$records
glimpse(dz2011_1v, width = 50)
# Observations: 97,678
# Variables: 1
# $ DZ2011 &amp;lt;chr&amp;gt; &amp;quot;S92000003&amp;quot;, &amp;quot;S92000003&amp;quot;, &amp;quot;S01...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;No issues with this query and everything was extracted as expected.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions-and-further-ideas&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions and Further Ideas&lt;/h2&gt;
&lt;p&gt;This post has given a little bit of background to open data in Scotland as well as an introduction to downloading NHS Scotland open data directly into R using simple queries with the CKAN API but there are, of course, much fancier things that you can do when constructing queries (e.g. joins on datasets using SQL or using the API to search CKAN for datasets with a particular tag) which I’ve not covered. I may cover some of these in a future post but for now, the interested reader can trawl through the &lt;a href=&#34;https://docs.ckan.org/en/2.8/user-guide.html&#34;&gt;CKAN user guide&lt;/a&gt; to find out more about features like that! As a final point, I think it would be neat to write some wrapper functions in R to make it easier to make queries to CKAN (this could even be packaged up) – it might be a future project! I envision that this would work similarly to the &lt;a href=&#34;https://github.com/jsphdms/opendatascot&#34;&gt;opendatascot&lt;/a&gt; package which has been built to help with extracting data from &lt;a href=&#34;https://statistics.gov.scot/home&#34;&gt;statistics.gov.scot&lt;/a&gt;. Anyway that’s for another day.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Glasgow R User Group</title>
      <link>https://alan-y.netlify.com/post/glasgow-r-user-group/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://alan-y.netlify.com/post/glasgow-r-user-group/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;https://alan-y.netlify.com/img/glasgowR.png&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I am very excited to hear that there are attempts to create a brand new &lt;a href=&#34;https://www.meetup.com/Glasgow-R-User-Group&#34;&gt;R user group in Glasgow&lt;/a&gt;! I had just talked in &lt;a href=&#34;../post-number-one&#34;&gt;Post Number One&lt;/a&gt; about my guilt at not having been able to attend &lt;a href=&#34;http://edinbr.org&#34;&gt;EdinbR&lt;/a&gt; as often as I wished but it should be much easier for me to find time to attend a group based in Glasgow. If you are based in (or near) Glasgow and would like to join the R community, this sounds like the place to be – I hope this idea takes off! This is the blurb from their meetup page.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This group is for people who use R (or want to start to). This meetup is a first attempt to get together people in Glasgow interested in R, meet and decide how to go about the organisation. There are several R User around the world and would be nice to ave one in Glasgow as well.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>
